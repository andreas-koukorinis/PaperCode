{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 1,
>>>>>>> 0be85d3afea9eb5df285a6137fd4dfbb0ac90522
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "sys.path.append('/home/kman/papers/QFPaper/Code/')\n",
    "import hmm \n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import seaborn as sns\n",
    "from hmm import hmm_calibration\n",
    "from observation_models import *\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "prng = np.random.RandomState(10)\n",
    "n_components = 3\n",
    "startprob = prng.rand(n_components)\n",
    "startprob = startprob / startprob.sum()\n",
    "transmat = prng.rand(n_components, n_components) #random starting point\n",
    "transmat /= np.tile(transmat.sum(axis=1)[:, np.newaxis], (1, n_components))#normalising so all entries sum up to 1\n",
    "\n",
    "sigmas = [ .3, 2.5, 1][0:n_components]\n",
    "lambdas = [0.5, 1, 0.8][0:n_components]\n",
    "weights = [0.1, 0.5, 0.4][0:n_components]\n",
    "sample_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 2,
>>>>>>> 0be85d3afea9eb5df285a6137fd4dfbb0ac90522
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate state and observation data from the \\\"right\\\" distribution\\n\",\n",
    "states = hmm_calibration.sample_states(startprob, transmat, prng, sample_size=sample_size)\n",
    "taus, price_changes = ExpGauss.sample_data(states, lambdas, sigmas, weights,  rng=prng)\n",
    "price_changes_sq = price_changes**2\n",
    "data_set = pd.DataFrame()\n",
    "data_set['tau'] = taus\n",
    "data_set['price_change'] = price_changes\n",
    "#define the calibrator and model \n",
    "\n",
    "priors = None \n",
    "update_tag = 'tpsql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,1].set_title('Duration')\n",
    "axs[0,1].plot(data_set['tau'])\n",
    "axs[0,0].set_title('Price Change')\n",
    "axs[0,0].plot(data_set['price_change'])\n",
    "axs[1,1].hist(data_set['tau'])\n",
    "axs[1,0].hist(data_set['price_change'])\n",
    "\n",
    "#data_set['price_change'].plot.axs[1,1]\n",
    "#axs[0]\n",
    "#axs[1].set_title('Price Change')\n",
    "\n",
    "obs_model = ExpGauss(n_components)\n",
    "obs_model.set_up_initial(data_set) \n",
    "the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "complete_data_log_likelihood() takes exactly 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d252fd0925d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#and these should be the optimal observation likelihood and complete data likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moptimal_obs_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_model_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mcomplete_data_ll_optimal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplete_data_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_obs_ll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# now lets vary the \"var_to_plot[no_state]\" and make sure we indeed hit a maxima\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: complete_data_log_likelihood() takes exactly 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "obs_model = ExpGauss(n_components)\n",
    "obs_model.set_up_initials(data_set) \n",
    "the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "\n",
    "result = the_hmm.run_hmm(data_set, update_tag=update_tag, initialise_method_tag='uniform', rng=prng)\n",
    "var_to_plot = 'lambdas_'\n",
    "no_state = 0\n",
    "\n",
    "for step_object in result['step_calibrations']: \n",
    "        #this is the variable that the M-step calculated at the step-th step \n",
    "        theoretical_solution = getattr(step_object.obs_model_, var_to_plot)[no_state]\n",
    "        #and these should be the optimal observation likelihood and complete data likelihood\n",
    "        optimal_obs_ll = step_object.obs_model_.score(data_set)\n",
    "        complete_data_ll_optimal = step_object.complete_data_log_likelihood(optimal_obs_ll)\n",
    "        \n",
    "        # now lets vary the \"var_to_plot[no_state]\" and make sure we indeed hit a maxima\n",
    "        range1 = np.arange(0.05, theoretical_solution, (theoretical_solution-0.05)/20.)\n",
    "        range2 = np.arange(theoretical_solution, 5., (5. - theoretical_solution)/20)\n",
    "        variable_range = np.concatenate((range1, range2))\n",
    "\n",
    "        values_range = []\n",
    "        for var in variable_range:\n",
    "            step_object.obs_model_.sigmas_[no_state] = var\n",
    "            obs_ll = step_object.obs_model_.score(data_set)\n",
    "            values_range.append(step_object.complete_data_log_likelihood(obs_ll))\n",
    "\n",
    "plt.plot(variable_range, values_range)\n",
    "plt.axvline(x=theoretical_solution) \n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a dataset with a thousand datapoints. TYhe run EM algo using the first 100, the first 200 etc\n",
    "The calculate the likelihood using the last calibraiton object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "states = hmm_calibration.sample_states(startprob, transmat, prng, sample_size=sample_size)\n",
    "taus, price_changes = ExpGauss.sample_data(states, lambdas, sigmas, weights,  rng=prng)\n",
    "data = pd.DataFrame() \n",
    "data['tau'] = taus \n",
    "data['price_change'] = price_changes \n",
    "complete_log_likelihoods = [] \n",
    "update_tag = 'tplqs'\n",
    "for i in range(1,11): \n",
    "    df = data[0:i*100]\n",
    "    obs_model = ExpGauss(n_components)\n",
    "    obs_model.set_up_initial_params(df) \n",
    "    the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "    \n",
    "    result = the_hmm.run_hmm(df, update_tag=update_tag, initialise_method_tag='uniform', rng=prng)\n",
    "    \n",
    "    last_calibration = result['step_calibrations'][-1]\n",
    "    optimal_obs_ll = last_calibration.obs_model_.score(df)\n",
    "    complete_log_likelihoods.append(last_calibration.complete_data_log_likelihood(optimal_obs_ll)) \n",
    "    \n",
    "plt.plot(range(1,11), complete_log_likelihoods)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_object= result['step_calibrations'][10] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_object.tpm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimal_obs_ll = last_calibration.obs_model_.score(df)\n",
    "complete_log_likelihoods.append(last_calibration.complete_data_log_likelihood(optimal_obs_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "states = hmm_calibration.sample_states(startprob, transmat, prng, sample_size=sample_size)\n",
    "taus, price_changes = ExpGauss.sample_data(states, lambdas, sigmas, weights,  rng=prng)\n",
    "data = pd.DataFrame() \n",
    "data['tau'] = taus \n",
    "data['price_change'] = price_changes \n",
    "complete_log_likelihoods = [] \n",
    "update_tag = 'tplqs'\n",
    "obs_model = ExpGauss(n_components)\n",
    "obs_model.set_up_initial_params(data) \n",
    "the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "result = the_hmm.run_hmm(data, update_tag=update_tag, initialise_method_tag='uniform', rng=prng)\n",
    "steps_ll = [] \n",
    "for step_object in result['step_calibrations']: \n",
    "    #optimal_obs_ll = step_object.obs_model_.score(data)\n",
    "    #steps_ll.append(step_object.complete_data_log_likelihood(optimal_obs_ll)) \n",
    "    print step_object.tpm_, '\\n' \n",
    "plt.plot(range(len(steps_ll)), steps_ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(10)\n",
    "n_components = 3\n",
    "startprob_2 = prng.rand(n_components)\n",
    "startprob_2 = startprob_2 / startprob_2.sum()\n",
    "transmat_2 = prng.rand(n_components, n_components) #random starting point\n",
    "transmat_2 /= np.tile(transmat.sum(axis=1)[:, np.newaxis], (1, n_components))#normalising so all entries sum up to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transmat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transmat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transmat_2[0,0]=transmat_2[0,0]+random.random()\n",
    "transmat_2 /= np.tile(transmat_2.sum(axis=1)[:, np.newaxis], (1, n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transmat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape_ =np.shape(transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,shape_[0]-1):\n",
    "    transmat2 = transmat\n",
    "    transmat2[0,i]=transmat2[0,i]+random.random()\n",
    "    transmat2 /= np.tile(transmat2.sum(axis=1)[:, np.newaxis], (1, n_components))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_sums = transmat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "states_2 = hmm_calibration.sample_states(startprob_2, transmat_2, prng, sample_size=sample_size)\n",
    "taus, price_changes = ExpGauss.sample_data(states_2, lambdas, sigmas, weights,  rng=prng)\n",
    "data = pd.DataFrame() \n",
    "data['tau'] = taus \n",
    "data['price_change'] = price_changes \n",
    "complete_log_likelihoods_2 = [] \n",
    "update_tag = 'tplqs'\n",
    "for i in range(1,11): \n",
    "    df = data[0:i*100]\n",
    "    obs_model = ExpGauss(n_components)\n",
    "    obs_model.set_up_initial_params(df) \n",
    "    the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "    \n",
    "    result = the_hmm.run_hmm(df, update_tag=update_tag, initialise_method_tag='uniform', rng=prng)\n",
    "    \n",
    "    last_calibration = result['step_calibrations'][-1]\n",
    "    optimal_obs_ll = last_calibration.obs_model_.score(df)\n",
    "    complete_log_likelihoods_2.append(last_calibration.complete_data_log_likelihood(optimal_obs_ll)) \n",
    "    \n",
    "plt.plot(range(1,11), complete_log_likelihoods_2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "states2 = hmm_calibration.sample_states(startprob, transmat2, prng, sample_size=sample_size)\n",
    "taus2, price_changes2 = ExpGauss.sample_data(states2, lambdas, sigmas, weights,  rng=prng)\n",
    "data2 = pd.DataFrame() \n",
    "data2['tau'] = taus2 \n",
    "data2['price_change'] = price_changes2 \n",
    "complete_log_likelihoods2 = [] \n",
    "update_tag = 'tplqs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,11): \n",
    "    df = data2[0:i*100]\n",
    "    obs_model = ExpGauss(n_components)\n",
    "    obs_model.set_up_initial_params(df) \n",
    "    the_hmm = hmm_calibration(obs_model, n_components, max_iter=50) \n",
    "    \n",
    "    result = the_hmm.run_hmm(df, update_tag=update_tag, initialise_method_tag='uniform', rng=prng)\n",
    "    \n",
    "    last_calibration = result['step_calibrations'][-1]\n",
    "    optimal_obs_ll = last_calibration.obs_model_.score(df)\n",
    "    complete_log_likelihoods2.append(last_calibration.complete_data_log_likelihood(optimal_obs_ll)) \n",
    "    \n",
    "plt.plot(range(1,11), complete_log_likelihoods2)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
