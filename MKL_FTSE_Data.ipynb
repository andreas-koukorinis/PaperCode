{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only_drive = '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'  # external date only drive\n",
    "ext_drive_loc = ('/media/ak/My Passport/Experiment Data/')\n",
    "data_dir = os.getenv('FINANCE_DATA') #internal folder with finance data \n",
    "\n",
    "features = os.path.join(ext_drive_loc,'features')\n",
    "labels = os.path.join(ext_drive_loc, 'labels')\n",
    "\n",
    "symbols = [s for s in os.listdir(features) if s.endswith('.L')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path/media/ak/My Passport/Experiment Data/features/AAL.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDir(dirLoc):\n",
    "    print\n",
    "    if os.path.exists(dirLoc):#Checks if the dir exists\n",
    "        print(\"The directory exists\")\n",
    "    else:\n",
    "        print (\"No directory found for \"+dirLoc) #Output if no directory\n",
    "#         print\n",
    "#         os.makedirs(CheckDir)#Creates a new dir for the given name\n",
    "#         print \"Directory created for \"+CheckDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170117',\n",
       " '20170118',\n",
       " '20170119',\n",
       " '20170120',\n",
       " '20170123',\n",
       " '20170124',\n",
       " '20170125',\n",
       " '20170126',\n",
       " '20170127',\n",
       " '20170130',\n",
       " '20170131',\n",
       " '20170301',\n",
       " '20170703',\n",
       " '20170704',\n",
       " '20170705',\n",
       " '20170706',\n",
       " '20170707',\n",
       " '20170710',\n",
       " '20170711',\n",
       " '20170713',\n",
       " '20170714',\n",
       " '20170717',\n",
       " '20170718',\n",
       " '20170719',\n",
       " '20170720',\n",
       " '20170721',\n",
       " '20170724',\n",
       " '20170725',\n",
       " '20170811',\n",
       " '20170814',\n",
       " '20170815',\n",
       " '20170816',\n",
       " '20170817',\n",
       " '20170818',\n",
       " '20170821',\n",
       " '20170822',\n",
       " '20170823',\n",
       " '20170824',\n",
       " '20170825',\n",
       " '20170829',\n",
       " '20170830',\n",
       " '20170831',\n",
       " '20170712',\n",
       " '20170726',\n",
       " '20170810',\n",
       " '20170727',\n",
       " '20170728',\n",
       " '20170731',\n",
       " '20170801',\n",
       " '20170802',\n",
       " '20170803',\n",
       " '20170804',\n",
       " '20170807',\n",
       " '20170808',\n",
       " '20170809']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unit test\n",
    "test_dir = '/media/ak/My Passport/Experiment Data/features/AAL.L/MODEL_BASED/20170116'\n",
    "os.listdir(test_dir)\n",
    "[file.split(\"_\")[5] for file in os.listdir(test_dir)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = os.path.join(data_dir,'Labels')\n",
    "\n",
    "idxSymbol = 1 #0,1,2, in our case - so you pick a symbol here\n",
    "print(\"you picked symbol: \",symbols[idxSymbol])  \n",
    "\n",
    "#based on the symbol select the features path\n",
    "symbolFeaturesPath = os.path.join(features,symbols[idxSymbol],'MODEL_BASED') \n",
    "# path all the list of dates we have features for\n",
    "#select the Labels path as well\n",
    "symbolLabelsPath = os.path.join(labels, symbols[idxSymbol],'NON_DIRECTIONAL')\n",
    "\n",
    "symbolLabelsDatesList = [fileDate.split(\".\")[0] for fileDate in sorted(os.listdir(symbolLabelsPath))]\n",
    "#strip out all the features dates, for the particular symbol. \n",
    "#so far we have selcected a symbol, picked the directory of features and labels for that symbol (features being the HMM files),\n",
    "# and split the labels files by date\n",
    "\n",
    "symbolFeaturesListDates = os.listdir(symbolFeaturesPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([featureOOSDate.split(\"_\")[5] for featureOOSDate in\n",
    "#                                      sorted(os.listdir(oos_features_date_path))]) \n",
    "featureDatePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, featuresDate in enumerate(symbolFeaturesListDates): #got through all the features dates\n",
    "    featureDatePath =os.path.join(symbolFeaturesPath, symbolFeaturesListDates[idx])\n",
    "    featureListFiles = os.listdir(featureDatePath)\n",
    "    #featureDates = sorted([featureFile.split(\"_\")[5] for featureFile in sorted(featureListFiles)]) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, featuresDate in enumerate(symbolFeaturesListDates): #got through all the features dates\n",
    "#     #create a features path\n",
    "#     featuresDatePath = (os.path.join(symbolFeaturesPath, featuresDate))\n",
    "# #     labelsFeaturesDatePaths = [(os.listdir(featuresDatePath)[date].split(\"_\")[5]) for date in os.listdir(featuresDatePath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[os.listdir(featuresDatePath)[x].split(\"_\")[5] for x in os.listdir(featuresDatePath)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#list of all the directories each containing the forward features for one HMM day\n",
    "\n",
    "# to pick a path for features, select a directory from above, within the FeaturesPath, and then look inside.\n",
    "# so what you have done is pick an HMM model date and then the features inside it.\n",
    "os.listdir(os.path.join(symbolFeaturesPath, symbolFeaturesListDates[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(symbolLabelsPath, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------')\n",
    "\n",
    "\n",
    "\n",
    "symbolfeaturesPath = os.path.join(os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED'), featuresDateList[idxDate])\n",
    "\n",
    "#for each of the featuresDateItems, I have a set of features that needs to get matched with a set of labels and used to train an MKLSVM\n",
    "print(featuresDateItemsPath)\n",
    "print('---------------')\n",
    "listFeaturesPickle = os.listdir(featuresDateItemsPath) #all the features!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxDate= 3 #as an example, enumerate the above list when parsing thru\n",
    "print(featuresDateList[idxDate])\n",
    "os.listdir(featuresDateItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxFeatures = 0 #placeholder for enumerator\n",
    "featuresTuple = pickle.load(open(os.path.join(featuresDateItems,listFeaturesPickle[idxFeatures]), \"rb\"), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDateItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresArray = np.asarray(pd.concat([featuresTuple[0], featuresTuple[1],\\\n",
    "                                                 featuresTuple[2], featuresTuple[3]], axis=1, sort=False).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDate = os.path.splitext(listFeaturesPickle[idxDate])[0].split(\"_\")[5]\n",
    "#take the featuresTuple file, pick the first element and split it using \"_\", then pick the data the features were created\n",
    "\n",
    "symbolLabelDir = os.path.join(labels,symbols[idxSymbol],'NON_DIRECTIONAL') #path that has all the labels for the particular symbol, i.e all the dates\n",
    "#each day is a set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsFile = os.path.join(symbolLabelDir,labelsDate+\".csv\") # formulate the path for (as an example) the specific date we dealt with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDf= pd.read_csv(labelsFile).fillna(0) #load the dataframe and replace the NAs with zero (this is small cheat)\n",
    "labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] #just retain the column of labels please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulate the problem\n",
    "Y_all = labels\n",
    "X_all = featuresArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape[0] == Y_all.shape[0] #check for dimensions, if False, there is a problem somewhere, prob picked wrong date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
