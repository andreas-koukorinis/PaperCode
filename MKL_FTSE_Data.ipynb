{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "scaler = StandardScaler()\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "import pickle as pkl\n",
    "###\n",
    "\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file\n",
    "def checkDir(dirLoc):\n",
    "    print\n",
    "    if os.path.exists(dirLoc):#Checks if the dir exists\n",
    "        print(\"The directory exists\")\n",
    "    else:\n",
    "        print (\"No directory found for \"+dirLoc) #Output if no directory\n",
    "#         print\n",
    "#         os.makedirs(CheckDir)#Creates a new dir for the given name\n",
    "#         print \"Directory created for \"+CheckDir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ak/FinData/\n"
     ]
    }
   ],
   "source": [
    "hardDrivesLoc = '/media/ak/'\n",
    "hardDrivesList = os.listdir('/media/ak/')\n",
    "\n",
    "dataOnlyDrive = '/media/ak/DataOnly'  # external date only drive\n",
    "#ext_drive_loc = ('/media/ak/My Passport/Experiment Data/')\n",
    "data_dir = os.getenv('FINANCE_DATA') #internal folder with finance data \n",
    "folderList =  [s for s in os.listdir(dataOnlyDrive) if s.startswith('Dat') or s.startswith('Fin')]\n",
    "# inputDrive = data_only_drive\n",
    "# features = os.path.join(inputDrive,'features')\n",
    "# labels = os.path.join(inputDrive, 'labels')\n",
    "\n",
    "# symbols = [s for s in os.listdir(features) if s.endswith('.L')]\n",
    "folderIdx = 0\n",
    "finalLocation= \"/\".join((dataOnlyDrive,folderList[folderIdx]))\n",
    "symbols = [s for s in os.listdir(finalLocation) if s.endswith('.L')] #keep a list of the symbols\n",
    "os.listdir(finalLocation)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory exists\n"
     ]
    }
   ],
   "source": [
    "locIdx= 1 #'''WorkDrive'''\n",
    "\n",
    "selection = hardDrivesList[locIdx]\n",
    "\n",
    "selectionLoc = os.path.join(hardDrivesLoc,selection ) \n",
    "''' location of WorkDrive'''\n",
    "dataList = [s for s in os.listdir(selectionLoc) if s.startswith('Dat')]\n",
    "DataLoc = os.path.join(hardDrivesLoc,selection,dataList[1] )\n",
    "path= 'MKL_Experiments'\n",
    "MKLExpPath = os.path.join(DataLoc,path)\n",
    "#os.makedirs(os.path.join(DataLoc,path)) # run once so comment out afterwards- we can write an if statement later\n",
    "checkDir(MKLExpPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick a symbol ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRU.L\n",
      "/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED\n"
     ]
    }
   ],
   "source": [
    "##picking up a specific feature\n",
    "symbolIdx = 1 #pick one of the symbols\n",
    "#symbols[symbolIdx] -->output :PRU.L\n",
    "print(symbols[symbolIdx])\n",
    "# do a join to get the location\n",
    "symbolLocation = \"/\".join((finalLocation,symbols[symbolIdx])) \n",
    "\n",
    "# get he features now\n",
    "symbolFeaturesLocation = \"/\".join((symbolLocation,'MODEL_BASED')) # where all the HMM output is\n",
    "\n",
    "print(symbolFeaturesLocation) # <-- all the HMM model output is here, for each model there is a Date Folder and then OOS files\n",
    "MKLSymbolPath = os.path.join(MKLExpPath,symbols[symbolIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(os.path.join(MKLExpPath,symbols[symbolIdx])) #make MKL path for symbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick Features for a specific HMM MODEL Date ###\n",
    "### then move to labels ...pick the location of the labels and make a list of all the available labels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbolHMMDatesList = os.listdir(symbolFeaturesLocation) \n",
    "\n",
    "#list of all the MODEL dates we have generated features files for. each #\n",
    "# each of these dates in symbolFeaturesDates corresponds to a list of dates\n",
    "## (symbolHMMDatesList = '20170829', '20170710', '20170801', ... ]\n",
    "#location of labels : /media/ak/DataOnly/FinDataReal/Labels/[Symbol :PRU.L]/NON_DIRECTIONAL\n",
    "\n",
    "symbolLabelsLocation = \"/\".join((finalLocation, 'Labels',symbols[symbolIdx],'NON_DIRECTIONAL')) \n",
    "\n",
    "#list of all the label dates\n",
    "\n",
    "symbolLabelsDates =[dateFile.split(\".\")[0] for dateFile in os.listdir(symbolLabelsLocation)]\n",
    "\n",
    "# Output symbolLabelsDates --> ['20170704', '20180226', '20180208',...] all we are doing is going for this \n",
    "# os.listdir(symbolFeaturesLocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The directory exists\n",
      "1\n",
      "The directory exists\n",
      "2\n",
      "The directory exists\n",
      "3\n",
      "The directory exists\n",
      "4\n",
      "The directory exists\n",
      "5\n",
      "The directory exists\n",
      "6\n",
      "The directory exists\n",
      "7\n",
      "The directory exists\n",
      "8\n",
      "The directory exists\n",
      "9\n",
      "The directory exists\n",
      "10\n",
      "The directory exists\n",
      "11\n",
      "The directory exists\n",
      "12\n",
      "The directory exists\n",
      "13\n",
      "The directory exists\n",
      "14\n",
      "The directory exists\n",
      "15\n",
      "The directory exists\n",
      "16\n",
      "The directory exists\n",
      "17\n",
      "The directory exists\n",
      "18\n",
      "The directory exists\n",
      "19\n",
      "The directory exists\n",
      "20\n",
      "The directory exists\n",
      "21\n",
      "The directory exists\n",
      "22\n",
      "The directory exists\n",
      "23\n",
      "The directory exists\n",
      "24\n",
      "The directory exists\n",
      "25\n",
      "The directory exists\n",
      "26\n",
      "The directory exists\n",
      "27\n",
      "The directory exists\n",
      "28\n",
      "The directory exists\n",
      "29\n",
      "The directory exists\n",
      "30\n",
      "The directory exists\n",
      "31\n",
      "The directory exists\n",
      "32\n",
      "The directory exists\n",
      "33\n",
      "The directory exists\n",
      "34\n",
      "The directory exists\n",
      "35\n",
      "The directory exists\n",
      "36\n",
      "The directory exists\n",
      "37\n",
      "The directory exists\n",
      "38\n",
      "The directory exists\n",
      "39\n",
      "The directory exists\n",
      "40\n",
      "The directory exists\n",
      "41\n",
      "The directory exists\n",
      "42\n",
      "The directory exists\n",
      "43\n",
      "The directory exists\n",
      "44\n",
      "The directory exists\n",
      "45\n",
      "The directory exists\n",
      "46\n",
      "The directory exists\n",
      "47\n",
      "The directory exists\n",
      "48\n",
      "The directory exists\n",
      "49\n",
      "The directory exists\n",
      "50\n",
      "The directory exists\n",
      "51\n",
      "The directory exists\n",
      "52\n",
      "The directory exists\n",
      "53\n",
      "The directory exists\n",
      "54\n",
      "The directory exists\n",
      "55\n",
      "The directory exists\n",
      "56\n",
      "The directory exists\n",
      "57\n",
      "The directory exists\n",
      "58\n",
      "The directory exists\n",
      "59\n",
      "The directory exists\n",
      "60\n",
      "The directory exists\n",
      "61\n",
      "The directory exists\n",
      "62\n",
      "The directory exists\n",
      "63\n",
      "The directory exists\n",
      "64\n",
      "The directory exists\n",
      "65\n",
      "The directory exists\n",
      "66\n",
      "The directory exists\n",
      "67\n",
      "The directory exists\n",
      "68\n",
      "The directory exists\n",
      "69\n",
      "The directory exists\n",
      "70\n",
      "The directory exists\n",
      "71\n",
      "The directory exists\n",
      "72\n",
      "The directory exists\n",
      "73\n",
      "The directory exists\n",
      "74\n",
      "The directory exists\n",
      "75\n",
      "The directory exists\n",
      "76\n",
      "The directory exists\n",
      "77\n",
      "The directory exists\n",
      "78\n",
      "The directory exists\n",
      "79\n",
      "The directory exists\n",
      "80\n",
      "The directory exists\n",
      "81\n",
      "The directory exists\n",
      "82\n",
      "The directory exists\n",
      "83\n",
      "The directory exists\n",
      "84\n",
      "The directory exists\n",
      "85\n",
      "The directory exists\n",
      "86\n",
      "The directory exists\n",
      "87\n",
      "The directory exists\n",
      "88\n",
      "The directory exists\n"
     ]
    }
   ],
   "source": [
    "idxHMM=2\n",
    "for idx,idxHMM in enumerate(sorted(symbolHMMDatesList)):\n",
    "    print(idx)\n",
    "    fileToCheck = os.path.join(symbolFeaturesLocation, symbolHMMDatesList[idx])\n",
    "    checkDir(fileToCheck)\n",
    "#     s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##now lets go down into each HMM-model date, and pick all the forward futures (out of sample)\n",
    "hmmFeatureLocations ={} #symbol-hmm-model-date index --> this is the indexation in symbolFeaturesDatesList\n",
    "commonDatesDict ={} # this is a struct that will contain for each HMM date, the common labels/features- this should be used for training and testing\n",
    "createDate =[] #place holder for the hash key of when the features got created\n",
    "symbolEachModelFeaturesDates ={}\n",
    "HMMModelFeaturesLabelsCommon ={} #location dictionary with 2 keys: HMM Date and Common Date\n",
    "commonDates =[]\n",
    "\n",
    "LocDictsList=[]\n",
    "\n",
    "#this symbolFeaturesDatesList[featrsIdx] will give you a date: 20170710 =which contains all the HMM induced featureb\n",
    "for hmmDateIdx, hmmDate in enumerate(sorted(symbolHMMDatesList)):\n",
    "    \n",
    "    symbolModelFeaturesDate = os.path.join(symbolFeaturesLocation, symbolHMMDatesList[hmmDateIdx])\n",
    "    createDate = os.listdir(symbolModelFeaturesDate)[0].split(\"_\")[7] #stupid hack\n",
    "#     #output looks like this: /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20170710\n",
    "    symbolEachModelFeaturesDates[symbolHMMDatesList[hmmDateIdx]]=[file.split(\"_\")[5] for file in os.listdir(symbolModelFeaturesDate )] \n",
    "#      #output is a dictionary where the keys are the HMM models dates and the values a list of dates - for each HMM date we have a list of features\n",
    "    \n",
    "    for keyHMMDate in sorted(list(symbolEachModelFeaturesDates.keys())): # for each of the HMM model dates\n",
    "        print(keyHMMDate)\n",
    "        EachModelFeaturesDates = set(symbolEachModelFeaturesDates[keyHMMDate])\n",
    "        commonDates=(list(EachModelFeaturesDates & set(symbolLabelsDates)))  \n",
    "        #take the list of feature dates (conditional on HMM model date) + the list of labels -intersection!\n",
    "        \n",
    "        ''' we now produce a dict for each HMM model, where each value is a list of common dates and we are key-ed by the HMM Date'''\n",
    "        commonDatesDict[keyHMMDate] = commonDates \n",
    "        for commonDate in commonDates:\n",
    "            ''' iterate through all the common dates and figure out the location of each file for labels and features'''\n",
    "            labelsCommonFileLoc = \"/\".join((symbolLabelsLocation, \".\".join((commonDate,'csv'))))\n",
    "#             comnDateFeatureLocMaster = os.path.join((symbolModelFeaturesDate, commonDate))\n",
    "            commonDatesFeatureFile = \"\".join((symbols[symbolIdx],'_3_states_features_date:_',commonDate,\"_now:_\",createDate,\"_.pickle\"))\n",
    "            FeatureFileLoc = os.path.join(symbolModelFeaturesDate,commonDatesFeatureFile)\n",
    "            checkDir(FeatureFileLoc)\n",
    "            checkDir(labelsCommonFileLoc)\n",
    "            conditions=[os.path.exists(FeatureFileLoc), os.path.exists(labelsCommonFileLoc)]\n",
    "            print(conditions)            \n",
    "            if all(conditions)== True:\n",
    "                print('all good on Date:', commonDate)\n",
    "                HMMModelFeaturesLabelsCommon[keyHMMDate, commonDate] =[FeatureFileLoc,labelsCommonFileLoc ]\n",
    "                hmmFeatureLocations[keyHMMDate, commonDate] =FeatureFileLoc\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                print('problem on date: ', commonDate)\n",
    "                continue \n",
    "\n",
    "LocDictsList = [commonDatesDict, HMMModelFeaturesLabelsCommon, hmmFeatureLocations]\n",
    "LocDictsListFile = \"/\".join((MKLSymbolPath,\"LocDictsList.pkl\"))\n",
    "pkl.dump( LocDictsList, open( LocDictsListFile, \"wb\" ) )    # dump it all in the same location    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# #     commonDates =list(set(symbolEachModelFeaturesDates) & set(symbolLabelsDates)) # this is a list of features and labels dates\n",
    "# #     HMMModelFeaturesLabelsCommon[hmmDate] = commonDates\n",
    "# for HMMDate, commonDate in zip(symbolHMMDatesList,commonDates):\n",
    "#     print(HMMDate, commonDate)\n",
    "# #     print(HMMModelFeaturesLabelsCommon[HMMDate,commonDate])\n",
    "\n",
    "len(EachModelFeaturesDates)\n",
    "len(sorted(symbolHMMDatesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for HMMdate in np.sort(symbolHMMDatesList):\n",
    "#     print(len(list(commonDatesDict[HMMdate])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardDates(idxKey, commonLocs):\n",
    "    ''' return all the forward looking dates for each idxKey we use for training'''\n",
    "    keys =list(commonLocs.keys()) #this produces a list with 2 keys -first HMM Symbol Date and common Date\n",
    "    lookAheadKeys = sorted(i for i in keys if i>keys[idxKey])\n",
    "    return dict((k, commonLocs[k]) for k in lookAheadKeys )\n",
    "\n",
    "def featureCreation(locDict, idxKey):\n",
    "    ''' gives out clean features and labels for a given locDict and a idxKey '''\n",
    "    keys=list(locDict.keys())\n",
    "    featuresIdxDirFileLoc= locDict[keys[idxKey]][0]\n",
    "    labelsIdxDirFileLoc= locDict[keys[idxKey]][1]\n",
    "    ''' read the features file'''\n",
    "    featuresTupleFile = pickle.load(open(featuresIdxDirFileLoc,\"rb\"), encoding='latin1') \n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1],\\\n",
    "                                                 featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "    labelsDf=pd.read_csv(labelsIdxDirFileLoc)\n",
    "    ''' pop the labels out'''\n",
    "    labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] \n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[ labelName])\n",
    "    arrX = np.array(dfX)\n",
    "    ''' feature normalisation'''\n",
    "    #feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    X = normalization(rescale_01(arrX))\n",
    "    y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "    ''' returns features, labels'''\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('20170116', '20170717')\n"
     ]
    }
   ],
   "source": [
    "### testing ###\n",
    "keys =sorted(list(HMMModelFeaturesLabelsCommon.keys())) #make a sorted list of all the locations\n",
    "idxKey=22 #pick a key\n",
    "print(keys[idxKey]) #print that key\n",
    "sorted(i for i in keys if i>keys[idxKey])\n",
    "forwardDatesKeysList =list(forwardDates(idxKey = 22, commonLocs=HMMModelFeaturesLabelsCommon).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20170717_now:_20181229_.pickle\n"
     ]
    }
   ],
   "source": [
    "checkDir(HMMModelFeaturesLabelsCommon[keys[idxKey]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this to store commonLocs in the appropriate folder\n",
    "commonLocsSymbolPath = os.path.join(MKLSymbolPath, 'commonLocs.pickle')\n",
    "with open(commonLocsSymbolPath, 'wb') as handle:\n",
    "    pickle.dump(commonLocs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(commonLocsSymbolPath, 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "commonLocs == b # simple check- delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Functions for Training Set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the keys the model fitting key - can use something like this to test?!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing above##\n",
    "forwardDatesDict = forwardDates(idxKey = 3, commonLocs=commonLocs)\n",
    "for forwardDateKey in list(forwardDatesDict.keys()):\n",
    "    checkDir(forwardDatesDict[forwardDateKey][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do Training of 3 models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingIdxKey =2\n",
    "\n",
    "Xtr, ytr =  featureCreation(locDict = commonLocs, idxKey =trainingIdxKey)\n",
    "\n",
    "print('checking shapes',Xtr.shape[0]==ytr.shape[0])\n",
    "if (Xtr.shape[0]==ytr.shape[0]):\n",
    "    print('Shapes Match- starting training ')\n",
    "    ##polynomial Kernels ##\n",
    "    KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "    ''' Compute RBF Kernels'''\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "\n",
    "    ### and train 3 classifiers ###\n",
    "    clf = AverageMKL().fit(KLtr,ytr) #a wrapper for averaging kernels\n",
    "    print(clf.weights) #print the weights of the combination of base kernels\n",
    "    print ('training EasyMKL...for polynomials and RBF', end='')\n",
    "    clfEasy = EasyMKL(lam=0.1).fit(KLtr,ytr)#combining kernels with the EasyMKL algorithm\n",
    "    clfRBF = EasyMKL(lam=0.1).fit(ker_list,ytr)  \n",
    "    print('finished training')     \n",
    "else:\n",
    "    print('Shapes dont match.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(trainingIdxKey+1,trainingIdxKey+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testKernelsPolyn ={}\n",
    "testKernelsRBF ={}\n",
    "\n",
    "\n",
    "forwardDatesDict = forwardDates(trainingIdxKey, commonLocs)\n",
    "testingIdxKey =13 #need to print the date to be precise here\n",
    "for testingIdxKey in range(trainingIdxKey+1,trainingIdxKey+5):\n",
    "    Xte, Yte=featureCreation(forwardDatesDict , testingIdxKey)\n",
    "    print('checking shapes',Xte.shape[0]==Yte.shape[0])\n",
    "    if (Xte.shape[0]==Yte.shape[0]):\n",
    "        ##polynomial Kernels ##\n",
    "        print('Computing test case')\n",
    "        KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "        ''' Compute RBF Kernels'''\n",
    "        gamma_range = np.logspace(-9, 3, 13)\n",
    "        ker_list_te = [rbf_kernel(Xte, gamma=g) for g in gamma_range]\n",
    "        testKernelsPolyn[testingIdxKey] =[KLte, Yte]\n",
    "        testKernelsRBF[testingIdxKey] =[ker_list_te, Yte]\n",
    "    else:\n",
    "        print('Shapes Dont match- move to next date')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Kernel Testing')\n",
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "fprAverage, tprAverage, thresholdsAverage = roc_curve(Yte.ravel(), y_score.ravel())\n",
    "roc_auc = auc(fprAverage, tprAverage)\n",
    "\n",
    "''' Test Linear'''\n",
    "print('MKL-Linear Testing')\n",
    "y_predMKLLinear = clfEasy.predict(KLte)                 #predictions\n",
    "y_scoreMKLLinear = clfEasy.decision_function(KLte)  #rank\n",
    "\n",
    "accuracy_MKLLinear = accuracy_score(Yte, y_predMKLLinear)\n",
    "roc_auc_MKLLinear = roc_auc_score(Yte, y_scoreMKLLinear)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy_MKLLinear, roc_auc_MKLLinear))\n",
    "\n",
    "fprLinear, tprLinear, thresholds = roc_curve(Yte.ravel(), y_scoreMKLLinear.ravel())\n",
    "\n",
    "roc_auc_Linear = auc(fprLinear, tprLinear)\n",
    "\n",
    "# fprMKLLinear, fprMKLLinear, thresholdsRBF =roc_curve(Yte, y_scoreMKLLinear)\n",
    "\n",
    "print(roc_auc_Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_model_results= {\n",
    "    'clfs': np.empty((M, T)),\n",
    "    'test_F1': np.empty((M, T)),\n",
    "    'data_date': np.empty((M, T)),\n",
    "    'test_recall': np.empty((M, T)),\n",
    "    'train_recall': np.empty((M, T)),\n",
    "    'test_accuracy' :np.empty((M, T)),\n",
    "    'train_accuracy' :np.empty((M, T)),\n",
    "}\n",
    "    _model_results['test_accuracy'][_idx, :] = accuracy_score(y_test, y_predict)\n",
    "    _model_results['test_recall'][_idx, :] = recall_score(y_true=y_test, y_pred=y_predict)\n",
    "    _model_results['train_accuracy'][_idx, :] = accuracy_score(y_train, y_predict_train)\n",
    "    _model_results['train_recall'][_idx, :] = recall_score(y_true=y_train, y_pred=y_predict_train)\n",
    "    _model_results['test_F1'][_idx, :]=f1_score(y_true=y_test, y_pred=y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(fprAverage, tprAverage, color='darkred',label='Average Kernel')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot(fprLinear, tprLinear, color='orange',label='MKL Polyn')\n",
    "plt.legend(loc=\"lower right\")\n",
    "lw=2\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='orange', lw=lw, linestyle='-',label='ROC curve (area = %0.2f)' % roc_auc_Linear)\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example (MKL)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for idxKey, commonDate in #enumerate(commonLocs.keys()):\n",
    "for idxKey in range(3):\n",
    "   \n",
    "        print('Doing key:')\n",
    "        print(keys[idxKey])\n",
    "        ''' locations'''\n",
    "        featuresIdxDirFileLoc= commonLocs[keys[idxKey]][0]\n",
    "        labelsIdxDirFileLoc= commonLocs[keys[idxKey]][1]  \n",
    "\n",
    "        featuresTupleFile = pickle.load(open(featuresIdxDirFileLoc,\"rb\"), encoding='latin1')   \n",
    "        ''' read the labels file'''\n",
    "        labelsDf=pd.read_csv(labelsIdxDirFileLoc)\n",
    "        ''' take in the input file'''\n",
    "        dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1],\\\n",
    "                                                     featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "        #take the labels out\n",
    "        labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] \n",
    "        print ('preprocessing data...', end='')\n",
    "        '''dataframe of Features and Labels - X and Y'''\n",
    "        dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "        labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "        ''' drop the labels from the features'''\n",
    "        dfX = dfXY.drop(columns=[ labelName])\n",
    "        print(\"Shape of dfX..\",dfX.shape[0])   \n",
    "        ''' MKL stuff- convert the Dataframe into an array'''\n",
    "        arrX = np.array(dfX)\n",
    "        ''' feature normalisation'''\n",
    "         #feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "        X = normalization(rescale_01(arrX))\n",
    "        print (X.shape,'done')\n",
    "\n",
    "        y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "        print(\"Shape of y..\", y.shape)\n",
    "        '''training and testing- this we can probably skip'''\n",
    "        Xtr,Xte,Ytr,Yte = train_test_split(X,y, test_size=.1, random_state=42)\n",
    "\n",
    "        '''compute homogeneous polynomial kernels with degrees 0,1,2,...,10'''\n",
    "\n",
    "        print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "\n",
    "        KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "        KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "\n",
    "        ''' Compute RBF Kernels'''\n",
    "        ### test set work ###\n",
    "        #KLtest = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "        gamma_range = np.logspace(-9, 3, 13)\n",
    "        ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "\n",
    "        print ('RBF Kernels done')\n",
    "\n",
    "        print ('training AverageMKL...', end='')\n",
    "        clf = AverageMKL().fit(KLtr,Ytr) #a wrapper for averaging kernels\n",
    "   \n",
    "        ''' need to serialise this--here'''\n",
    "        print ('done')\n",
    "        print(clf.weights) #print the weights of the combination of base kernels\n",
    "\n",
    "        print ('training EasyMKL...for polynomials and RBF', end='')\n",
    "        clfEasy = EasyMKL(lam=0.1).fit(KLtr,Ytr)#combining kernels with the EasyMKL algorithm\n",
    " \n",
    "        clfRBF = EasyMKL(lam=0.1).fit(ker_list,Ytr)  \n",
    "         \n",
    "        #lam is a hyper-parameter in [0,1]\n",
    "        print ('weights:')\n",
    "        print (clfEasy.weights)\n",
    "        print(clfRBF.weights)\n",
    "        print('Training Done')\n",
    "           \n",
    "        \n",
    "        ''' Now do the testing'''\n",
    "        try: \n",
    "            print('Average Kernel Testing')\n",
    "            y_pred = clf.predict(KLte)                 #predictions\n",
    "            y_score = clf.decision_function(KLte)      #rank\n",
    "            accuracy = accuracy_score(Yte, y_pred)\n",
    "            roc_auc = roc_auc_score(Yte, y_score)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "            ''' Test Linear'''\n",
    "            print('MKL-Linear Testing')\n",
    "            y_predTest = clfEasy.predict(KLte)                 #predictions\n",
    "            y_scoreTest = clfEasy.decision_function(KLte)      #rank\n",
    "            accuracy = accuracy_score(Yte, y_predTest)\n",
    "            roc_auc = roc_auc_score(Yte, y_scoreTest)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "            '''Test RBF'''\n",
    "            print('MKL-RBF Testing')\n",
    "            y_predRBF = clfRBF.predict(KLte)                 #predictions\n",
    "            y_scoreRBF = clfRBF.decision_function(KLte)      #rank\n",
    "            accuracyRBF = accuracy_score(Yte, y_predRBF)\n",
    "            roc_aucRBF = roc_auc_score(Yte, y_scoreRBF)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracyRBF, roc_aucRBF))\n",
    "        except IndexError: #  catch the error      \n",
    "            continue# pass will basically ignore it\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDirectory = os.getcwd()\n",
    "# save the model to disk\n",
    "filename = os.path.join(testDirectory,'test_MKL_model.pkl')\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick up the train features ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data + standarise ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =StandardScaler().fit_transform(dfX)\n",
    "y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX = StandardScaler().fit_transform(dfTestXY)\n",
    "# testY = dfTestXY[dfTestXY.columns[dfTestXY.columns.str.contains(pat='label')]].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Classifiers for Comparison ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_binarised = label_binarize(y, classes=[0, 1])\n",
    "n_classes = y_binarised.shape[1]\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Yte[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Yte.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#    y_score = clf.decision_function(KLte)      #rank\n",
    "#     accuracy = accuracy_score(Yte, y_pred)\n",
    "#     roc_auc = roc_auc_score(Yte, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds =roc_curve(Yte, y_score)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fprRBF, tprRBF, thresholdsRBF =roc_curve(Yte, y_scoreRBF)\n",
    "\n",
    "roc_aucRBF = auc(fprRBF, tprRBF)\n",
    "print(roc_aucRBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(fpr, tpr, color='darkred',)\n",
    "plt.plot(fprRBF, tprRBF, color='darkorange',)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_aucRBF)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example (MKL)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRBF = clfRBF.predict(KLte)                 #predictions\n",
    "y_scoreRBF = clfRBF.decision_function(KLte)      #rank\n",
    "accuracyRBF = accuracy_score(Yte, y_predRBF)\n",
    "roc_aucRBF = roc_auc_score(Yte, y_scoreRBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying MKL for the very first time ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "arrX = np.array(dfX)\n",
    "X = rescale_01(arrX) #feature scaling in [0,1]\n",
    "X = normalization(rescale_01(arrX))\n",
    "Y=y\n",
    "print(X.shape, y.shape)\n",
    "# ## test set\n",
    "arrTestX = np.array(dfTestX)\n",
    "TestX = rescale_01(arrTestX) #feature scaling in [0,1]\n",
    "TestX = normalization(rescale_01(arrTestX))\n",
    "TestY=testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the date into training and testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte = train_test_split(X,Y, test_size=.55, random_state=42)\n",
    "print (X.shape,'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "print ('RBF Kernels done')\n",
    "### test set work ###\n",
    "KLtest = [pairwise.homogeneous_polynomial_kernel(TestX,Xtr, degree=d) for d in range(4)]\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, y_train)\n",
    "classifier = SVC(kernel='linear', C=0.01)\n",
    "linear_clf=classifier.fit(Xtr, Ytr)\n",
    "# Create a SVC classifier using an RBF kernel\n",
    "rbf_classifier= SVC(kernel='rbf', random_state=0, gamma=1000, C=1000)\n",
    "rbf_clf=rbf_classifier.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr) #a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights) #print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix #the combined kernel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfRBF = clf = AverageMKL().fit(ker_list,Ytr) #a wrapper for averaging kernels\n",
    "K_average_rbf = clfRBF.ker_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKaverage =pd.DataFrame(K_average)\n",
    "dfKaverageRBF =pd.DataFrame(K_average_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_=plt.matshow(dfKaverage, fignum=100)\n",
    "plt.gca().set_aspect('auto')\n",
    "plt.title(' K-average matrix' ,y=1.18)\n",
    "plt.show()\n",
    "plt.matshow(dfKaverageRBF, fignum=100)\n",
    "plt.gca().set_aspect('auto')\n",
    "_=plt.title('K-average RBF matrix', y=1.18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)#combining kernels with the EasyMKL algorithm\n",
    "clfEasyRBF = EasyMKL(lam=0.1).fit(ker_list,Ytr)\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(clfEasyRBF.weights)\n",
    "plt.show()\n",
    "_=plt.hist (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeights =pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfweights = pd.DataFrame(clfEasyRBF.weights) # pd.DataFrame(dict(rate=np.random.randn(10000)))\n",
    "dfweights2 = pd.DataFrame(clf.weights) #pd.DataFrame(dict(rate=np.random.randn(10000)))\n",
    "dfweights.rename(columns={'0':'weights'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "_=dfweights.hist( ax=axes[0],label='RBF')\n",
    "\n",
    "_=dfweights2.hist( ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_pred_linear = linear_clf.predict(Xte)\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predTest = clf.predict(KLtest)                 #predictions\n",
    "y_scoreTest = clf.decision_function(KLtest)      #rank\n",
    "accuracy = accuracy_score(TestY, y_predTest)\n",
    "roc_auc = roc_auc_score(TestY, y_scoreTest)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.decision_function(KLtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('tuning lambda for EasyMKL...', end='')\n",
    "# base_learner = SVC(C=100)\t#simil hard-margin svm\n",
    "# best_results = {}\n",
    "# for lam in [0, 0.01, 0.1, 0.2, 0.9, 1]:#possible lambda values for the EasyMKL algorithm\n",
    "#     #MKLpy.model_selection.cross_val_predict performs the cross validation automatically, it optimizes the accuracy\n",
    "#     #the counterpart cross_val_score optimized the roc_auc_score (use score='roc_auc')\n",
    "#     #WARNING: these functions will change in the next version\n",
    "#     scores = cross_val_predict(KLtr, Ytr, EasyMKL(learner=base_learner, lam=lam), n_folds=5, score='accuracy')\n",
    "#     acc = np.mean(scores)\n",
    "# #     if not best_results or best_results['score'] < acc:\n",
    "# #         best_results = {'lam' : lam, 'score' : acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
