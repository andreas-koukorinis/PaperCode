{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "scaler = StandardScaler()\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "import pickle as pkl\n",
    "###\n",
    "\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file\n",
    "def checkDir(dirLoc):\n",
    "    print\n",
    "    if os.path.exists(dirLoc):#Checks if the dir exists\n",
    "        print(\"The directory exists\")\n",
    "    else:\n",
    "        print (\"No directory found for \"+dirLoc) #Output if no directory\n",
    "#         print\n",
    "#         os.makedirs(CheckDir)#Creates a new dir for the given name\n",
    "#         print \"Directory created for \"+CheckDir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNA.L', 'PRU.L', 'Labels', 'REL.L', 'BARC.L']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardDrivesLoc = '/media/ak/'\n",
    "hardDrivesList = os.listdir('/media/ak/')\n",
    "\n",
    "dataOnlyDrive = '/media/ak/DataOnly'  # external date only drive\n",
    "#ext_drive_loc = ('/media/ak/My Passport/Experiment Data/')\n",
    "data_dir = os.getenv('FINANCE_DATA') #internal folder with finance data \n",
    "folderList =  [s for s in os.listdir(dataOnlyDrive) if s.startswith('Dat') or s.startswith('Fin')]\n",
    "# inputDrive = data_only_drive\n",
    "# features = os.path.join(inputDrive,'features')\n",
    "# labels = os.path.join(inputDrive, 'labels')\n",
    "\n",
    "# symbols = [s for s in os.listdir(features) if s.endswith('.L')]\n",
    "folderIdx = 0\n",
    "finalLocation= \"/\".join((dataOnlyDrive,folderList[folderIdx]))\n",
    "symbols = [s for s in os.listdir(finalLocation) if s.endswith('.L')] #keep a list of the symbols\n",
    "os.listdir(finalLocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locIdx= 1 #'''WorkDrive'''\n",
    "\n",
    "selection = hardDrivesList[locIdx]\n",
    "\n",
    "selectionLoc = os.path.join(hardDrivesLoc,selection ) \n",
    "''' location of WorkDrive'''\n",
    "dataList = [s for s in os.listdir(selectionLoc) if s.startswith('Dat')]\n",
    "DataLoc = os.path.join(hardDrivesLoc,selection,dataList[1] )\n",
    "path= 'MKL_Experiments'\n",
    "MKLExpPath = os.path.join(DataLoc,path)\n",
    "#os.makedirs(os.path.join(DataLoc,path)) # run once so comment out afterwards- we can write an if statement later\n",
    "checkDir(MKLExpPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick a symbol ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRU.L\n",
      "/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED\n"
     ]
    }
   ],
   "source": [
    "##picking up a specific feature\n",
    "symbolIdx = 1 #pick one of the symbols\n",
    "#symbols[symbolIdx] -->output :PRU.L\n",
    "print(symbols[symbolIdx])\n",
    "# do a join to get the location\n",
    "symbolLocation = \"/\".join((finalLocation,symbols[symbolIdx])) \n",
    "\n",
    "# get he features now\n",
    "symbolFeaturesLocation = \"/\".join((symbolLocation,'MODEL_BASED')) # where all the HMM output is\n",
    "\n",
    "print(symbolFeaturesLocation) # <-- all the HMM model output is here, for each model there is a Date Folder and then OOS files\n",
    "MKLSymbolPath = os.path.join(MKLExpPath,symbols[symbolIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/WorkDrive/Data/MKL_Experiments/PRU.L'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.makedirs(os.path.join(MKLExpPath,symbols[symbolIdx])) #make MKL path for symbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick Features for a specific HMM MODEL Date ###\n",
    "### then move to labels ...pick the location of the labels and make a list of all the available labels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbolHMMDatesList = os.listdir(symbolFeaturesLocation) \n",
    "\n",
    "#list of all the MODEL dates we have generated features files for. each #\n",
    "# each of these dates in symbolFeaturesDates corresponds to a list of dates\n",
    "## (symbolHMMDatesList = '20170829', '20170710', '20170801', ... ]\n",
    "#location of labels : /media/ak/DataOnly/FinDataReal/Labels/[Symbol :PRU.L]/NON_DIRECTIONAL\n",
    "\n",
    "symbolLabelsLocation = \"/\".join((finalLocation, 'Labels',symbols[symbolIdx],'NON_DIRECTIONAL')) \n",
    "\n",
    "#list of all the label dates\n",
    "\n",
    "symbolLabelsDates =[dateFile.split(\".\")[0] for dateFile in os.listdir(symbolLabelsLocation)]\n",
    "\n",
    "# Output symbolLabelsDates --> ['20170704', '20180226', '20180208',...] all we are doing is going for this \n",
    "# os.listdir(symbolFeaturesLocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##now lets go down into each HMM-model date, and pick all the forward futures (out of sample)\n",
    "hmmFeatureLocations ={} #symbol-hmm-model-date index --> this is the indexation in symbolFeaturesDatesList\n",
    "commonDatesDict ={} # this is a struct that will contain for each HMM date, the common labels/features- this should be used for training and testing\n",
    "createDate =[] #place holder for the hash key of when the features got created\n",
    "\n",
    "HMMModelFeaturesLabelsCommon ={} #location dictionary with 2 keys: HMM Date and Common Date\n",
    "commonDates =[]\n",
    "\n",
    "LocDictsList=[]\n",
    "\n",
    "#this symbolFeaturesDatesList[featrsIdx] will give you a date: 20170710 =which contains all the HMM induced featureb\n",
    "for hmmDateIdx, hmmDate in enumerate(np.sort(symbolHMMDatesList)):\n",
    "    \n",
    "    symbolModelFeaturesDate = \"/\".join((symbolFeaturesLocation, symbolHMMDatesList[hmmDateIdx]))\n",
    "    createDate = os.listdir(symbolModelFeaturesDate)[0].split(\"_\")[7] #stupid hack\n",
    "#     #output looks like this: /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20170710\n",
    "\n",
    "    symbolEachModelFeaturesDates[symbolHMMDatesList[hmmDateIdx]]=[file.split(\"_\")[5] for file in os.listdir(symbolModelFeaturesDate )] \n",
    "     #output is a dictionary where the keys are the HMM dates and the values a list of dates - for each HMM date we have a list of features\n",
    "    \n",
    "    for symbolHMMDate in np.sort(list(symbolEachModelFeaturesDates.keys())): # for each of the HMM model dates\n",
    "#         print(symbolHMMDate)\n",
    "#         #take the list of feature dates (conditional on HMM model date) + the list of labels -intersection!\n",
    "        \n",
    "        commonDates=(list(set(symbolEachModelFeaturesDates[symbolHMMDate]) & set(symbolLabelsDates)))   \n",
    "        #print(len(commonDates))\n",
    "        ''' we now produce a dict for each HMM model, where each value is a list of common dates and we are key-ed by the HMM Date'''\n",
    "        commonDatesDict[symbolHMMDate] = commonDates \n",
    "#         print('###############')\n",
    "        for commonDate in commonDates:\n",
    "        ''' iterate through all the common dates and figure out the location of each file for labels and features'''\n",
    "            labelsCommonFileLoc = \"/\".join((symbolLabelsLocation, \".\".join((commonDate,'csv'))))\n",
    "            comnDateFeatureLocMaster =(\"/\".join((symbolFeaturesLocation, hmmDate)))\n",
    "            commonDatesFeatureFile = \"\".join((symbols[1],'_3_states_features_date:_',commonDate,\"_now:_\",createDate,\"_.pickle\"))\n",
    "            FeatureFileLoc = \"/\".join((comnDateFeatureLocMaster,commonDatesFeatureFile))\n",
    "            if os.path.exists(comnDateFeatureLocMaster) == True:\n",
    "                HMMModelFeaturesLabelsCommon[symbolHMMDate, commonDate] =[FeatureFileLoc,labelsCommonFileLoc ]\n",
    "                hmmFeatureLocations[symbolHMMDate, commonDate] =FeatureFileLoc\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                continue \n",
    "\n",
    "LocDictsList = [commonDatesDict, HMMModelFeaturesLabelsCommon, hmmFeatureLocations]\n",
    "LocDictsListFile = \"/\".join((MKLSymbolPath,\"LocDictsList.pkl\"))\n",
    "pkl.dump( LocDictsList, open( LocDictsListFile, \"wb\" ) )    # dump it all in the same location    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #     commonDates =list(set(symbolEachModelFeaturesDates) & set(symbolLabelsDates)) # this is a list of features and labels dates\n",
    "# #     HMMModelFeaturesLabelsCommon[hmmDate] = commonDates\n",
    "# for HMMDate, commonDate in zip(symbolHMMDatesList,commonDates):\n",
    "#     print(HMMDate, commonDate)\n",
    "# #     print(HMMModelFeaturesLabelsCommon[HMMDate,commonDate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for HMMdate in np.sort(symbolHMMDatesList):\n",
    "#     print(len(list(commonDatesDict[HMMdate])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardDates(idxKey, commonLocs):\n",
    "    ''' return all the forward looking dates for each idxKey we use for training'''\n",
    "    keys =list(commonLocs.keys())\n",
    "    lookAheadKeys = sorted(i for i in keys if i>keys[idxKey])\n",
    "    return dict((k, commonLocs[k]) for k in lookAheadKeys )\n",
    "\n",
    "def featureCreation(locDict, idxKey):\n",
    "    ''' gives out clean features and labels for a given locDict and a idxKey '''\n",
    "    keys=list(locDict.keys())\n",
    "    featuresIdxDirFileLoc= locDict[keys[idxKey]][0]\n",
    "    labelsIdxDirFileLoc= locDict[keys[idxKey]][1]\n",
    "    ''' read the features file'''\n",
    "    featuresTupleFile = pickle.load(open(featuresIdxDirFileLoc,\"rb\"), encoding='latin1') \n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1],\\\n",
    "                                                 featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "    labelsDf=pd.read_csv(labelsIdxDirFileLoc)\n",
    "    ''' pop the labels out'''\n",
    "    labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] \n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[ labelName])\n",
    "    arrX = np.array(dfX)\n",
    "    ''' feature normalisation'''\n",
    "    #feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    X = normalization(rescale_01(arrX))\n",
    "    y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "    ''' returns features, labels'''\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this to store commonLocs in the appropriate folder\n",
    "commonLocsSymbolPath = os.path.join(MKLSymbolPath, 'commonLocs.pickle')\n",
    "with open(commonLocsSymbolPath, 'wb') as handle:\n",
    "    pickle.dump(commonLocs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(commonLocsSymbolPath, 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "commonLocs == b # simple check- delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Functions for Training Set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the keys the model fitting key - can use something like this to test?!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180205_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180206_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180207_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180208_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180209_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180212_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180213_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180214_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180215_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180216_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180219_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180220_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180221_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180222_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180223_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180226_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180227_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180228_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180403_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180404_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180405_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180406_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180409_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180410_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180411_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180412_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180413_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180416_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180417_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180418_now:_20181229_.pickle\n",
      "No directory found for /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20180419/PRU.L_3_states_features_date:_20180419_now:_20181229_.pickle\n",
      "The directory exists\n"
     ]
    }
   ],
   "source": [
    "## testing above##\n",
    "forwardDatesDict = forwardDates(idxKey = 3, commonLocs=commonLocs)\n",
    "for forwardDateKey in list(forwardDatesDict.keys()):\n",
    "    checkDir(forwardDatesDict[forwardDateKey][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170829',\n",
       " '20170710',\n",
       " '20170801',\n",
       " '20170120',\n",
       " '20170724',\n",
       " '20170802',\n",
       " '20170727',\n",
       " '20170725',\n",
       " '20180202',\n",
       " '20180212',\n",
       " '20170803',\n",
       " '20180416',\n",
       " '20180417',\n",
       " '20170808',\n",
       " '20180405',\n",
       " '20170811',\n",
       " '20170719',\n",
       " '20180215',\n",
       " '20170821',\n",
       " '20170117',\n",
       " '20170726',\n",
       " '20180223',\n",
       " '20180406',\n",
       " '20170818',\n",
       " '20170718',\n",
       " '20170713',\n",
       " '20180201',\n",
       " '20170705',\n",
       " '20180228',\n",
       " '20180221',\n",
       " '20180220',\n",
       " '20170720',\n",
       " '20180403',\n",
       " '20180419',\n",
       " '20170711',\n",
       " '20170119',\n",
       " '20170118',\n",
       " '20170831',\n",
       " '20170814',\n",
       " '20170301',\n",
       " '20170728',\n",
       " '20180205',\n",
       " '20170712',\n",
       " '20180213',\n",
       " '20180418',\n",
       " '20170706',\n",
       " '20170707',\n",
       " '20180209',\n",
       " '20180208',\n",
       " '20170126',\n",
       " '20170116',\n",
       " '20180219',\n",
       " '20170123',\n",
       " '20170125',\n",
       " '20180409',\n",
       " '20170815',\n",
       " '20180404',\n",
       " '20170804',\n",
       " '20180207',\n",
       " '20170823',\n",
       " '20170830',\n",
       " '20180411',\n",
       " '20170824',\n",
       " '20170825',\n",
       " '20170807',\n",
       " '20180227',\n",
       " '20170704',\n",
       " '20170124',\n",
       " '20170731',\n",
       " '20180206',\n",
       " '20180226',\n",
       " '20180214',\n",
       " '20170810',\n",
       " '20170809',\n",
       " '20170130',\n",
       " '20170817',\n",
       " '20170131',\n",
       " '20180412',\n",
       " '20170714',\n",
       " '20170703',\n",
       " '20180413',\n",
       " '20170816',\n",
       " '20170721',\n",
       " '20170127',\n",
       " '20180410',\n",
       " '20180216',\n",
       " '20170717',\n",
       " '20180222',\n",
       " '20170822']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do Training of 3 models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingIdxKey =2\n",
    "\n",
    "Xtr, ytr =  featureCreation(locDict = commonLocs, idxKey =trainingIdxKey)\n",
    "\n",
    "print('checking shapes',Xtr.shape[0]==ytr.shape[0])\n",
    "if (Xtr.shape[0]==ytr.shape[0]):\n",
    "    print('Shapes Match- starting training ')\n",
    "    ##polynomial Kernels ##\n",
    "    KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "    ''' Compute RBF Kernels'''\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "\n",
    "    ### and train 3 classifiers ###\n",
    "    clf = AverageMKL().fit(KLtr,ytr) #a wrapper for averaging kernels\n",
    "    print(clf.weights) #print the weights of the combination of base kernels\n",
    "    print ('training EasyMKL...for polynomials and RBF', end='')\n",
    "    clfEasy = EasyMKL(lam=0.1).fit(KLtr,ytr)#combining kernels with the EasyMKL algorithm\n",
    "    clfRBF = EasyMKL(lam=0.1).fit(ker_list,ytr)  \n",
    "    print('finished training')     \n",
    "else:\n",
    "    print('Shapes dont match.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(trainingIdxKey+1,trainingIdxKey+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testKernelsPolyn ={}\n",
    "testKernelsRBF ={}\n",
    "\n",
    "\n",
    "forwardDatesDict = forwardDates(trainingIdxKey, commonLocs)\n",
    "testingIdxKey =13 #need to print the date to be precise here\n",
    "for testingIdxKey in range(trainingIdxKey+1,trainingIdxKey+5):\n",
    "    Xte, Yte=featureCreation(forwardDatesDict , testingIdxKey)\n",
    "    print('checking shapes',Xte.shape[0]==Yte.shape[0])\n",
    "    if (Xte.shape[0]==Yte.shape[0]):\n",
    "        ##polynomial Kernels ##\n",
    "        print('Computing test case')\n",
    "        KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "        ''' Compute RBF Kernels'''\n",
    "        gamma_range = np.logspace(-9, 3, 13)\n",
    "        ker_list_te = [rbf_kernel(Xte, gamma=g) for g in gamma_range]\n",
    "        testKernelsPolyn[testingIdxKey] =[KLte, Yte]\n",
    "        testKernelsRBF[testingIdxKey] =[ker_list_te, Yte]\n",
    "    else:\n",
    "        print('Shapes Dont match- move to next date')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Kernel Testing')\n",
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "fprAverage, tprAverage, thresholdsAverage = roc_curve(Yte.ravel(), y_score.ravel())\n",
    "roc_auc = auc(fprAverage, tprAverage)\n",
    "\n",
    "''' Test Linear'''\n",
    "print('MKL-Linear Testing')\n",
    "y_predMKLLinear = clfEasy.predict(KLte)                 #predictions\n",
    "y_scoreMKLLinear = clfEasy.decision_function(KLte)  #rank\n",
    "\n",
    "accuracy_MKLLinear = accuracy_score(Yte, y_predMKLLinear)\n",
    "roc_auc_MKLLinear = roc_auc_score(Yte, y_scoreMKLLinear)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy_MKLLinear, roc_auc_MKLLinear))\n",
    "\n",
    "fprLinear, tprLinear, thresholds = roc_curve(Yte.ravel(), y_scoreMKLLinear.ravel())\n",
    "\n",
    "roc_auc_Linear = auc(fprLinear, tprLinear)\n",
    "\n",
    "# fprMKLLinear, fprMKLLinear, thresholdsRBF =roc_curve(Yte, y_scoreMKLLinear)\n",
    "\n",
    "print(roc_auc_Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_model_results= {\n",
    "    'clfs': np.empty((M, T)),\n",
    "    'test_F1': np.empty((M, T)),\n",
    "    'data_date': np.empty((M, T)),\n",
    "    'test_recall': np.empty((M, T)),\n",
    "    'train_recall': np.empty((M, T)),\n",
    "    'test_accuracy' :np.empty((M, T)),\n",
    "    'train_accuracy' :np.empty((M, T)),\n",
    "}\n",
    "    _model_results['test_accuracy'][_idx, :] = accuracy_score(y_test, y_predict)\n",
    "    _model_results['test_recall'][_idx, :] = recall_score(y_true=y_test, y_pred=y_predict)\n",
    "    _model_results['train_accuracy'][_idx, :] = accuracy_score(y_train, y_predict_train)\n",
    "    _model_results['train_recall'][_idx, :] = recall_score(y_true=y_train, y_pred=y_predict_train)\n",
    "    _model_results['test_F1'][_idx, :]=f1_score(y_true=y_test, y_pred=y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(fprAverage, tprAverage, color='darkred',label='Average Kernel')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot(fprLinear, tprLinear, color='orange',label='MKL Polyn')\n",
    "plt.legend(loc=\"lower right\")\n",
    "lw=2\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='orange', lw=lw, linestyle='-',label='ROC curve (area = %0.2f)' % roc_auc_Linear)\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example (MKL)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for idxKey, commonDate in #enumerate(commonLocs.keys()):\n",
    "for idxKey in range(3):\n",
    "   \n",
    "        print('Doing key:')\n",
    "        print(keys[idxKey])\n",
    "        ''' locations'''\n",
    "        featuresIdxDirFileLoc= commonLocs[keys[idxKey]][0]\n",
    "        labelsIdxDirFileLoc= commonLocs[keys[idxKey]][1]  \n",
    "\n",
    "        featuresTupleFile = pickle.load(open(featuresIdxDirFileLoc,\"rb\"), encoding='latin1')   \n",
    "        ''' read the labels file'''\n",
    "        labelsDf=pd.read_csv(labelsIdxDirFileLoc)\n",
    "        ''' take in the input file'''\n",
    "        dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1],\\\n",
    "                                                     featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "        #take the labels out\n",
    "        labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] \n",
    "        print ('preprocessing data...', end='')\n",
    "        '''dataframe of Features and Labels - X and Y'''\n",
    "        dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "        labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "        ''' drop the labels from the features'''\n",
    "        dfX = dfXY.drop(columns=[ labelName])\n",
    "        print(\"Shape of dfX..\",dfX.shape[0])   \n",
    "        ''' MKL stuff- convert the Dataframe into an array'''\n",
    "        arrX = np.array(dfX)\n",
    "        ''' feature normalisation'''\n",
    "         #feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "        X = normalization(rescale_01(arrX))\n",
    "        print (X.shape,'done')\n",
    "\n",
    "        y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "        print(\"Shape of y..\", y.shape)\n",
    "        '''training and testing- this we can probably skip'''\n",
    "        Xtr,Xte,Ytr,Yte = train_test_split(X,y, test_size=.1, random_state=42)\n",
    "\n",
    "        '''compute homogeneous polynomial kernels with degrees 0,1,2,...,10'''\n",
    "\n",
    "        print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "\n",
    "        KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "        KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "\n",
    "        ''' Compute RBF Kernels'''\n",
    "        ### test set work ###\n",
    "        #KLtest = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "        gamma_range = np.logspace(-9, 3, 13)\n",
    "        ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "\n",
    "        print ('RBF Kernels done')\n",
    "\n",
    "        print ('training AverageMKL...', end='')\n",
    "        clf = AverageMKL().fit(KLtr,Ytr) #a wrapper for averaging kernels\n",
    "   \n",
    "        ''' need to serialise this--here'''\n",
    "        print ('done')\n",
    "        print(clf.weights) #print the weights of the combination of base kernels\n",
    "\n",
    "        print ('training EasyMKL...for polynomials and RBF', end='')\n",
    "        clfEasy = EasyMKL(lam=0.1).fit(KLtr,Ytr)#combining kernels with the EasyMKL algorithm\n",
    " \n",
    "        clfRBF = EasyMKL(lam=0.1).fit(ker_list,Ytr)  \n",
    "         \n",
    "        #lam is a hyper-parameter in [0,1]\n",
    "        print ('weights:')\n",
    "        print (clfEasy.weights)\n",
    "        print(clfRBF.weights)\n",
    "        print('Training Done')\n",
    "           \n",
    "        \n",
    "        ''' Now do the testing'''\n",
    "        try: \n",
    "            print('Average Kernel Testing')\n",
    "            y_pred = clf.predict(KLte)                 #predictions\n",
    "            y_score = clf.decision_function(KLte)      #rank\n",
    "            accuracy = accuracy_score(Yte, y_pred)\n",
    "            roc_auc = roc_auc_score(Yte, y_score)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "            ''' Test Linear'''\n",
    "            print('MKL-Linear Testing')\n",
    "            y_predTest = clfEasy.predict(KLte)                 #predictions\n",
    "            y_scoreTest = clfEasy.decision_function(KLte)      #rank\n",
    "            accuracy = accuracy_score(Yte, y_predTest)\n",
    "            roc_auc = roc_auc_score(Yte, y_scoreTest)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "            '''Test RBF'''\n",
    "            print('MKL-RBF Testing')\n",
    "            y_predRBF = clfRBF.predict(KLte)                 #predictions\n",
    "            y_scoreRBF = clfRBF.decision_function(KLte)      #rank\n",
    "            accuracyRBF = accuracy_score(Yte, y_predRBF)\n",
    "            roc_aucRBF = roc_auc_score(Yte, y_scoreRBF)\n",
    "            print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracyRBF, roc_aucRBF))\n",
    "        except IndexError: #  catch the error      \n",
    "            continue# pass will basically ignore it\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDirectory = os.getcwd()\n",
    "# save the model to disk\n",
    "filename = os.path.join(testDirectory,'test_MKL_model.pkl')\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick up the train features ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data + standarise ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =StandardScaler().fit_transform(dfX)\n",
    "y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX = StandardScaler().fit_transform(dfTestXY)\n",
    "# testY = dfTestXY[dfTestXY.columns[dfTestXY.columns.str.contains(pat='label')]].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Classifiers for Comparison ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_binarised = label_binarize(y, classes=[0, 1])\n",
    "n_classes = y_binarised.shape[1]\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Yte[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Yte.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#    y_score = clf.decision_function(KLte)      #rank\n",
    "#     accuracy = accuracy_score(Yte, y_pred)\n",
    "#     roc_auc = roc_auc_score(Yte, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds =roc_curve(Yte, y_score)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fprRBF, tprRBF, thresholdsRBF =roc_curve(Yte, y_scoreRBF)\n",
    "\n",
    "roc_aucRBF = auc(fprRBF, tprRBF)\n",
    "print(roc_aucRBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot(fpr, tpr, color='darkred',)\n",
    "plt.plot(fprRBF, tprRBF, color='darkorange',)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--',label='ROC curve (area = %0.2f)' % roc_aucRBF)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example (MKL)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRBF = clfRBF.predict(KLte)                 #predictions\n",
    "y_scoreRBF = clfRBF.decision_function(KLte)      #rank\n",
    "accuracyRBF = accuracy_score(Yte, y_predRBF)\n",
    "roc_aucRBF = roc_auc_score(Yte, y_scoreRBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying MKL for the very first time ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "arrX = np.array(dfX)\n",
    "X = rescale_01(arrX) #feature scaling in [0,1]\n",
    "X = normalization(rescale_01(arrX))\n",
    "Y=y\n",
    "print(X.shape, y.shape)\n",
    "# ## test set\n",
    "arrTestX = np.array(dfTestX)\n",
    "TestX = rescale_01(arrTestX) #feature scaling in [0,1]\n",
    "TestX = normalization(rescale_01(arrTestX))\n",
    "TestY=testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the date into training and testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte = train_test_split(X,Y, test_size=.55, random_state=42)\n",
    "print (X.shape,'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(4)]\n",
    "KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(4)]\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n",
    "print ('RBF Kernels done')\n",
    "### test set work ###\n",
    "KLtest = [pairwise.homogeneous_polynomial_kernel(TestX,Xtr, degree=d) for d in range(4)]\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train, y_train)\n",
    "classifier = SVC(kernel='linear', C=0.01)\n",
    "linear_clf=classifier.fit(Xtr, Ytr)\n",
    "# Create a SVC classifier using an RBF kernel\n",
    "rbf_classifier= SVC(kernel='rbf', random_state=0, gamma=1000, C=1000)\n",
    "rbf_clf=rbf_classifier.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr) #a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights) #print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix #the combined kernel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfRBF = clf = AverageMKL().fit(ker_list,Ytr) #a wrapper for averaging kernels\n",
    "K_average_rbf = clfRBF.ker_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKaverage =pd.DataFrame(K_average)\n",
    "dfKaverageRBF =pd.DataFrame(K_average_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_=plt.matshow(dfKaverage, fignum=100)\n",
    "plt.gca().set_aspect('auto')\n",
    "plt.title(' K-average matrix' ,y=1.18)\n",
    "plt.show()\n",
    "plt.matshow(dfKaverageRBF, fignum=100)\n",
    "plt.gca().set_aspect('auto')\n",
    "_=plt.title('K-average RBF matrix', y=1.18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)#combining kernels with the EasyMKL algorithm\n",
    "clfEasyRBF = EasyMKL(lam=0.1).fit(ker_list,Ytr)\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(clfEasyRBF.weights)\n",
    "plt.show()\n",
    "_=plt.hist (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeights =pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfweights = pd.DataFrame(clfEasyRBF.weights) # pd.DataFrame(dict(rate=np.random.randn(10000)))\n",
    "dfweights2 = pd.DataFrame(clf.weights) #pd.DataFrame(dict(rate=np.random.randn(10000)))\n",
    "dfweights.rename(columns={'0':'weights'})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "_=dfweights.hist( ax=axes[0],label='RBF')\n",
    "\n",
    "_=dfweights2.hist( ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_pred_linear = linear_clf.predict(Xte)\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predTest = clf.predict(KLtest)                 #predictions\n",
    "y_scoreTest = clf.decision_function(KLtest)      #rank\n",
    "accuracy = accuracy_score(TestY, y_predTest)\n",
    "roc_auc = roc_auc_score(TestY, y_scoreTest)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.decision_function(KLtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('tuning lambda for EasyMKL...', end='')\n",
    "# base_learner = SVC(C=100)\t#simil hard-margin svm\n",
    "# best_results = {}\n",
    "# for lam in [0, 0.01, 0.1, 0.2, 0.9, 1]:#possible lambda values for the EasyMKL algorithm\n",
    "#     #MKLpy.model_selection.cross_val_predict performs the cross validation automatically, it optimizes the accuracy\n",
    "#     #the counterpart cross_val_score optimized the roc_auc_score (use score='roc_auc')\n",
    "#     #WARNING: these functions will change in the next version\n",
    "#     scores = cross_val_predict(KLtr, Ytr, EasyMKL(learner=base_learner, lam=lam), n_folds=5, score='accuracy')\n",
    "#     acc = np.mean(scores)\n",
    "# #     if not best_results or best_results['score'] < acc:\n",
    "# #         best_results = {'lam' : lam, 'score' : acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
