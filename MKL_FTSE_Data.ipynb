{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only_drive = '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'  # external date only drive\n",
    "data_dir = os.getenv('FINANCE_DATA') #internal folder with finance data \n",
    "symbols = [s for s in os.listdir(data_dir) if s.endswith('.L')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you picked symbol:  PRU.L\n",
      "-------------\n",
      "/home/ak/FinData/PRU.L/MODEL_BASED\n",
      "-------------\n",
      "Features Dates:\n",
      "-------------\n",
      "['20180417', '20170724', '20180418', '20170713', '20170120', '20170811', '20170808', '20180406', '20180226', '20180202', '20180214', '20180404', '20180212', '20170818', '20170809', '20180201', '20170823', '20180213', '20180419', '20170130', '20170719', '20170804', '20170705', '20170117', '20170726', '20170126', '20170718', '20170810', '20170707', '20170301', '20170711', '20180227', '20170703', '20170131', '20170825', '20180221', '20180223', '20170714', '20170728', '20180206', '20170803', '20170123', '20180405', '20180413', '20170801', '20170807', '20170727', '20170821', '20170815', '20170124', '20180205', '20180403', '20180410', '20180222', '20170127', '20180228', '20170116', '20180409', '20170817', '20170829', '20170731', '20180208', '20180416', '20170119', '20170704', '20170725', '20180412', '20170721', '20180207', '20170706', '20170822', '20180216', '20170824', '20170125', '20180215', '20170118', '20170816', '20170831', '20180209', '20180219', '20170712', '20170814', '20170830', '20180411', '20170710', '20170720', '20180220', '20170802', '20170717']\n",
      "-------------\n",
      "/home/ak/FinData/PRU.L/MODEL_BASED/20180202\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "labels = os.path.join(data_dir,'Labels')\n",
    "\n",
    "idxSymbol = 1 #0,1,2, in our case\n",
    "print(\"you picked symbol: \",symbols[idxSymbol]) \n",
    "\n",
    "featuresDates = os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED') # path all the list of dates we have features for\n",
    "print('-------------')\n",
    "print(featuresDates)\n",
    "print('-------------')\n",
    "print('Features Dates:')\n",
    "print('-------------')\n",
    "featuresDateList = os.listdir(os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED')) #list of all dates with features\n",
    "print(featuresDateList)\n",
    "print('-------------')\n",
    "\n",
    "idxDate= 9 #as an example, enumerate the above list when parsing thru\n",
    "\n",
    "featuresDateItems = os.path.join(os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED'), featuresDateList[idxDate])\n",
    "#for each of the featuresDateItems, I have a set of features that needs to get matched with a set of labels and used to train an MKLSVM\n",
    "print(featuresDateItems)\n",
    "print('---------------')\n",
    "listFeaturesPickle = os.listdir(featuresDateItems) #all the features!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PRU.L_3_states_features_date:_20180403_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180404_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180208_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180412_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180215_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180226_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180227_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180213_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180406_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180409_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180416_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180228_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180411_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180417_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180212_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180418_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180405_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180413_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180214_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180206_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180420_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180419_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180216_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180205_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180207_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180209_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180220_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180222_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180219_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180221_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180223_now:_20181229_.pickle',\n",
       " 'PRU.L_3_states_features_date:_20180410_now:_20181229_.pickle']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(featuresDateList[idxDate])\n",
    "os.listdir(featuresDateItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxFeatures = 0 #placeholder for enumerator\n",
    "featuresTuple = pickle.load(open(os.path.join(featuresDateItems,listFeaturesPickle[idxFeatures]), \"rb\"), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresArray = np.asarray(pd.concat([featuresTuple[0], featuresTuple[1],\\\n",
    "                                                 featuresTuple[2], featuresTuple[3]], axis=1, sort=False).fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDate = os.path.splitext(listFeaturesPickle[idxDate])[0].split(\"_\")[5]\n",
    "#take the featuresTuple file, pick the first element and split it using \"_\", then pick the data the features were created\n",
    "\n",
    "symbolLabelDir = os.path.join(labels,symbols[idxSymbol],'NON_DIRECTIONAL') #path that has all the labels for the particular symbol, i.e all the dates\n",
    "#each day is a set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsFile = os.path.join(symbolLabelDir,labelsDate+\".csv\") # formulate the path for (as an example) the specific date we dealt with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDf= pd.read_csv(labelsFile).fillna(0) #load the dataframe and replace the NAs with zero (this is small cheat)\n",
    "labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] #just retain the column of labels please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formulate the problem\n",
    "Y_all = labels\n",
    "X_all = featuresArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape[0] == Y_all.shape[0] #check for dimensions, if False, there is a problem somewhere, prob picked wrong date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
