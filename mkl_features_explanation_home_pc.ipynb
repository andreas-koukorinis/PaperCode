{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "scaler = StandardScaler()\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.preprocessing import kernel_normalization\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics.pairwise import rbf_kernel as RBF\n",
    "import pickle as pkl\n",
    "###\n",
    "\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from MKLpy.metrics.pairwise.misc import homogeneous_polynomial_kernel as HPK_kernel\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "from yellowbrick.features import Rank1D\n",
    "from yellowbrick.datasets import load_game\n",
    "from yellowbrick.datasets import load_hobbies\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.datasets import load_occupancy\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from yellowbrick.features import FeatureImportances\n",
    "from yellowbrick.contrib.missing import MissingValuesBar\n",
    "from yellowbrick.target import ClassBalance, FeatureCorrelation\n",
    "import pandas as pd\n",
    "from yellowbrick.classifier.confusion_matrix import *\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Feature Analysis Imports \n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "from yellowbrick.features import PCADecomposition\n",
    "from yellowbrick.features import Rank1D, Rank2D \n",
    "from yellowbrick.features import RadViz \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file\n",
    "\n",
    "def featureCreation4Viz(idxKey, locDict):\n",
    "    ''' gives out clean features and labels for a given locDict and a idxKey\n",
    "        use idxKey to inser a key from the locDict keys\n",
    "        so for a particular day based on the key we get features and labels here\n",
    "        returns features, labels in one data frame\n",
    "    '''\n",
    "    keys=list(locDict.keys())\n",
    "    featuresIdxDirFileLoc= locDict[keys[idxKey]][0]\n",
    "    labelsIdxDirFileLoc= locDict[keys[idxKey]][1]\n",
    "    ''' read the features file'''\n",
    "    featuresTupleFile = pickle.load(open(featuresIdxDirFileLoc,\"rb\"), encoding='latin1') \n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1],\\\n",
    "                                                 featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "    labelsDf=pd.read_csv(labelsIdxDirFileLoc)\n",
    "    ''' pop the labels out'''\n",
    "    labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1'] \n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "#     labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "#     ''' drop the labels from the features'''\n",
    "#     dfX = dfXY.drop(columns=[ labelName])\n",
    "#     arrX = np.array(dfX)\n",
    "#     ''' feature normalisation'''\n",
    "#     #feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "#     X = normalization(rescale_01(arrX))\n",
    "#     y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "#     ''\n",
    "    return dfXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardDrivesLoc = '/media/ak/'\n",
    "dataOnlyDrive = '/media/ak/DataOnly'  # external date only drive\n",
    "ext_drive_loc = '/media/ak/My Passport/Experiment Data/'\n",
    "\n",
    "#  input drive\n",
    "inputDrive = hardDrivesLoc\n",
    "print(os.listdir(ext_drive_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Inputs '''\n",
    "folderIdx = 0\n",
    "folderList = [s for s in os.listdir(dataOnlyDrive) if s.startswith('Dat') or s.startswith('Fin')]\n",
    "finalLocation = \"/\".join((dataOnlyDrive, folderList[folderIdx]))\n",
    "symbols = [s for s in os.listdir(finalLocation) if s.endswith('.L')]  # keep a list of the symbols\n",
    "#make a table to describe the data\n",
    "# print(pd.DataFrame(symbols).to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features in Pickle Format ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking up a specific symbol\n",
    "symbolIdx = 14  # pick one of the symbols\n",
    "# symbols[symbolIdx] -->output :PRU.L\n",
    "# do a join to get the location\n",
    "print('you chose symbol:', symbols[symbolIdx])\n",
    "symbolLocation = \"/\".join((finalLocation, symbols[symbolIdx]))\n",
    "print('all your files are here:',symbolLocation)\n",
    "# # get the features now\n",
    "symbolFeaturesLocation = \"/\".join((symbolLocation, 'MODEL_BASED'))  # where all the HMM output is\n",
    "print('your features are here-in pickle format:',symbolFeaturesLocation)\n",
    "# print(symbolFeaturesLocation) # <-- all the HMM model output is here, for each model there is a Date Folder and\n",
    "# then OOS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locIdx = 1  # '''WorkDrive'''\n",
    "\n",
    "selection = os.listdir(inputDrive)[locIdx] #<-- '/media/ak/WorkDrive'\n",
    "\n",
    "selectionLoc = os.path.join(inputDrive, selection) #this has raw data in h\n",
    "print('you are picking this a work location:',selectionLoc)\n",
    "# ''' location of WorkDrive'''\n",
    "dataList = [s for s in os.listdir(selectionLoc) if s.startswith('Dat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DataLoc = os.path.join(hardDrivesLoc, selection, dataList[1]) #this contains the purely raw data\n",
    "path = 'MKLExpPath'\n",
    "MKLExpPath = os.path.join(ext_drive_loc, path)\n",
    "MKLSymbolPath = os.path.join(MKLExpPath, symbols[symbolIdx]) #unclear if this symbol exists in this path!\n",
    "# print('Location to store output of experiments:',MKLSymbolPath)\n",
    "os.listdir(MKLSymbolPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSymbolLoc= '/media/ak/My Passport/Experiment Data/MKLExpPath/RSA.L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Struct Dict that matches all your data for the same dates: labels and features!'\n",
    "HMMModelFeaturesLabelsCommon = pkl.load(open(\"/\".join((testSymbolLoc, \"LocDictsListCorrect.pkl\")), \"rb\"),\n",
    "                                                encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(HMMModelFeaturesLabelsCommon.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=29\n",
    "\n",
    "dfXY = featureCreation4Viz(i, HMMModelFeaturesLabelsCommon)\n",
    "# Xte, yte = featureCreation(i + 1, HMMModelFeaturesLabelsCommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SymbolCommonPaths =open_pickle_file(MKLSymbolPath,'LocDictsListCorrect.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= np.array([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "''' drop the labels from the features'''\n",
    "dfX = dfXY.drop(columns=[ labelName])\n",
    "arrX = np.array(dfX)\n",
    "''' feature normalisation'''\n",
    "#feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "X = normalization(rescale_01(arrX))\n",
    "y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "''' returns features, labels'''\n",
    "features =list(dfX.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical data with one-hot encoding\n",
    "X = pd.get_dummies(dfXY[features])\n",
    "\n",
    "# Convert unique classes (strings) into integers\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(dfXY[labelName])\n",
    "visualizer = PCADecomposition(scale=True, center=False, col=y)\n",
    "visualizer.fit_transform(X,y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'scale': True, 'color': y}\n",
    "visualizer = PCADecomposition(**params)\n",
    "visualizer.fit(X)\n",
    "visualizer.transform(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'scale': True, 'color': y, 'proj_dim':3}\n",
    "visualizer = PCADecomposition(**params)\n",
    "visualizer.fit(X)\n",
    "visualizer.transform(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer with the Covariance ranking algorithm \n",
    "visualizer = Rank1D(features=features, algorithm='shapiro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.show()                   # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Rank1D(algorithm='shapiro', color=[\"cadetblue\"])\n",
    "\n",
    "visualizer.fit(X, y)\n",
    "visualizer.transform(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "visualizer = CVScores(\n",
    "    GaussianNB(), cv=cv, scoring='f1_weighted', color=\"goldenrod\"\n",
    ")\n",
    "\n",
    "visualizer.fit(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer with the Covariance ranking algorithm \n",
    "visualizer = Rank2D(features=features, algorithm='covariance')\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.show()                   # Finalize and render the visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer with the Pearson ranking algorithm \n",
    "visualizer = Rank2D(features=features, algorithm='pearson')\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "locationFileName = os.path.join('/home/ak/Documents/Research/Papers/figures',str(symbols[symbolIdx])+'_Rank2D.png')\n",
    "visualizer.show(outpath=locationFileName)# Finalize and render the visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = JointPlotVisualizer(columns=\"fischer_score_dlambda\", kind=\"hexbin\")\n",
    "\n",
    "visualizer.fit_transform(X, y)        # Fit and transform the data\n",
    "visualizer.show()                     # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Plot to compare 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = JointPlotVisualizer(columns=[\"fischer_score_dlambda\", \"ksi_2_to_2\"])\n",
    "\n",
    "visualizer.fit_transform(X, y)        # Fit and transform the data\n",
    "visualizer.show()                     # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RadViz \n",
    "\n",
    "RadViz is a multivariate data visualization algorithm that plots each feature dimension uniformly around the circumference of a circle then plots points on the interior of the circle such that the point normalizes its values on the axes from the center to each arc. This mechanism allows as many dimensions as will easily fit on a circle, greatly expanding the dimensionality of the visualization. \n",
    "\n",
    "Data scientists use this method to detect separability between classes. E.g. is there an opportunity to learn from the feature set or is there just too much noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer\n",
    "\n",
    "my_title = \"RadViz for 21 Features for symbol: \"+str(symbols[symbolIdx])\n",
    "visualizer = RadViz(classes=classes, features=features,  title=my_title,size=(1080, 720))\n",
    "# Create your custom title\n",
    "\n",
    "visualizer.fit(X, y)      # Fit the data to the visualizer\n",
    "visualizer.transform(X)   # Transform the data\n",
    "visualizer.show()         # Finalize and render the visualizer\n",
    "locationFileName = os.path.join('/home/ak/Documents/Research/Papers/figures',str(symbols[symbolIdx])+'_RadViz.png')\n",
    "visualizer.show().axvline(color='r')\n",
    "visualizer.show(outpath=locationFileName)# Finalize and render the visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = plt.imread(locationFileName)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread(locationFileName)\n",
    "imgplot = plt.imshow(img)\n",
    "# radviztest=plt.imread(locationFileName)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(locationFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features.manifold import Manifold\n",
    "my_title = \"T-SNE for symbol: \"+str(symbols[symbolIdx])\n",
    "visualizer = Manifold(\n",
    "    manifold=\"tsne\", target=\"discrete\", colors=[\"red\", \"blue\"], title= my_title\n",
    ")\n",
    "visualizer.fit_transform(X, y)      # Fit the data to the visualizer\n",
    "visualizer.show()         # Finalize and render the visualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features.manifold import Manifold\n",
    "\n",
    "visualizer = Manifold(\n",
    "    manifold=\"isomap\", target=\"discrete\", colormap=\"YlOrRd\"\n",
    ")\n",
    "visualizer.fit_transform(X, y)      # Fit the data to the visualizer\n",
    "visualizer.show()         # Finalize and render the visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "visualizer = KElbowVisualizer(MiniBatchKMeans(), k=(4,12))\n",
    "\n",
    "visualizer.fit(X)\n",
    "\n",
    "visualizer.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.contrib.scatter import ScatterVisualizer\n",
    "\n",
    "visualizer = ScatterVisualizer(\n",
    "    x=\"light\", y=\"C02\", classes=classes, alpha=0.5\n",
    ")\n",
    "visualizer.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellowbrick.features.importances\n",
    "# Feature importance visualizer\n",
    "#\n",
    "# Author:  Benjamin Bengfort <benjamin@bengfort.com>\n",
    "# Created: Fri Mar 02 15:21:36 2018 -0500\n",
    "# Author:  Rebecca Bilbro <rbilbro@districtdatalabs.com>\n",
    "# Updated: Sun Jun 24 10:53:36 2018 -0500\n",
    "#\n",
    "# Copyright (C) 2018 District Data Labs\n",
    "# For license information, see LICENSE.txt\n",
    "#\n",
    "# ID: importances.py [] benjamin@bengfort.com $\n",
    "\n",
    "\"\"\"\n",
    "Implementation of a feature importances visualizer. This visualizer sits in\n",
    "kind of a weird place since it is technically a model scoring visualizer, but\n",
    "is generally used for feature engineering.\n",
    "\"\"\"\n",
    "\n",
    "##########################################################################\n",
    "## Imports\n",
    "##########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from yellowbrick.utils import is_dataframe\n",
    "from yellowbrick.base import ModelVisualizer\n",
    "from yellowbrick.exceptions import YellowbrickTypeError, NotFitted\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "## Feature Visualizer\n",
    "##########################################################################\n",
    "\n",
    "class FeatureImportances(ModelVisualizer):\n",
    "    \"\"\"\n",
    "    Displays the most informative features in a model by showing a bar chart\n",
    "    of features ranked by their importances. Although primarily a feature\n",
    "    engineering mechanism, this visualizer requires a model that has either a\n",
    "    ``coef_`` or ``feature_importances_`` parameter after fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Estimator\n",
    "        A Scikit-Learn estimator that learns feature importances. Must support\n",
    "        either ``coef_`` or ``feature_importances_`` parameters.\n",
    "\n",
    "    ax : matplotlib Axes, default: None\n",
    "        The axis to plot the figure on. If None is passed in the current axes\n",
    "        will be used (or generated if required).\n",
    "\n",
    "    labels : list, default: None\n",
    "        A list of feature names to use. If a DataFrame is passed to fit and\n",
    "        features is None, feature names are selected as the column names.\n",
    "\n",
    "    relative : bool, default: True\n",
    "        If true, the features are described by their relative importance as a\n",
    "        percentage of the strongest feature component; otherwise the raw\n",
    "        numeric description of the feature importance is shown.\n",
    "\n",
    "    absolute : bool, default: False\n",
    "        Make all coeficients absolute to more easily compare negative\n",
    "        coeficients with positive ones.\n",
    "\n",
    "    xlabel : str, default: None\n",
    "        The label for the X-axis. If None is automatically determined by the\n",
    "        underlying model and options provided.\n",
    "\n",
    "    kwargs : dict\n",
    "        Keyword arguments that are passed to the base class and may influence\n",
    "        the visualization as defined in other Visualizers.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    features_ : np.array\n",
    "        The feature labels ranked according to their importance\n",
    "\n",
    "    feature_importances_ : np.array\n",
    "        The numeric value of the feature importance computed by the model\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from sklearn.ensemble import GradientBoostingClassifier\n",
    "    >>> visualizer = FeatureImportances(GradientBoostingClassifier())\n",
    "    >>> visualizer.fit(X, y)\n",
    "    >>> visualizer.show()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, ax=None, labels=None, relative=True,\n",
    "                 absolute=False, xlabel=None, **kwargs):\n",
    "        super(FeatureImportances, self).__init__(model, ax, **kwargs)\n",
    "\n",
    "        # Data Parameters\n",
    "        self.set_params(\n",
    "            labels=labels, relative=relative, absolute=absolute,\n",
    "            xlabel=xlabel,\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fits the estimator to discover the feature importances described by\n",
    "        the data, then draws those importances as a bar plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray or DataFrame of shape n x m\n",
    "            A matrix of n instances with m features\n",
    "\n",
    "        y : ndarray or Series of length n\n",
    "            An array or series of target or class values\n",
    "\n",
    "        kwargs : dict\n",
    "            Keyword arguments passed to the fit method of the estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : visualizer\n",
    "            The fit method must always return self to support pipelines.\n",
    "        \"\"\"\n",
    "        super(FeatureImportances, self).fit(X, y, **kwargs)\n",
    "\n",
    "        # Get the feature importances from the model\n",
    "        self.feature_importances_ = self._find_importances_param()\n",
    "        \n",
    "        # Check if feature importances is a multidimensional array & if so flatten\n",
    "        if self.feature_importances_.ndim > 1:\n",
    "            self.feature_importances_ = np.mean(self.feature_importances_, axis=0)\n",
    "\n",
    "        # Apply absolute value filter before normalization\n",
    "        if self.absolute:\n",
    "            self.feature_importances_ = np.abs(self.feature_importances_)\n",
    "\n",
    "        # Normalize features relative to the maximum\n",
    "        if self.relative:\n",
    "            maxv = self.feature_importances_.max()\n",
    "            self.feature_importances_ /= maxv\n",
    "            self.feature_importances_ *= 100.0\n",
    "\n",
    "        # Create labels for the feature importances\n",
    "        # NOTE: this code is duplicated from MultiFeatureVisualizer\n",
    "        if self.labels is None:\n",
    "            # Use column names if a dataframe\n",
    "            if is_dataframe(X):\n",
    "                self.features_ = np.array(X.columns)\n",
    "\n",
    "            # Otherwise use the column index as the labels\n",
    "            else:\n",
    "                _, ncols = X.shape\n",
    "                self.features_ = np.arange(0, ncols)\n",
    "        else:\n",
    "            self.features_ = np.array(self.labels)\n",
    "\n",
    "        # Sort the features and their importances\n",
    "        sort_idx = np.argsort(self.feature_importances_)\n",
    "        self.features_ = self.features_[sort_idx]\n",
    "        self.feature_importances_ = self.feature_importances_[sort_idx]\n",
    "\n",
    "        # Draw the feature importances\n",
    "        self.draw()\n",
    "        return self\n",
    "\n",
    "    def draw(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Draws the feature importances as a bar chart; called from fit.\n",
    "        \"\"\"\n",
    "        # Quick validation\n",
    "        for param in ('feature_importances_', 'features_'):\n",
    "            if not hasattr(self, param):\n",
    "                raise NotFitted(\"missing required param '{}'\".format(param))\n",
    "\n",
    "        # Find the positions for each bar\n",
    "        pos = np.arange(self.features_.shape[0]) + 0.5\n",
    "\n",
    "        # Plot the bar chart\n",
    "        self.ax.barh(pos, self.feature_importances_, align='center')\n",
    "\n",
    "        # Set the labels for the bars\n",
    "        self.ax.set_yticks(pos)\n",
    "        self.ax.set_yticklabels(self.features_)\n",
    "\n",
    "        return self.ax\n",
    "\n",
    "    def finalize(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Finalize the drawing setting labels and title.\n",
    "        \"\"\"\n",
    "        # Set the title\n",
    "        self.set_title('Feature Importances of {} Features using {}'.format(\n",
    "                len(self.features_), self.name))\n",
    "\n",
    "        # Set the xlabel\n",
    "        self.ax.set_xlabel(self._get_xlabel())\n",
    "\n",
    "        # Remove the ygrid\n",
    "        self.ax.grid(False, axis='y')\n",
    "\n",
    "        # Ensure we have a tight fit\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def _find_importances_param(self):\n",
    "        \"\"\"\n",
    "        Searches the wrapped model for the feature importances parameter.\n",
    "        \"\"\"\n",
    "        for attr in (\"feature_importances_\", \"coef_\"):\n",
    "            try:\n",
    "                return getattr(self.estimator, attr)\n",
    "            except AttributeError:\n",
    "                continue\n",
    "\n",
    "        raise YellowbrickTypeError(\n",
    "            \"could not find feature importances param on {}\".format(\n",
    "                self.estimator.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _get_xlabel(self):\n",
    "        \"\"\"\n",
    "        Determines the xlabel based on the underlying data structure\n",
    "        \"\"\"\n",
    "        # Return user-specified label\n",
    "        if self.xlabel:\n",
    "            return self.xlabel\n",
    "\n",
    "        # Label for coefficients\n",
    "        if hasattr(self.estimator, \"coef_\"):\n",
    "            if self.relative:\n",
    "                return \"relative coefficient magnitude\"\n",
    "            return \"coefficient value\"\n",
    "\n",
    "        # Default label for feature_importances_\n",
    "        if self.relative:\n",
    "            return \"relative importance\"\n",
    "        return \"feature importance\"\n",
    "\n",
    "    def _is_fitted(self):\n",
    "        \"\"\"\n",
    "        Returns true if the visualizer has been fit.\n",
    "        \"\"\"\n",
    "        return hasattr(self, 'feature_importances_') and hasattr(self, 'features_')\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "## Quick Method\n",
    "##########################################################################\n",
    "\n",
    "def feature_importances(model, X, y=None, ax=None, labels=None,\n",
    "                        relative=True, absolute=False, xlabel=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Displays the most informative features in a model by showing a bar chart\n",
    "    of features ranked by their importances. Although primarily a feature\n",
    "    engineering mechanism, this visualizer requires a model that has either a\n",
    "    ``coef_`` or ``feature_importances_`` parameter after fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Estimator\n",
    "        A Scikit-Learn estimator that learns feature importances. Must support\n",
    "        either ``coef_`` or ``feature_importances_`` parameters.\n",
    "\n",
    "    X : ndarray or DataFrame of shape n x m\n",
    "        A matrix of n instances with m features\n",
    "\n",
    "    y : ndarray or Series of length n, optional\n",
    "        An array or series of target or class values\n",
    "\n",
    "    ax : matplotlib Axes, default: None\n",
    "        The axis to plot the figure on. If None is passed in the current axes\n",
    "        will be used (or generated if required).\n",
    "\n",
    "    labels : list, default: None\n",
    "        A list of feature names to use. If a DataFrame is passed to fit and\n",
    "        features is None, feature names are selected as the column names.\n",
    "\n",
    "    relative : bool, default: True\n",
    "        If true, the features are described by their relative importance as a\n",
    "        percentage of the strongest feature component; otherwise the raw\n",
    "        numeric description of the feature importance is shown.\n",
    "\n",
    "    absolute : bool, default: False\n",
    "        Make all coeficients absolute to more easily compare negative\n",
    "        coeficients with positive ones.\n",
    "\n",
    "    xlabel : str, default: None\n",
    "        The label for the X-axis. If None is automatically determined by the\n",
    "        underlying model and options provided.\n",
    "\n",
    "    kwargs : dict\n",
    "        Keyword arguments that are passed to the base class and may influence\n",
    "        the visualization as defined in other Visualizers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : matplotlib axes\n",
    "        Returns the axes that the parallel coordinates were drawn on.\n",
    "    \"\"\"\n",
    "    # Instantiate the visualizer\n",
    "    visualizer = FeatureImportances(\n",
    "        model, ax, labels, relative, absolute, xlabel, **kwargs)\n",
    "\n",
    "    # Fit and transform the visualizer (calls draw)\n",
    "    visualizer.fit(X, y)\n",
    "    visualizer.finalize()\n",
    "\n",
    "    # Return the axes object on the visualizer\n",
    "    return visualizer.ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_importances = FeatureImportances(LogisticRegression())\n",
    "lr_importances.fit(X,y)\n",
    "lr_importances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_importances = FeatureImportances(LogisticRegression(), absolute=True)\n",
    "lr_importances.fit(X,y)\n",
    "lr_importances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "colors = [\"lightpink\", \"pink\", \"hotpink\", \"crimson\", \"orchid\"]\n",
    "viz = FeatureImportances(model, colors=colors)\n",
    "viz.fit(X, y)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = OrdinalEncoder().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "model = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\n",
    "viz = FeatureImportances(model, stack=True, relative=False)\n",
    "viz.fit(X, y)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_title = \"Class Balance: \"+str(symbols[symbolIdx])\n",
    "visualizer = ClassBalance(\n",
    "    labels=classes,\n",
    "    colors=[\"teal\", \"blue\"], title=my_title\n",
    ")\n",
    "locationFileName = os.path.join('/home/ak/Documents/Research/Papers/figures',str(symbols[symbolIdx])+'_ClassBalance.png')\n",
    "#viz.fit(X, y)\n",
    "visualizer.fit(y)\n",
    "visualizer.show(outpath=locationFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ClassBalance(\n",
    "    labels=classes,\n",
    "    colormap=\"copper\"\n",
    ")\n",
    "\n",
    "visualizer.fit(y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = FeatureCorrelation(labels=features, color=\"rebeccapurple\")\n",
    "\n",
    "visualizer.fit(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Methods ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernelmethods import PolyKernel, GaussianKernel, LinearKernel\n",
    "\n",
    "poly = PolyKernel(degree=4)\n",
    "rbf = GaussianKernel()\n",
    "linear = LinearKernel()\n",
    "# you can print/present then in many ways\n",
    "print(poly)\n",
    "print(rbf)\n",
    "print(linear)\n",
    "repr(rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernelmethods import KernelMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KernelMatrix(rbf)\n",
    "km_linear = KernelMatrix(linear)\n",
    "km_poly = KernelMatrix(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.attach_to(X)\n",
    "km_linear.attach_to(X)\n",
    "km_poly.attach_to(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "km.full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm \n",
    "\n",
    "plt.matshow(km_poly.full)\n",
    "\n",
    "title ='PolyKernel_'+symbols[symbolIdx]\n",
    "plt.savefig('/home/ak/Documents/Research/Papers/figures/' + str(title) + '.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(km_linear.full, cmap=plt.cm.Spectral_r, interpolation='none', vmin=0, vmax=1)\n",
    "title ='LinearKernel_'+symbols[symbolIdx]\n",
    "plt.savefig('/home/ak/Documents/Research/Papers/figures/' + str(title) + '.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_kernel_linear = sns.heatmap(km_linear.full,cmap=\"YlGnBu\", xticklabels=90, yticklabels=90)\n",
    "title ='LinearKernel_'+symbols[symbolIdx]\n",
    "fig=sns_kernel_linear.get_figure()\n",
    "fig.savefig('/home/ak/Documents/Research/Papers/figures/' + str(title) + '.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_kernel_poly = sns.heatmap(km_poly.full,cmap=\"RdYlGn\", xticklabels=90, yticklabels=90)\n",
    "title ='PolyKernel_'+symbols[symbolIdx]\n",
    "fig = sns_kernel_poly.get_figure()\n",
    "fig.savefig('/home/ak/Documents/Research/Papers/figures/' + str(title) + '.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('AAL.L').split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
