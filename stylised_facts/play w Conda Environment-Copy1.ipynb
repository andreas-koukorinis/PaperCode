{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import all shogun classes\n",
    "from shogun import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ak/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import stylised_facts_data_utilities.createLOB as createLOB\n",
    "import stylised_facts_data_utilities.mmd as mmd\n",
    "import stylised_facts_data_utilities.ksd as ksd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the data in \n",
    "ActivityCLockData= '/media/ak/My Passport/Experiment Data/ActivityClockData/'\n",
    "OHLCData= '/media/ak/My Passport/Experiment Data/OHLCData/'\n",
    "folderList = os.listdir(ActivityCLockData)\n",
    "OHLCDataList = os.listdir(OHLCData)\n",
    "ActivityClockDataList = os.listdir(ActivityCLockData)\n",
    "\n",
    "symbols =['FB1','JB1','FV1','G_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol1= symbols[1]\n",
    "Symbol1ClocksData = np.sort([s for s in os.listdir(ActivityCLockData) if 'Clocks' in s and (str(symbol1)) in s])\n",
    "Symbol1tickBarDictCondensed = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/media/ak/My Passport/Experiment Data/ActivityClockData/ClocksData_JB1_Comdty_20180413_.pkl\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0df8db3e5880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpklClockFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivityCLockData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSymbol1ClocksData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpklidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpklClockFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtickBarDF\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpklClockFile\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TickBarDf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#tickbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     Symbol1tickBarDictCondensed[Symbol1ClocksData[pklidx].split('_')[3]]=tickBarDF [['BidSize', 'QuoteTime','BestBid',\n\u001b[1;32m      7\u001b[0m        \u001b[0;34m'TradeTime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AskSize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BestAsk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TradeVolume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TradedTime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "for pklidx,_ in enumerate(Symbol1ClocksData):\n",
    "    print(pklidx)\n",
    "    pklClockFile = \"\".join((ActivityCLockData,Symbol1ClocksData[pklidx]))\n",
    "    print(pklClockFile)\n",
    "    tickBarDF =pickle.load(open(pklClockFile , \"rb\"))['TickBarDf'] #tickbar\n",
    "    Symbol1tickBarDictCondensed[Symbol1ClocksData[pklidx].split('_')[3]]=tickBarDF [['BidSize', 'QuoteTime','BestBid',\n",
    "       'TradeTime', 'AskSize','BestAsk', 'TradeVolume', 'TradedTime', 'type',\n",
    "       'TradePrice', 'TimeStamp', 'milliSeconds','DollarVolume', 'MicroPrice', 'TradeSize', 'DollarVolumeTraded']]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueETFList = list(etfSymbol_to_number.values()) #converting dictionary to ETF list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "twoETFS = random.sample(set(uniqueETFList), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Pick the', twoETFS[0],' and ' ,twoETFS[1], 'symbols to play with')\n",
    "### combine symbol index with etfDir to get all the location\n",
    "for etfIdx in list(twoETFS):\n",
    "    etfSymbolFiles = os.path.join(etfDir, etfSymbols[etfIdx])\n",
    "\n",
    "    print('Symbol Location:', etfSymbolFiles)\n",
    "    ## and make a list of all the dates\n",
    "    listETFSymbolFiles = os.listdir(etfSymbolFiles)\n",
    "\n",
    "    print('Picked the following ETF: ',etfSymbols[etfIdx])\n",
    "    combinedETFfiles_A = dict()\n",
    "    for fileIdx, _ in enumerate(os.listdir(etfSymbolFiles)):\n",
    "        etfFileDate = os.listdir(etfSymbolFiles)[fileIdx]\n",
    "        fileLoc = os.path.join(etfSymbolFiles, os.listdir(etfSymbolFiles)[fileIdx])\n",
    "        combinedETFfiles_A[etfFileDate.split('.')[0]] = pd.read_csv(fileLoc)\n",
    "        for idxKey, dateKey in enumerate(etfDateKeys):\n",
    "            originalCreateLOB = createLOB.formatETFlob(combinedETFfiles_A[etfDateKeys[idxKey]])\n",
    "            microPxDict[dateKey] = originalCreateLOB['MicroPriceReturns']\n",
    "            durationsDict[dateKey] = originalCreateLOB['milliSeconds'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedETFfiles_A = dict() # combine all the files for a single ETF\n",
    "# combinedETFfiles_B = dict() # combine all the files for a single ETF\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    go through all the dates for the symbol choice above and create a location for each \n",
    "    etf symbol+ date csv and read it into a pandas dataframe then store it\n",
    "    \n",
    "    '''\n",
    "    etfFileDate = os.listdir(etfSymbolFiles)[fileIdx]\n",
    "    fileLoc = os.path.join(etfSymbolFiles, os.listdir(etfSymbolFiles)[fileIdx])\n",
    "    combinedETFfiles_A[etfFileDate.split('.')[0]] = pd.read_csv(fileLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etfDateKeys =list(combinedETFfiles_A.keys())\n",
    "print('This file has ',len(etfDateKeys), 'days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microPxDict = dict()\n",
    "durationsDict = dict()\n",
    "\n",
    "for idxKey, dateKey in enumerate(etfDateKeys):\n",
    "    originalCreateLOB = createLOB.formatETFlob(combinedETFfiles_A[etfDateKeys[idxKey]])\n",
    "    microPxDict[dateKey] = originalCreateLOB['MicroPriceReturns']\n",
    "    durationsDict[dateKey] = originalCreateLOB['milliSeconds'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConcat = pd.concat(list(microPxDict.values() ), axis =0, keys = list(microPxDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microPriceArray = dfConcat.dropna().values\n",
    "mPnonZero = microPriceArray[microPriceArray!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mPnonZero).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset =mPnonZero[0:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(subset)) < 0.55\n",
    "train = subset[msk]\n",
    "\n",
    "test = subset[~msk]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_p  =  RealFeatures(train.reshape(1,len(train)))\n",
    "features_q = RealFeatures(test.reshape(1,len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd = LinearTimeMMD()\n",
    "kernel = GaussianKernel(10, 1)\n",
    "mmd.set_kernel(kernel)\n",
    "mmd.set_p(features_p)\n",
    "mmd.set_q(features_q)\n",
    "mmd.set_num_samples_p(1000)\n",
    "mmd.set_num_samples_q(1000)\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd.set_statistic_type(ST_BIASED_FULL)\n",
    "statistic = mmd.compute_statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = mmd.compute_threshold(alpha)\n",
    "p_value = mmd.compute_p_value(statistic)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "Y = test\n",
    "plt.hist(X, alpha=0.5)\n",
    "plt.hist(Y, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_statistic(X,Y, squared=False):\n",
    "    assert X.ndim == Y.ndim == 1\n",
    "    \n",
    "    # IMPLEMENT: compute mean difference of X and Y\n",
    "    result = np.mean(X) - np.mean(Y)\n",
    "    \n",
    "    if squared:\n",
    "        result *= result\n",
    "    return result\n",
    "\n",
    "my_statistic = simple_statistic(X,Y)\n",
    "print(\"Mean differencce:\", my_statistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_permutation_test(test_statistic, X, Y, num_permutations, prog_bar=True):\n",
    "    assert X.ndim == Y.ndim\n",
    "    \n",
    "    statistics = np.zeros(num_permutations)\n",
    "    \n",
    "    range_ = range(num_permutations)\n",
    "    if prog_bar:\n",
    "        range_ = tqdm(range_)\n",
    "    for i in range_:\n",
    "        # concatenate samples\n",
    "        if X.ndim == 1:\n",
    "            Z = np.hstack((X,Y))\n",
    "        elif X.ndim == 2:\n",
    "            Z = np.vstack((X,Y))\n",
    "            \n",
    "        # IMPLEMENT: permute samples and compute test statistic\n",
    "        perm_inds = np.random.permutation(len(Z))\n",
    "        Z = Z[perm_inds]\n",
    "        X_ = Z[:len(X)]\n",
    "        Y_ = Z[len(X):]\n",
    "        my_test_statistic = test_statistic(X_, Y_)\n",
    "        statistics[i] = my_test_statistic\n",
    "    return statistics\n",
    "\n",
    "num_permutations = 200\n",
    "statistics = two_sample_permutation_test(simple_statistic, X, Y, num_permutations,prog_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_samples(null_samples, statistic=None):\n",
    "    plt.hist(null_samples)\n",
    "    plt.axvline(x=np.percentile(null_samples, 2.5), c='b')\n",
    "    legend = [\"95% quantiles\"]\n",
    "    if statistic is not None:\n",
    "        plt.axvline(x=statistic, c='r')\n",
    "        legend += [\"Actual test statistic\"]\n",
    "    plt.legend(legend)\n",
    "    plt.axvline(x=np.percentile(null_samples, 97.5), c='b')\n",
    "    plt.xlabel(\"Test statistic value\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    \n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "\n",
    "def sq_distances(X,Y=None):\n",
    "    \"\"\"\n",
    "    If Y=None, then this computes the distance between X and itself\n",
    "    \"\"\"\n",
    "    assert(X.ndim==2)\n",
    "\n",
    "    # IMPLEMENT: compute pairwise distance matrix. Don't use explicit loops, but the above scipy functions\n",
    "    # if X=Y, use more efficient pdist call which exploits symmetry\n",
    "    if Y is None:\n",
    "        sq_dists = squareform(pdist(X, 'sqeuclidean'))\n",
    "    else:\n",
    "        assert(Y.ndim==2)\n",
    "        assert(X.shape[1]==Y.shape[1])\n",
    "        sq_dists = cdist(X, Y, 'sqeuclidean')\n",
    "\n",
    "    return sq_dists\n",
    "\n",
    "def gauss_kernel(X, Y=None, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Computes the standard Gaussian kernel k(x,y)=exp(- ||x-y||**2 / (2 * sigma**2))\n",
    "\n",
    "    X - 2d array, samples on left hand side\n",
    "    Y - 2d array, samples on right hand side, can be None in which case they are replaced by X\n",
    "    \n",
    "    returns: kernel matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # IMPLEMENT: compute squared distances and kernel matrix\n",
    "    sq_dists = sq_distances(X,Y)\n",
    "    K = np.exp(-sq_dists / (2 * sigma**2))\n",
    "    return K\n",
    "\n",
    "# IMPLEMENT\n",
    "def linear_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_time_mmd(X,Y,kernel):\n",
    "    assert X.ndim == Y.ndim == 2\n",
    "    K_XX = kernel(X,X)\n",
    "    K_XY = kernel(X,Y)\n",
    "    K_YY = kernel(Y,Y)\n",
    "       \n",
    "    n = len(K_XX)\n",
    "    m = len(K_YY)\n",
    "    \n",
    "    # IMPLEMENT: unbiased MMD statistic (could also use biased, doesn't matter if we use permutation tests)\n",
    "    np.fill_diagonal(K_XX, 0)\n",
    "    np.fill_diagonal(K_YY, 0)\n",
    "    mmd = np.sum(K_XX) / (n*(n-1))  + np.sum(K_YY) / (m*(m-1))  - 2*np.sum(K_XY)/(n*m)\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kernel = lambda X,Y : gauss_kernel(X,Y,sigma=0.3)\n",
    "my_mmd = lambda X,Y : quadratic_time_mmd(X[:,np.newaxis],Y[:,np.newaxis], my_kernel)\n",
    "\n",
    "statistics = two_sample_permutation_test(my_mmd, X, Y, num_permutations, prog_bar=False)\n",
    "my_statistic = my_mmd(X,Y)\n",
    "\n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
