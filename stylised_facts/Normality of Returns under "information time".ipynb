{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ak/Documents/Research/PaperCode/stylised_facts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "try:\n",
    "    from tqdm import tqdm_notebooks as tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "###\n",
    "\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from MFDFA import fgn\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set()\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/directory/tothe/handshakefile/')\n",
    "\n",
    "# import stylised_facts_data_utilities.createLOB as createLOB\n",
    "import stylised_facts_data_utilities.gpyNARX as gpyNARX\n",
    "import stylised_facts_data_utilities.longtaildistr as longtail\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20120427.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etfDir = '/media/ak/My Passport/MarketData/ETF_Levels/'\n",
    "etfSymbols = os.listdir(etfDir)\n",
    "idx=1\n",
    "etfSymbolFiles = os.path.join(etfDir, etfSymbols[idx])\n",
    "fileIdx = 1\n",
    "fileLoc = os.path.join(etfSymbolFiles, os.listdir(etfSymbolFiles)[fileIdx])\n",
    "os.listdir(etfSymbolFiles)[fileIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>millis</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>l1_bid_size</th>\n",
       "      <th>l1_ask_size</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34200067</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.18</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>16.18</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34200067</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.18</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>16.18</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34200067</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.18</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>16.18</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34200069</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.18</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>16.18</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34200147</td>\n",
       "      <td>16.16</td>\n",
       "      <td>16.18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>16.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34200147</td>\n",
       "      <td>16.16</td>\n",
       "      <td>16.18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>16.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34200147</td>\n",
       "      <td>16.16</td>\n",
       "      <td>16.18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>16.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34200149</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.17</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>16.16</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34200163</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.17</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>16.17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34200177</td>\n",
       "      <td>16.15</td>\n",
       "      <td>16.17</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>16.15</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     millis    bid    ask  l1_bid_size  l1_ask_size  price  volume\n",
       "0  34200067  16.15  16.18           62           11  16.18     100\n",
       "1  34200067  16.15  16.18           62           11  16.18     100\n",
       "2  34200067  16.15  16.18           62           11  16.18     300\n",
       "3  34200069  16.15  16.18           62           11  16.18     100\n",
       "4  34200147  16.16  16.18            3           12  16.16     300\n",
       "5  34200147  16.16  16.18            3           12  16.16     300\n",
       "6  34200147  16.16  16.18            3           12  16.16     300\n",
       "7  34200149  16.15  16.17           66            3  16.16     300\n",
       "8  34200163  16.15  16.17           66            3  16.17     100\n",
       "9  34200177  16.15  16.17           66            3  16.15     300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile =pd.read_csv(fileLoc)\n",
    "testFile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatETFlob(df):\n",
    "    dfLOB = pd.DataFrame()\n",
    "    dfLOB['Duration'] = df['millis'].diff().values\n",
    "    dfLOB['MicroPrice'] = (df['bid']*df['l1_bid_size'] + df['ask']*df['l1_ask_size'])/(df['l1_bid_size'] + df['l1_ask_size'])\n",
    "    dfLOB['TradedPrice'] = df['price']\n",
    "    dfLOB['MicroPriceReturns'] = dfLOB['MicroPrice'].pct_change() \n",
    "    dfLOB['TradedSize'] = df['volume']\n",
    "    dfLOB = dfLOB.dropna()\n",
    "    return dfLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = formatETFlob(testFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numerical libraries\n",
    "\n",
    "from scipy import stats\n",
    "# import tableone\n",
    "try:\n",
    "    from tableone import TableOne\n",
    "except (ModuleNotFoundError, ImportError):\n",
    "    # install on Colab\n",
    "    !pip install tableone\n",
    "    from tableone import TableOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions and Investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ By moving to the tick domain, the need to force each trade into a time slot is removed as one does\n",
    "not need to force the trades into predetermined sampling points as in calendar time. Additionally, when using calendar time sampling\n",
    "\n",
    "2/ can we recover normality in each of the assets and periods?\n",
    "\n",
    "3/duration between trades is\n",
    "also added to the subordination framework to account for\n",
    "the speed with which market participants act in physical\n",
    "time.\n",
    "\n",
    "4/we bring qualitative empirical evidence that the impact of a single\n",
    "trade depends on the intertrade time lags. We find that when the trading rate be- comes faster, the return variance per trade strongly increases and that this behavior persists at coarser time scales. \n",
    "\n",
    "5/So we answer the following question: is the realized variance created by 10 trades arriving over 10 seconds similar to the realized variance created by those very same trades had they arrived during 10 minutes? Any model that uses a transaction time clock implies that the two situations are similar. Our empirical findings show that they are not, and that trades arriving in a shorter duration have higher variance, thus showing the importance of the physical inter-trade time duration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivityCLockData= '/media/ak/My Passport/Experiment Data/ActivityClockData/'\n",
    "OHLCData= '/media/ak/My Passport/Experiment Data/OHLCData/'\n",
    "folderList = os.listdir(ActivityCLockData)\n",
    "OHLCDataList = os.listdir(OHLCData)\n",
    "ActivityClockDataList = os.listdir(ActivityCLockData)\n",
    "\n",
    "symbols =['FB1','JB1','FV1','G_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolIdx=0\n",
    "pklList = list(np.sort([s for s in OHLCDataList if (str(symbols[symbolIdx])) in s and ('ohlcFile') in s]))\n",
    "combinedDF = pd.DataFrame()\n",
    "for pklIdx, _ in enumerate(pklList):\n",
    "\n",
    "    pklOHLCFile = \"\".join((OHLCData,pklList[pklIdx]))\n",
    "    combinedDF = combinedDF.append(pickle.load(open(pklOHLCFile , \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileIdx=0\n",
    "# FV1ClocksData = np.sort([s for s in os.listdir(ActivityCLockData) if 'Clocks' in s and ('FV1') in s])\n",
    "# combinedSymbolClockDF = pd.DataFrame()\n",
    "# for pklIdx, _ in enumerate(pklList):\n",
    "\n",
    "#     pklClockFile = \"\".join((ActivityCLockData,FV1ClocksData[pklIdx]))\n",
    "#     combinedSymbolClockDF = combinedSymbolClockDF.append(pickle.load(open(pklClockFile , \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FV1ClocksData = np.sort([s for s in os.listdir(ActivityCLockData) if 'Clocks' in s and ('FV1') in s])\n",
    "pklidx=1\n",
    "tickBarDictCondensed = dict()\n",
    "for pklidx in range(0,39):\n",
    "    pklClockFile = \"\".join((ActivityCLockData,FV1ClocksData[pklidx]))\n",
    "    tickBarDF =pickle.load(open(pklClockFile , \"rb\"))['TickBarDf'] #tickbar\n",
    "    tickBarDictCondensed[FV1ClocksData[pklidx].split('_')[3]]=tickBarDF [['BidSize', 'QuoteTime','BestBid',\n",
    "       'TradeTime', 'AskSize','BestAsk', 'TradeVolume', 'TradedTime', 'type',\n",
    "       'TradePrice', 'TimeStamp', 'milliSeconds','DollarVolume', 'MicroPrice', 'TradeSize', 'DollarVolumeTraded']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(tickBarDictCondensed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMicroPrice = pd.DataFrame()\n",
    "testFile =pd.concat(list(tickBarDictCondensed.values() ), axis =0, keys = list(tickBarDictCondensed.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microPriceReturns(key):\n",
    "    return np.array(tickBarDictCondensed[str(key)].MicroPrice.pct_change().fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key= keys[1]\n",
    "# for key in keys:\n",
    "#     print(len(microPriceReturns(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#write a piece of code that essentially looks at returns across all the clocks and then assesses normality of returns. do we recover normality using different clocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key= keys[2]\n",
    "mpr=microPriceReturns(key)\n",
    "sns.distplot(microPriceReturns(key));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longtail.fit_distributions(mpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import longtail\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(longtail.plot(mpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hsic(n, angle, sigma=0.2, offset=1):\n",
    "    n4 = int(n/4)\n",
    "    N = np.random.randn(n4, 2)*sigma\n",
    "    S = np.random.randn(n4, 2)*sigma\n",
    "    E = np.random.randn(n4, 2)*sigma\n",
    "    W = np.random.randn(n4, 2)*sigma\n",
    "    \n",
    "    N[:,1] += offset\n",
    "    S[:,1] -= offset\n",
    "    W[:,0] -= offset\n",
    "    E[:,0] += offset\n",
    "    \n",
    "    R = np.array([[np.cos(angle), -np.sin(angle)],[np.sin(angle), np.cos(angle)]])\n",
    "    A = R.dot(np.vstack((N,S,W,E)).T).T\n",
    "    \n",
    "    return A[:,0], A[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N=200\n",
    "# np.random.seed(0)\n",
    "# X,Y = sample_hsic(n=N, angle=np.pi/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =microPriceReturns(key=keys[2])\n",
    "Y =microPriceReturns(key=keys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X, alpha=0.5)\n",
    "plt.hist(Y, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_statistic(X,Y, squared=False):\n",
    "    assert X.ndim == Y.ndim == 1\n",
    "    \n",
    "    # IMPLEMENT: compute mean difference of X and Y\n",
    "    result = np.mean(X) - np.mean(Y)\n",
    "    \n",
    "    if squared:\n",
    "        result *= result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_statistic = simple_statistic(X,Y)\n",
    "print(\"Mean differencce:\", my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_permutation_test(test_statistic, X, Y, num_permutations, prog_bar=True):\n",
    "    assert X.ndim == Y.ndim\n",
    "    \n",
    "    statistics = np.zeros(num_permutations)\n",
    "    \n",
    "    range_ = range(num_permutations)\n",
    "    if prog_bar:\n",
    "        range_ = tqdm(range_)\n",
    "    for i in range_:\n",
    "        # concatenate samples\n",
    "        if X.ndim == 1:\n",
    "            Z = np.hstack((X,Y))\n",
    "        elif X.ndim == 2:\n",
    "            Z = np.vstack((X,Y))\n",
    "            \n",
    "        # IMPLEMENT: permute samples and compute test statistic\n",
    "        perm_inds = np.random.permutation(len(Z))\n",
    "        Z = Z[perm_inds]\n",
    "        X_ = Z[:len(X)]\n",
    "        Y_ = Z[len(X):]\n",
    "        my_test_statistic = test_statistic(X_, Y_)\n",
    "        statistics[i] = my_test_statistic\n",
    "    return statistics\n",
    "\n",
    "num_permutations = 200\n",
    "statistics = two_sample_permutation_test(simple_statistic, X, Y, num_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_samples_sns(null_samples, statistic= None):\n",
    "    sns.distplot(null_samples)\n",
    "    plt.axvline(x=np.percentile(null_samples, 2.5),ls='--', c='red')\n",
    "    plt.axvline(x=np.percentile(null_samples, 2.5), ls='--', c='b')\n",
    "    legend = [\"95% quantiles\"]\n",
    "    if statistic is not None:\n",
    "        plt.axvline(x=statistic, c='r')\n",
    "        legend += [\"Actual test statistic\"]\n",
    "    plt.legend(legend)\n",
    "    plt.axvline(x=np.percentile(null_samples, 97.5),ls='--',  c='b')\n",
    "    plt.xlabel(\"Test statistic value\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_samples(null_samples, statistic=None):\n",
    "    plt.hist(null_samples)\n",
    "    plt.axvline(x=np.percentile(null_samples, 2.5), c='b')\n",
    "    legend = [\"95% quantiles\"]\n",
    "    if statistic is not None:\n",
    "        plt.axvline(x=statistic,ls='--',  c='r')\n",
    "        legend += [\"Actual test statistic\"]\n",
    "    plt.legend(legend)\n",
    "    plt.axvline(x=np.percentile(null_samples, 97.5), c='b')\n",
    "    plt.xlabel(\"Test statistic value\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    \n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutation_samples_sns(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENT: use squared test statistic\n",
    "simple_statistic_squared = lambda X,Y: simple_statistic(X,Y,squared=True)\n",
    "\n",
    "# visualise test\n",
    "statistics = two_sample_permutation_test(simple_statistic_squared, X, Y, num_permutations)\n",
    "my_statistic = simple_statistic_squared(X,Y)\n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "statistics_null = two_sample_permutation_test(simple_statistic_squared, X, Y, num_permutations)\n",
    "my_statistic = simple_statistic_squared(X,Y) # this is a single sample from the alternative\n",
    "shift=0\n",
    "statistics_alt = np.zeros(num_permutations)\n",
    "for i in tqdm(range(num_permutations)):\n",
    "    # IMPLEMENT: generate more data from the alternative\n",
    "    X = np.random.randn(N)\n",
    "    Y = np.random.randn(N)+shift\n",
    "    \n",
    "    statistics_alt[i] = simple_statistic_squared(X,Y)\n",
    "    \n",
    "plt.figure(figsize=(12,4))\n",
    "plot_permutation_samples(statistics_null, my_statistic)    \n",
    "plt.hist(statistics_alt, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "\n",
    "def sq_distances(X,Y=None):\n",
    "    \"\"\"\n",
    "    If Y=None, then this computes the distance between X and itself\n",
    "    \"\"\"\n",
    "    assert(X.ndim==2)\n",
    "\n",
    "    # IMPLEMENT: compute pairwise distance matrix. Don't use explicit loops, but the above scipy functions\n",
    "    # if X=Y, use more efficient pdist call which exploits symmetry\n",
    "    if Y is None:\n",
    "        sq_dists = squareform(pdist(X, 'sqeuclidean'))\n",
    "    else:\n",
    "        assert(Y.ndim==2)\n",
    "        assert(X.shape[1]==Y.shape[1])\n",
    "        sq_dists = cdist(X, Y, 'sqeuclidean')\n",
    "\n",
    "    return sq_dists\n",
    "\n",
    "def gauss_kernel(X, Y=None, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Computes the standard Gaussian kernel k(x,y)=exp(- ||x-y||**2 / (2 * sigma**2))\n",
    "\n",
    "    X - 2d array, samples on left hand side\n",
    "    Y - 2d array, samples on right hand side, can be None in which case they are replaced by X\n",
    "    \n",
    "    returns: kernel matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # IMPLEMENT: compute squared distances and kernel matrix\n",
    "    sq_dists = sq_distances(X,Y)\n",
    "    K = np.exp(-sq_dists / (2 * sigma**2))\n",
    "    return K\n",
    "\n",
    "# IMPLEMENT\n",
    "def linear_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_time_mmd(X,Y,kernel):\n",
    "    assert X.ndim == Y.ndim == 2\n",
    "    K_XX = kernel(X,X)\n",
    "    K_XY = kernel(X,Y)\n",
    "    K_YY = kernel(Y,Y)\n",
    "       \n",
    "    n = len(K_XX)\n",
    "    m = len(K_YY)\n",
    "    \n",
    "    # IMPLEMENT: unbiased MMD statistic (could also use biased, doesn't matter if we use permutation tests)\n",
    "    np.fill_diagonal(K_XX, 0)\n",
    "    np.fill_diagonal(K_YY, 0)\n",
    "    mmd = np.sum(K_XX) / (n*(n-1))  + np.sum(K_YY) / (m*(m-1))  - 2*np.sum(K_XY)/(n*m)\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_kernel = lambda X,Y : gauss_kernel(X,Y,sigma=0.3)\n",
    "my_mmd = lambda X,Y : quadratic_time_mmd(X[:,np.newaxis],Y[:,np.newaxis], my_kernel)\n",
    "\n",
    "statistics = two_sample_permutation_test(my_mmd, X, Y, num_permutations)\n",
    "my_statistic = my_mmd(X,Y)\n",
    "\n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kernel = lambda X,Y : gauss_kernel(X,Y,sigma=0.3)\n",
    "my_mmd = lambda X,Y : quadratic_time_mmd(X[:,np.newaxis],Y[:,np.newaxis], my_kernel)\n",
    "\n",
    "statistics = two_sample_permutation_test(my_mmd, X, Y, num_permutations)\n",
    "my_statistic = my_mmd(X,Y)\n",
    "\n",
    "plot_permutation_samples(statistics, my_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(np.min(X), np.max(X))\n",
    "\n",
    "my_kernel = lambda X,Y : gauss_kernel(X,Y, sigma=0.5)\n",
    "\n",
    "# IMPLEMENT: evaluate MMD witness function on grid\n",
    "phi_X = np.mean(my_kernel(X[:,np.newaxis], grid[:,np.newaxis]), axis=0)\n",
    "phi_Y = np.mean(my_kernel(Y[:,np.newaxis], grid[:,np.newaxis]), axis=0)\n",
    "witness = phi_X-phi_Y\n",
    "\n",
    "plt.plot(grid, witness)\n",
    "\n",
    "plt.hist(X,  normed=True, facecolor='green', alpha=0.75, bins=50)\n",
    "plt.hist(Y,  normed=True, facecolor='pink', alpha=0.75, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the witness function is positive where X as a higher density than Y, and negative vice versa.\n",
    "It is zero where both densities match.\n",
    "Intuitively, the RKHS norm of this function can only be zero if the densities match everywhere, and it grows as the densities differ on more and more points in their support.\n",
    "Of course, this kind of visualization only works in few dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
