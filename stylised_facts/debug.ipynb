{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846e611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import multiprocessing\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pickle as pkl\n",
    "import fnmatch\n",
    "import lob_for_futures as lobFut\n",
    "from lob_for_futures import *\n",
    "# extra imports\n",
    "from collections import OrderedDict\n",
    "from itertools import zip_longest\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import glob\n",
    "import fathon\n",
    "from fathon import fathonUtils as fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890430d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "winSizes = fu.linRangeByStep(10, 1000, step=20)\n",
    "polOrd = 1\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "from multiprocessing import Pool, freeze_support, Manager\n",
    "\n",
    "import itertools\n",
    "\n",
    "# colormap = plt.cm.RdBu\n",
    "# plt.style.use(os.path.join(mpl.get_configdir(), 'latexstyle.mplstyle'))\n",
    "from collections import defaultdict\n",
    "\n",
    "dataFolder = lobFut.dataFolder\n",
    "t7 = lobFut.t7folder\n",
    "expInputFiles = os.path.join(lobFut.augExpertiments, 'ExperimentInputFiles')\n",
    "HiLoData = os.path.join(lobFut.augExpertiments, 'HiLoData')\n",
    "plt.style.use(os.path.join('/home/ak/.config/matplotlib', 'latexstyle3.mplstyle'))\n",
    "symbols = ['RX1', 'FB1', 'JB1', 'G_1', 'FV1', 'TY1', 'TU1', 'DU1', 'YM1', 'XM1', 'US1', 'OE1', 'KE1']\n",
    "\n",
    "# lapAugust11th2022Experiments\n",
    "# laptop data folder\n",
    "t7DataFolder = os.path.join(t7folder, 'August11th2022Experiments/ExperimentOne/' )\n",
    "laptopDataFolder = os.path.join('/media/ak/OS', 'Data')\n",
    "expFiles = os.path.join(laptopDataFolder, 'August11th2022Experiments')\n",
    "\n",
    "destination = os.path.join(laptopDataFolder, 'AthensSoloTripFeb2023')\n",
    "figuresDestination = '/home/ak/Documents/Papers/StylisedFactsPaper/figures/'\n",
    "# n: Array of window's sizes used for the computation.\n",
    "n = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
    "     39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
    "     68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53d05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CrossCorrel():\n",
    "    def __init__(self, path, symbols_list, idx, bar_choice):\n",
    "        \"\"\"\n",
    "\n",
    "        :param path: which path to read from for the data\n",
    "        :param symbols_list:\n",
    "        :param idx:\n",
    "        :param bar_choice:\n",
    "        \"\"\"\n",
    "\n",
    "        self._idx = idx  # this index is for the symbol\n",
    "        self._symbols = symbols_list\n",
    "        self._bar = bar_choice\n",
    "        self._symbol = self._symbols[self._idx]\n",
    "\n",
    "        self._symbolFilepath = os.path.join(path, str(self._symbol))\n",
    "\n",
    "        self._listOfFiles = os.listdir(self._symbolFilepath)\n",
    "\n",
    "        self._micro_variables = ['arrival_rates', 'gk_vol', 'median_traded_volume', 'micro_price_change']\n",
    "\n",
    "    def get_data_and_path(self):\n",
    "        # , fileIdx, symbols, path\n",
    "        \"\"\"\n",
    "\n",
    "        :param symbolIdx: symbol index from list\n",
    "        :param symbols: list of symbols\n",
    "        :param bar: bar for information clock\n",
    "        :param path: which path to read from\n",
    "        :return: list of files, and path to those files\n",
    "        \"\"\"\n",
    "        # print('data for symbol', self._symbol)\n",
    "        filesBarSymbol = [f for f in self._listOfFiles if str(self._bar) in f]\n",
    "\n",
    "        return filesBarSymbol, self._symbolFilepath\n",
    "\n",
    "    def get_all_data_from_file(self, fileIdx):\n",
    "        \"\"\"\n",
    "        fileIdx = index file to get unpickled\n",
    "        \"\"\"\n",
    "        filesBarSymbol, symbolFilepath = self.get_data_and_path()\n",
    "        fileToGet = os.path.join(symbolFilepath, filesBarSymbol[fileIdx])\n",
    "        return pd.read_pickle(fileToGet)\n",
    "\n",
    "    def get_microvar_data(self, fileIdx, var):\n",
    "        \"\"\"\n",
    "\n",
    "        :param fileIdx: index of file in list\n",
    "        :param var: which micro-structure market variable -string\n",
    "        :return: returns the microstructure variable\n",
    "        \"\"\"\n",
    "        pklDict = self.get_all_data_from_file(fileIdx)\n",
    "        return pklDict[str(var)]\n",
    "\n",
    "    def get_all_microvar_data(self, fileIdx):\n",
    "        \"\"\"\n",
    "\n",
    "        :param fileIdx: index in the list- position of file in the list\n",
    "        :return: all the microstructure data\n",
    "        \"\"\"\n",
    "        pkl_dict = self.get_all_data_from_file(fileIdx)\n",
    "        pkl_dict_keys = sorted(list(pkl_dict.keys()))  # get out all the keys- but its really bars\n",
    "\n",
    "        # ----micro structure vars-----#\n",
    "\n",
    "        gk_vol = pkl_dict['gk_vol']  # get the vol\n",
    "        median_traded_volume = pkl_dict['median_traded_volume']  # get the volume\n",
    "        arrival_rates = pkl_dict['arrival_rates']  # get arrival rates\n",
    "        micro_price_change = pkl_dict['micro_price_change']  # get micro price change\n",
    "\n",
    "        # ---- start getting all the mfdfa variables ----#\n",
    "\n",
    "        tau_dict = pkl_dict[str(self._bar)]['tau']  # tau\n",
    "        alpha = pkl_dict[str(self._bar)]['alpha']  # alpha\n",
    "        mfSpect = pkl_dict[str(self._bar)]['mfSpect']  # mfSpect\n",
    "        n_F_dict = pkl_dict[str(self._bar)]['n_F']  # n_F\n",
    "        list_H_dict = pkl_dict[str(self._bar)]['list_H']  # list_H\n",
    "        list_H_intercept = pkl_dict[str(self._bar)]['list_H_intercept']  # intercept\n",
    "\n",
    "        return gk_vol, median_traded_volume, arrival_rates, micro_price_change, tau_dict, alpha, mfSpect, n_F_dict, list_H_dict, list_H_intercept\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_n_Rho(var_a, var_b, idx, winSizes, polOrd):\n",
    "        \"\"\"\n",
    "        var_a = first variable for the dCCa rho\n",
    "        var_b = second variable for the dCCa rho\n",
    "        idx = index in for which \"day to pick\"\n",
    "        \"\"\"\n",
    "        a = fu.toAggregated(var_a[idx])\n",
    "        b = fu.toAggregated(var_b[idx])\n",
    "        try:\n",
    "            pydcca = fathon.DCCA(a, b)\n",
    "            n, F = pydcca.computeFlucVec(winSizes, polOrd=polOrd)\n",
    "            n, rho = pydcca.computeRho(winSizes, polOrd=polOrd)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        return n, rho\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_n_F_dcca(var_a, var_b, idx, winSizes, polOrd):\n",
    "        \"\"\"\n",
    "        var_a = first variable for the dCCa rho\n",
    "        var_b = second variable for the dCCa rho\n",
    "        idx = index in for which \"day to pick\"\n",
    "        \"\"\"\n",
    "        a = fu.toAggregated(var_a[idx])\n",
    "        b = fu.toAggregated(var_b[idx])\n",
    "        pydcca = fathon.DCCA(a, b)\n",
    "        n, F = pydcca.computeFlucVec(winSizes, polOrd=polOrd)\n",
    "        return n, F\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_H_H_intc_dcca(var_a, var_b, idx, winSizes, polOrd):\n",
    "        \"\"\"\n",
    "        var_a = first variable for the dCCa rho\n",
    "        var_b = second variable for the dCCa rho\n",
    "        idx = index in for which \"day to pick\"\n",
    "        \"\"\"\n",
    "        a = fu.toAggregated(var_a[idx])\n",
    "        b = fu.toAggregated(var_b[idx])\n",
    "        pydcca = fathon.DCCA(a, b)\n",
    "        n, F = pydcca.computeFlucVec(winSizes, polOrd=polOrd)\n",
    "\n",
    "        H, H_intercept = pydcca.fitFlucVec()\n",
    "        return n, F, H, H_intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27202b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#symbols = ['RX1', 'FB1', 'JB1', 'G_1', 'FV1', 'TY1', 'TU1', 'DU1', 'YM1', 'XM1', 'US1', 'OE1', 'KE1']\n",
    "symbols = sorted(['FB1', 'JB1', 'XM1', 'TY1', 'TU1', 'RX1', 'YM1', 'US1', 'DU1']) # symbols for T71 USB Drive\n",
    "winSizes = fu.linRangeByStep(10, 1000, step=20)\n",
    "polOrd = 1\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2263339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ak/T71/August11th2022Experiments/ExperimentOne/US1\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "micro_variables = ['arrival_rates', 'gk_vol', 'median_traded_volume', 'micro_price_change']\n",
    "# self, path, symbols, idx, bar, use_var\n",
    "symbolsIdx = 6\n",
    "bar = 'volume'\n",
    "cc2 = CrossCorrel(t7DataFolder, symbols, symbolsIdx, str(bar))\n",
    "files, filesPath = cc2.get_data_and_path()\n",
    "print(filesPath)\n",
    "print(len(os.listdir(filesPath)))\n",
    "range_to_use = range(0, 51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44a11f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30aa253b13e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marrivals_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_microvar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'arrival_rates'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_to_use\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# median_volumes_list = {f: cc2.get_microvar_data(fileIdx=f, var='median_traded_volume') for f in range_to_use}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# arrivalsDF = pd.DataFrame(arrivals_list).fillna(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# medianVolumesDF = pd.DataFrame(median_volumes_list).fillna(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-30aa253b13e7>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marrivals_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_microvar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'arrival_rates'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_to_use\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# median_volumes_list = {f: cc2.get_microvar_data(fileIdx=f, var='median_traded_volume') for f in range_to_use}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# arrivalsDF = pd.DataFrame(arrivals_list).fillna(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# medianVolumesDF = pd.DataFrame(median_volumes_list).fillna(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-06e5de91507a>\u001b[0m in \u001b[0;36mget_microvar_data\u001b[0;34m(self, fileIdx, var)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmicrostructure\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mpklDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_data_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpklDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-06e5de91507a>\u001b[0m in \u001b[0;36mget_all_data_from_file\u001b[0;34m(self, fileIdx)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[1;32m     41\u001b[0m         \u001b[0mfilesBarSymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolFilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_and_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mfileToGet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolFilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesBarSymbol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfileIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileToGet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "arrivals_list = {f:  for f in range_to_use}\n",
    "# median_volumes_list = {f: cc2.get_microvar_data(fileIdx=f, var='median_traded_volume') for f in range_to_use}\n",
    "# arrivalsDF = pd.DataFrame(arrivals_list).fillna(0)\n",
    "# medianVolumesDF = pd.DataFrame(median_volumes_list).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cf7cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 1\n",
    "cc2.get_microvar_data(fileIdx=f, var='arrival_rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #\n",
    "    # def fn_for_rho(idx):\n",
    "    #     rhoDict = dict()\n",
    "    #     n = []\n",
    "    #     #  = cc2.compute_n_Rho(arrivalsDF, medianVolumesDF, idx, winSizes, polOrd)\n",
    "    #     n, rhoDict[idx] = cc2.compute_n_Rho(arrivalsDF, medianVolumesDF, idx, winSizes, polOrd)\n",
    "    #     rhoDict['n'] = n\n",
    "    #     file_name = \"_\".join(('RhoDict_', str(symbols[symbolsIdx]), str(idx), bar, '.pkl'))\n",
    "    #     pickle_out_filename = os.path.join(expInputFiles, file_name)\n",
    "    #     pickle.dump(rhoDict, open(pickle_out_filename, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #     return rhoDict\n",
    "    #\n",
    "    #\n",
    "    # def fn_for_H_H_dcca(idx):\n",
    "    #     h_dcca = dict()\n",
    "    #     #  = cc2.compute_n_Rho(arrivalsDF, medianVolumesDF, idx, winSizes, polOrd)\n",
    "    #     h_dcca['n'], h_dcca['F'], h_dcca['H'], h_dcca['H_intercept'] = cc2.compute_H_H_intc_dcca(arrivalsDF, medianVolumesDF, idx, winSizes, polOrd)\n",
    "    #     file_name = \"_\".join(('HurstDict_', str(symbols[symbolsIdx]),str(idx), bar, '.pkl'))\n",
    "    #     pickle_out_filename = os.path.join(expInputFiles, file_name)\n",
    "    #     pickle.dump(h_dcca, open(pickle_out_filename, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    #     return h_dcca\n",
    "    #\n",
    "    # tic = time.perf_counter()\n",
    "    # # fn_for_rho(1)\n",
    "    # with Pool(5) as p:\n",
    "    #    # print(p.map(fn_for_H_H_dcca, [f for f in range(0, 40)]))\n",
    "    #     print(p.map(fn_for_rho, [f for f in range(0, 20)]))\n",
    "    # toc = time.perf_counter()\n",
    "    # print(\"elapsed time:\", (toc - tic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:newTimeSeries] *",
   "language": "python",
   "name": "conda-env-newTimeSeries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
