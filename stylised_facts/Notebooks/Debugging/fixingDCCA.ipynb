{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4326d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from typing import Dict, List\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import fathon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fathon import fathonUtils as fu\n",
    "\n",
    "SYMBOLS = ['RX1', 'FB1', 'JB1', 'G_1', 'FV1', 'TY1', 'TU1', 'DU1', 'YM1', 'XM1', 'US1', 'OE1', 'KE1']\n",
    "WIN_SIZES = fu.linRangeByStep(10, 1000, step=20)\n",
    "POL_ORD = 1\n",
    "MICRO_VARIABLES = ['arrival_rates', 'gk_vol', 'median_traded_volume', 'micro_price_change']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34465514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MicroVariableProcessor:\n",
    "    def __init__(self, base_path: str, symbol: str, bar: str):\n",
    "        \"\"\"\n",
    "        Initialize the MicroVariableProcessor class.\n",
    "\n",
    "        :param base_path: The base path to the directory containing the experiment data.\n",
    "        :type base_path: str\n",
    "        :param symbol: The symbol of the financial instrument (e.g., 'JB1').\n",
    "        :type symbol: str\n",
    "        :param bar_mfdfa_files: A list of file names containing the bar-mfdfa data.\n",
    "        :type bar_mfdfa_files: List[str]\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.symbol = symbol\n",
    "        self.bar = bar\n",
    "        self.symbol_path = os.path.join(self.base_path, self.symbol)\n",
    "        self.bar_mfdfa_files = [f for f in os.listdir(self.symbol_path) if str(self.bar) in f]\n",
    "\n",
    "        self.gk_vol_dict = defaultdict(dict)\n",
    "        self.micro_prices = None\n",
    "        self.median_traded_volume_dict = defaultdict(dict)\n",
    "        self.arrival_rates_dict = defaultdict(dict)\n",
    "        self.micro_price = defaultdict(dict)\n",
    "\n",
    "    def compute_intraday_volatility(self, micro_prices: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Compute the intraday volatility of returns based on micro prices.\n",
    "\n",
    "        :param micro_prices: A Pandas Series containing micro price data.\n",
    "        :type micro_prices: pd.Series\n",
    "        :return: Intraday volatility of returns.\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        log_returns = np.log(micro_prices / micro_prices.shift(1))\n",
    "        intraday_volatility = np.std(log_returns)\n",
    "\n",
    "        return intraday_volatility\n",
    "\n",
    "    def process_file(self, idx: int) -> Dict:\n",
    "        micro_variables = ['arrival_rates', 'GK_vol', 'median_traded_volume', 'micro_price_change']\n",
    "        file_path = os.path.join(self.symbol_path, self.bar_mfdfa_files[idx])\n",
    "        pkl_dict = pd.read_pickle(file_path)\n",
    "        #         pkl_dict_keys = sorted(list(pkl_dict.keys()))\n",
    "\n",
    "        output = {\n",
    "            \"gk_vol\": pkl_dict['GK_vol'],\n",
    "            \"median_traded_volume\": pkl_dict[\"median_traded_volume\"],\n",
    "            \"arrival_rates\": pkl_dict[\"arrival_rates\"],\n",
    "            \"micro_price\": pkl_dict[\"micro_price\"],\n",
    "\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_std_and_quantiles(self, intraday_volatilities: List[float]):\n",
    "        \"\"\"\n",
    "        Compute standard deviations and quantiles for the input list of intraday volatilities.\n",
    "\n",
    "        Args:\n",
    "            intraday_volatilities (List[float]): A list of intraday volatilities.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the standard deviation DataFrame, first regime quantile, and second regime quantile.\n",
    "        \"\"\"\n",
    "        mpc_df = pd.DataFrame(intraday_volatilities, columns=[\"intraday_volatility\"])\n",
    "        std_df = pd.DataFrame()\n",
    "        std = mpc_df.std(axis=0)\n",
    "        std_df['std'] = std\n",
    "        first_regime = np.quantile(std, 0.33)\n",
    "        second_regime = np.quantile(std, 0.66)\n",
    "\n",
    "        return std_df, first_regime, second_regime\n",
    "\n",
    "    def process_files(self):\n",
    "        results = []\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future_to_idx = {executor.submit(self.process_file, idx): idx for idx, file in\n",
    "                             enumerate(self.bar_mfdfa_files)}\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_idx):\n",
    "                idx = future_to_idx[future]\n",
    "                try:\n",
    "                    file_data = future.result()\n",
    "                except Exception as exc:\n",
    "                    print(f\"File {idx} generated an exception: {exc}\")\n",
    "                else:\n",
    "                    results.append((idx, file_data))\n",
    "\n",
    "        for idx, file_data in results:\n",
    "            try:\n",
    "                self.gk_vol_dict[idx] = file_data[\"gk_vol\"]\n",
    "                self.median_traded_volume_dict[idx] = file_data[\"median_traded_volume\"]\n",
    "                self.arrival_rates_dict[idx] = file_data[\"arrival_rates\"]\n",
    "                self.micro_price[idx] = file_data[\"micro_price\"]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        return self.gk_vol_dict, self.median_traded_volume_dict, self.arrival_rates_dict, self.micro_price\n",
    "\n",
    "    def get_output(self, idx):\n",
    "        \"\"\"\n",
    "        Return the computed intraday volatility and other attributes.\n",
    "\n",
    "        :param idx: The index of the file to be processed.\n",
    "        :type idx: int\n",
    "        :return: A dictionary containing the computed intraday volatility and other attributes.\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        # Process the specified file\n",
    "        file_data = self.process_file(idx)\n",
    "\n",
    "        # Extract the micro_price data\n",
    "        micro_prices = file_data[\"micro_price\"]\n",
    "\n",
    "        # Set the micro_prices attribute\n",
    "        self.micro_prices = micro_prices\n",
    "\n",
    "        output = {\n",
    "            \"intraday_volatility\": self.compute_intraday_volatility(self.micro_prices),\n",
    "            \"gk_vol\": file_data[\"gk_vol\"],\n",
    "            \"median_traded_volume\": file_data[\"median_traded_volume\"],\n",
    "            \"arrival_rates\": file_data[\"arrival_rates\"],\n",
    "            \"micro_price\": file_data[\"micro_price\"]\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    def save_output(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Save the output to a specified file.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): The path where the output should be saved.\n",
    "        \"\"\"\n",
    "        output = self.get_output()\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            json.dump(output, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac65702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CrossCorrel:\n",
    "    def __init__(self, base_path: str, symbols_list: list, idx: int, bar_choice: str):\n",
    "        \"\"\"\n",
    "        Initialize the CrossCorrel class.\n",
    "\n",
    "        Args:\n",
    "            base_path (str): Path to read data from.\n",
    "            symbols_list (list): List of symbols.\n",
    "            idx (int): Index for the symbol.\n",
    "            bar_choice (str): Bar for information clock.\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self._idx = idx\n",
    "        self._symbols = symbols_list\n",
    "        self._bar = bar_choice\n",
    "        self._symbol = self._symbols[self._idx]\n",
    "        self.symbol_path = os.path.join(self.base_path, \"ExperimentOne\", self._symbol[0])\n",
    "        self.winSizes = fu.linRangeByStep(10, 1000, step=20)\n",
    "        self.polOrd = 1\n",
    "\n",
    "    @staticmethod\n",
    "    def to_aggregated(data):\n",
    "        \"\"\"\n",
    "        Convert pandas Series to numpy array\n",
    "\n",
    "        Args:\n",
    "            data (pd.Series): The data to be converted\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The converted array\n",
    "        \"\"\"\n",
    "        data = np.array(data)\n",
    "        return data.cumsum()\n",
    "\n",
    "    # @staticmethod\n",
    "    def compute_n_rho(var_a: pd.Series, var_b: pd.Series, winSizes: np.ndarray, polOrd: int) -> Tuple[\n",
    "        np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute the DCCA cross-correlation coefficients (rho) and the corresponding window sizes (n).\n",
    "\n",
    "        Args:\n",
    "            var_a (pd.Series): The first time series.\n",
    "            var_b (pd.Series): The second time series.\n",
    "            win_sizes (np.ndarray): An array of window sizes to be used for DCCA.\n",
    "            pol_ord (int): The polynomial order for detrending.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: The window sizes (n) and the cross-correlation coefficients (rho).\n",
    "        \"\"\"\n",
    "        a = CrossCorrel.to_aggregated(var_a.values)\n",
    "        b = CrossCorrel.to_aggregated(var_b.values)\n",
    "\n",
    "        pydcca = fathon.DCCA(a, b)\n",
    "        try:\n",
    "            n, _ = pydcca.computeFlucVec(winSizes=winSizes, polOrd=polOrd)\n",
    "            _, rho = pydcca.computeRho(winSizes=winSizes, polOrd=polOrd)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "\n",
    "        return n, rho\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_n_f_dcca(var_a: pd.Series, var_b: pd.Series, winSizes: np.ndarray, polOrd: int) -> Tuple[\n",
    "        np.ndarray, np.ndarray]:\n",
    "        a = CrossCorrel.to_aggregated(var_a)\n",
    "        b = CrossCorrel.to_aggregated(var_b)\n",
    "\n",
    "        pydcca = fathon.DCCA(a, b)\n",
    "        n, F = pydcca.computeFlucVec(winSizes=winSizes, polOrd=polOrd)\n",
    "\n",
    "        return n, F\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_h_h_intc_dcca(var_a: pd.Series, var_b: pd.Series, winSizes: np.ndarray, polOrd: int) -> Tuple[\n",
    "        np.ndarray, np.ndarray, float, float]:\n",
    "        a = CrossCorrel.to_aggregated(var_a)\n",
    "        b = CrossCorrel.to_aggregated(var_b)\n",
    "\n",
    "        pydcca = fathon.DCCA(a, b)\n",
    "        n, F = pydcca.computeFlucVec(winSizes=winSizes, polOrd=polOrd)\n",
    "\n",
    "        H, H_intercept = pydcca.fitFlucVec()\n",
    "\n",
    "        return n, F, H, H_intercept\n",
    "\n",
    "    @staticmethod\n",
    "    def save_output(output_to_save, filepath: str):\n",
    "        \"\"\"\n",
    "        Save the output to a specified file.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): The path where the output should be saved.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            json.dump(output_to_save, f, indent=4)\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = \"/media/ak/Data1/ExperimentData/August11th2022Experiments/ExperimentInputFiles\"\n",
    "    # Define the path     to     the     data and the     list     of     symbols.\n",
    "    symbols_list = [\"G_1\"]\n",
    "    bar_choice = \"tick\"  # Replace with your choice of bar (e.g., 'tick', 'volume', 'dollar').\n",
    "    # # Initialize the MicroVariableProcessor.\n",
    "    mvp = MicroVariableProcessor(base_path, symbols_list[0], bar_choice)\n",
    "    idx = 0\n",
    "    output = mvp.get_output(idx)\n",
    "    print(output)\n",
    "\n",
    "    # Optional: Save output to a file\n",
    "    # filepath = \"/path/to/save/output.json\"\n",
    "    # mvp.save_output(filepath)\n",
    "\n",
    "\n",
    "def main_cross_correl(base_path: str, symbols_list: List[str], idx: int, bar_choice: str, var_a: pd.Series,\n",
    "                      var_b: pd.Series, fileIdx: int):\n",
    "    \"\"\"\n",
    "    Main function to run CrossCorrel for a single symbol.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): Path to read data from.\n",
    "        symbols_list (List[str]): List of symbols.\n",
    "        idx (int): Index for the symbol.\n",
    "        bar_choice (str): Bar for information clock.\n",
    "        var_a (pd.Series): The first time series.\n",
    "        var_b (pd.Series): The second time series.\n",
    "        fileIdx (int): The index of the file being processed.\n",
    "    \"\"\"\n",
    "    cross_correl = CrossCorrel(base_path, symbols_list, idx, bar_choice)\n",
    "    win_sizes = cross_correl.winSizes\n",
    "    pol_ord = cross_correl.polOrd\n",
    "    try:\n",
    "\n",
    "        n, rho = CrossCorrel.compute_n_rho(var_a=var_a, var_b=var_b, winSizes=win_sizes, polOrd=pol_ord)\n",
    "        n, F = CrossCorrel.compute_n_f_dcca(var_a=var_a, var_b=var_b, winSizes=win_sizes, polOrd=pol_ord)\n",
    "        n, F, H, H_intercept = CrossCorrel.compute_h_h_intc_dcca(var_a=var_a, var_b=var_b, winSizes=win_sizes,\n",
    "                                                                 polOrd=pol_ord)\n",
    "\n",
    "        # Process the results as required, e.g., save to file or display results\n",
    "        print(\"n:\", n)\n",
    "        print(\"rho:\", rho)\n",
    "        print(\"F:\", F)\n",
    "        print(\"H:\", H)\n",
    "        print(\"H_intercept:\", H_intercept)\n",
    "        output_path = os.path.join(base_path, \"outputs\")\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        output_filename = f\"{symbols_list[idx]}_{bar_choice}_{fileIdx}_output.json\"\n",
    "\n",
    "        output_filepath = os.path.join(output_path, output_filename)\n",
    "        print(output_filepath)\n",
    "\n",
    "        output_data = {\n",
    "            \"n\": n.tolist(),\n",
    "            \"rho\": rho.tolist(),\n",
    "            \"F\": F.tolist(),\n",
    "            \"H\": H,\n",
    "            \"H_intercept\": H_intercept\n",
    "        }\n",
    "\n",
    "        with open(output_filepath, \"w\") as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "            print(\"saved\")\n",
    "    except (ValueError, UnboundLocalError):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a27073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "base_path = \"/media/ak/Data1/ExperimentData/August11th2022Experiments/ExperimentInputFiles\"\n",
    "# Define the path     to     the     data and the     list     of     symbols.\n",
    "symbols_list = [\"G_1\"]\n",
    "bar_choice = \"dollar\"  # Replace with your choice of bar (e.g., 'tick', 'volume', 'dollar').\n",
    "idx = 0\n",
    "mvp = MicroVariableProcessor(base_path, symbols_list[idx], bar_choice)\n",
    "\n",
    "#     tic = time.perf_counter()\n",
    "\n",
    "#     with Pool() as pool:\n",
    "#         pool.starmap(main_cross_correl, [(base_path, symbols_list, idx, bar_choice,\n",
    "#                                           mvp.get_output(fileIdx)[\"micro_price\"], mvp.get_output(fileIdx)[\"gk_vol\"],\n",
    "#                                           fileIdx) for\n",
    "#                                          fileIdx in range(0, 14)])\n",
    "#     toc = time.perf_counter()\n",
    "#     print(\"elapsed time:\", (toc - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc60a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_dict  = mvp.process_file(1)\n",
    "keys = ['gk_vol', 'median_traded_volume', 'arrival_rates', 'micro_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6dfa5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.699412173102923e-05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvp.compute_intraday_volatility(mvp_dict['micro_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193e805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timeSeries] *",
   "language": "python",
   "name": "conda-env-timeSeries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
