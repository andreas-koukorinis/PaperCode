{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ak/Documents/PaperCode/stylised_facts/Notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/directory/tothe/handshakefile/')\n",
    "sys.path.append('/home/ak/Documents/PaperCode/stylised_facts')\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "###\n",
    "\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from MFDFA import fgn\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sb.set()\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import minmax_scale\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "sys.path.append('/home/ak/Documents/PaperCode/stylised_facts/')\n",
    "import stylised_facts_data_utilities as sfd\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install MFDFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/ak/My Passport/Experiment Data/ActivityClockData/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e0fbed408c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'/media/ak/My Passport/Experiment Data/ActivityClockData/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfolderList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfolderList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msymbosl\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FB1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JB1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FV1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'G_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/ak/My Passport/Experiment Data/ActivityClockData/'"
     ]
    }
   ],
   "source": [
    "folder= '/media/ak/My Passport/Experiment Data/ActivityClockData/'\n",
    "folderList = os.listdir(folder)\n",
    "folderList\n",
    "symbosl =['FB1','JB1','FV1','G_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "correlDU1ListOne =list(np.sort([s for s in folderList if ('AtoCor') in s and ('1AtoCorrelData_FB1') in s]))\n",
    "correlDU1ListZero =list(np.sort([s for s in folderList if ('AtoCor') in s and ('0AtoCorrelData_FB1') in s]))\n",
    "correlDU1ListTwo =list(np.sort([s for s in folderList if ('AtoCor') in s and ('2AtoCorrelData_FB1') in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd=DataFrame.from_dict(list, orient='columns', dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DU1CorrelVolBar= []\n",
    "for idx, _ in enumerate(correlDU1ListOne):\n",
    "    fileLoc = \"\".join((folder, correlDU1ListOne[idx]))\n",
    "    pickle_to_file = pickle.load(open(fileLoc, \"rb\"))\n",
    "    DU1CorrelVolBar.append(pickle_to_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DU1CorrelTickBar= []\n",
    "for idx, _ in enumerate(correlDU1ListZero):\n",
    "    fileLoc = \"\".join((folder, correlDU1ListZero[idx]))\n",
    "    pickle_to_file = pickle.load(open(fileLoc, \"rb\"))\n",
    "    DU1CorrelTickBar.append(pickle_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DU1CorrelDolVolBar= []\n",
    "for idx, _ in enumerate(correlDU1ListTwo):\n",
    "    fileLoc = \"\".join((folder, correlDU1ListTwo[idx]))\n",
    "    pickle_to_file = pickle.load(open(fileLoc, \"rb\"))\n",
    "    DU1CorrelDolVolBar.append(pickle_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAutoCorrelOne =pd.DataFrame.from_dict(DU1CorrelVolBar, orient='columns', dtype=None).T\n",
    "dfAutoCorrelZero =pd.DataFrame.from_dict(DU1CorrelTickBar, orient='columns', dtype=None).T\n",
    "dfAutoCorrelTwo =pd.DataFrame.from_dict(DU1CorrelDolVolBar, orient='columns', dtype=None).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title='MedianAutocorrelationForSymbolFB1'\n",
    "dfs = [dfAutoCorrelZero, dfAutoCorrelOne, dfAutoCorrelTwo]\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "size = 5\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (16, 9),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size * 0.75,\n",
    "          'ytick.labelsize': size * 0.75,\n",
    "          'axes.titlepad': 25}\n",
    "_=fig, ax1 = plt.subplots(figsize=(16, 9),constrained_layout=True)\n",
    "ax1.grid(color='grey', linestyle='--', linewidth=1)\n",
    "ax2 = ax1.twiny()\n",
    "ax1.set_facecolor('white')\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax1.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "for idx, df in enumerate(dfs):\n",
    "    ax1.plot( df.median(axis=1))\n",
    "ax1.set_title('Autocorrelation by lag')\n",
    "ax1.set_ylabel('Autocorrelation')\n",
    "ax1.set_xlabel('Lag')\n",
    "# Initial value of y at t=0, lifetime in s\n",
    "N, tau = 1, 19\n",
    "xlineLevel=180\n",
    "# Maximum time to consider (s)\n",
    "tmax = 500\n",
    "ntau = tmax // tau + 1\n",
    "# A suitable grid of time points, and the exponential decay itself\n",
    "t = np.linspace(0, tmax, 400)\n",
    "y = N * np.exp(-t / tau)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "ax1.plot(t, y, color='black', linestyle='--')\n",
    "ax1.grid(True)\n",
    "#     axvline(x=.5, ymin=0.25, ymax=0.75)\n",
    "_=ax1.axvline(x=xlineLevel, ymin=0.0, ymax=0.8, ls='--', alpha=0.7, color='#334f8d')\n",
    "_=ax1.text(xlineLevel, 0.85, 'lag ' + str(xlineLevel), rotation=90, fontsize=12)\n",
    "_=xtick_labels = [r'$0$', r'$\\tau$'] + [r'${}\\tau$'.format(k) for k in range(2, ntau)]\n",
    "_=ax1.legend(loc='lower right')\n",
    "_=ax2.set_xticklabels(xtick_labels)\n",
    "\n",
    "#plt.savefig('/home/ak/Documents/Research/Papers/figures/' + title + '.png', dpi=150)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle_to_file = pickle.load(open(fileLoc, \"rb\"))\n",
    "keys = pickle_to_file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pickle_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderList = os.listdir(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DU1Clocks =list(np.sort([s for s in folderList if ('Clocks') in s and ('_DU1') in s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "mergedDFs = defaultdict(dict)\n",
    "column='MicroPrice'\n",
    "for clocksIdx, _ in enumerate(DU1Clocks):\n",
    "    dateIdx = DU1Clocks[1].split(\"_\")[-2]\n",
    "    fileLoc = \"\".join((folder, DU1Clocks[clocksIdx]))\n",
    "    dFclockdf = pickle.load(open(fileLoc, \"rb\"))\n",
    "    ref = dFclockdf['OriginalDF']\n",
    "    sub = dFclockdf['TickBarDf']\n",
    "#     sub2 = dFclockdf['VolumeBarDf']\n",
    "#     sub3 = dFclockdf['DollarVolumeBarDf']\n",
    "    ohlcDF1 =createLOB.get_ohlc(ref, sub)\n",
    "#     ohlcDF2 =createLOB.get_ohlc(ref, sub2)\n",
    "#     ohlcDF3 =createLOB.get_ohlc(ref, sub3)\n",
    "    mergedDFs['Tick'][clocksIdx] = ohlcDF1\n",
    "#     mergedDFs['Volume'][clocksIdx] = ohlcDF2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleKeys = list(dFclocksSample.keys() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSampleTick = dFclocksSample[sampleKeys[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylised_facts.stylised_facts_data_utilities.createLOB as createLOB\n",
    "clocksDataList =[s for s in folderList if ('ClocksData') in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column='MicroPrice'\n",
    "ref=dFclocksSample[sampleKeys[0]][str(column)]\n",
    "sub=dFclocksSample[sampleKeys[1]][str(column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcDF =createLOB.get_ohlc(ref, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogersSatchell=createLOB.Volestim(ohlcDF,window=5).rogersSatchell()\n",
    "hodgesTompkins=createLOB.Volestim(ohlcDF, window=5).hodgesTompkins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohlcDF=ohlcDF.set_index('Start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quoteTime = dfSampleTick['QuoteTime']\n",
    "dfSampleTick.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSampleTick.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogSatchellVol =pd.DataFrame(rogersSatchell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =pd.merge(ohlcDF, dfSampleTick, left_index=True, right_index=True)\n",
    "#how equal left in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =dfMerged.merge(rogSatchellVol, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = dfMerged.rename_axis('Start').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfMerged.rename({'0': \"RogSatchVol\"},axis='index',inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged['RogSatchVol']=dfMerged[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfOriginal = dFclocksSample[sampleKeys[0]]\n",
    "dfTick =  dFclocksSample[sampleKeys[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBidAskSpread = dfTick.BestAsk - dfTick.BestBid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =dfMerged.merge(pd.DataFrame\n",
    "               (dfBidAskSpread), left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged['BidAsk']=dfMerged[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged =dfMerged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copulalib.copulalib import Copula\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and histograms\n",
    "def plotData(x,y):\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(2,2,1)\n",
    "    plt.hist(x,bins=20,color='green',alpha=0.8,align='mid')\n",
    "    plt.title('X variable distribution')\n",
    "    fig.add_subplot(2,2,3)\n",
    "    plt.scatter(x,y,marker=\"o\",alpha=0.8)\n",
    "    fig.add_subplot(2,2,4)\n",
    "    plt.title('Joint X,Y')\n",
    "    plt.hist(y,bins=20,orientation='horizontal',color='red',alpha=0.8,align='mid')\n",
    "    plt.title('Y variable distribution')    \n",
    "    plt.show()\n",
    "\n",
    "def generateCopulas(x,y):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    frank = Copula(x,y,family='frank')\n",
    "    uf,vf = frank.generate_uv(1000)\n",
    "    fig.add_subplot(2,2,1)\n",
    "    plt.scatter(uf,vf,marker='.',color='blue')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Frank copula')\n",
    "\n",
    "    clayton = Copula(x,y,family='clayton')\n",
    "    uc,vc = clayton.generate_uv(1000)\n",
    "    fig.add_subplot(2,2,2)\n",
    "    plt.scatter(uc,vc,marker='.',color='red')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Clayton copula')\n",
    "\n",
    "    gumbel = Copula(x,y,family='gumbel')\n",
    "    ug,vg = gumbel.generate_uv(1000)\n",
    "    fig.add_subplot(2,2,3)\n",
    "    plt.scatter(ug,vg,marker='.',color='green')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Gumbel copula')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change = dfMerged.MicroPrice.pct_change().dropna()\n",
    "vol = dfMerged.RogSatchVol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn_qqplot as sqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")    \n",
    "_=fig, ax = plt.subplots(figsize=(8, 5))    \n",
    "palette = sns.color_palette(\"bright\", 4)\n",
    "g =sns.distplot(pct_change);\n",
    "_=g.legend(bbox_to_anchor=(1, 1), ncol=1)\n",
    "_=g.set(xlim = (np.min(pct_change),np.max(pct_change)))\n",
    "_=xlabels = ['{:,.2f}'.format(x) + '' for x in g.get_xticks()*10000]\n",
    "_=g.set_xticklabels(xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(vol, color=\".2\", linewidth=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma, expon, fatiguelife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from seaborn_qqplot import qqplot\n",
    "qqplot(dfMerged, x='RogSatchVol', y=fatiguelife, height = 4, aspect = 1.5, display_kws={\"identity\":True})\n",
    "qqplot(dfMerged, x='RogSatchVol', y=expon, height = 4, aspect = 1.5, display_kws={\"identity\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=qqplot(dfMerged, x='RogSatchVol', y=fatiguelife, height = 4, aspect = 1.5, display_kws={\"identity\":False,\"fit\":True,\"reg\":True,\"ci\":0.025})\n",
    "_=plt.title('QQ-Plot of Rogers Satchell Realised Volatility Estimator versus Fatigue Life')\n",
    "\n",
    "plt.savefig('/home/ak/Documents/Research/Papers/figures/' + 'RogSatchQQPlot' + '.png', dpi=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, confidence intervals can be added for the linear regressions, we can precise the degree of confidence of the interval with the parameter ci a number in the interval [0,1] and the confidence intervals with degree of confidence 1 - ci/2 will be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "data = np.asarray(vol)# data can be list or numpy array\n",
    "results = powerlaw.Fit(data,discrete=False)\n",
    "print(results.power_law.alpha)\n",
    "print(results.power_law.xmin)\n",
    "R, p = results.distribution_compare('power_law', 'lognormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =results.plot_pdf( color='r')\n",
    "FigCCDFmax =results.plot_ccdf(color='b', label=r\"Empirical, no $x_{max}$\")\n",
    "results.plot_ccdf(linewidth=3, label='Empirical Data')\n",
    "\n",
    "fig.set_ylabel(\"p(X)\")\n",
    "fig.set_xlabel(r\"Volatility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit = powerlaw.Fit(data, discrete=False)\n",
    "####\n",
    "fit.distribution_compare('power_law', 'lognormal')\n",
    "fig = fit.plot_ccdf(linewidth=3, label='Empirical Data')\n",
    "fit.power_law.plot_ccdf(ax=fig, color='r', linestyle='--', label='Power law fit')\n",
    "fit.lognormal.plot_ccdf(ax=fig, color='g', linestyle='--', label='Lognormal fit')\n",
    "####\n",
    "fig.set_ylabel(u\"p(X≥x)\")\n",
    "fig.set_xlabel(\"Roger-Satchell Realised Volatility Estimator\")\n",
    "handles, labels = fig.get_legend_handles_labels()\n",
    "_=fig.legend(handles, labels, loc=3)\n",
    "plt.savefig('/home/ak/Documents/Research/Papers/figures/' + 'RogSatchDistroComp' + '.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = powerlaw.Fit(data, discrete=False, xmax=None)\n",
    "FigCCDFmax = fit.plot_ccdf(color='b', label=r\"Empirical, no $x_{max}$\")\n",
    "fit.power_law.plot_ccdf(color='b', linestyle='--', ax=FigCCDFmax, label=r\"Fit, no $x_{max}$\")\n",
    "fit = powerlaw.Fit(data, discrete=True, xmax=1000)\n",
    "fit.plot_ccdf(color='r', label=r\"Empirical, $x_{max}=1000$\")\n",
    "fit.power_law.plot_ccdf(color='r', linestyle='--', ax=FigCCDFmax, label=r\"Fit, $x_{max}=1000$\")\n",
    "#x, y = powerlaw.ccdf(data, xmax=max(data))\n",
    "#fig1.plot(x,y)\n",
    "####\n",
    "#FigCCDFmax.set_ylabel(r\"$p(X\\geq x)$\")\n",
    "FigCCDFmax.set_ylabel(u\"p(X≥x)\")\n",
    "FigCCDFmax.set_xlabel(r\"Roger-Satchell Realised Volatility Estimator\")\n",
    "handles, labels = FigCCDFmax.get_legend_handles_labels()\n",
    "leg = FigCCDFmax.legend(handles, labels, loc=3)\n",
    "leg.draw_frame(False)\n",
    "plt.savefig('/home/ak/Documents/Research/Papers/figures/' + 'RogSatchDCumDFwithLimits' + '.png', dpi=150)\n",
    "# figname = 'FigCCDFmax'\n",
    "# savefig(figname+'.png', bbox_inches='tight')\n",
    "# savefig(figname+'.tiff', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(style=\"white\")\n",
    "\n",
    "# # Load the example mpg dataset\n",
    "# mpg = sns.load_dataset(\"mpg\")\n",
    "\n",
    "# # Plot miles per gallon against horsepower with other semantics\n",
    "# sns.relplot(x=\"horsepower\", y=\"mpg\", hue=\"origin\", size=\"weight\",\n",
    "#             sizes=(40, 400), alpha=.5, palette=\"muted\",\n",
    "#             height=6, data=mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.exponential?\n",
    "\n",
    "target = 250\n",
    "beta = 1.0/target\n",
    "\n",
    "Y = np.random.exponential(beta, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and histograms\n",
    "def generateData():\n",
    "    global x,y\n",
    "    target = 250\n",
    "    beta = 1.0/target\n",
    "    x = np.random.normal(size=250)\n",
    "    y = np.random.exponential(beta,size=250)\n",
    "    \n",
    "def plotData():\n",
    "    global x,y\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(2,2,1)\n",
    "    plt.hist(x,bins=20,color='green',alpha=0.8,align='mid')\n",
    "    plt.title('X variable distribution')\n",
    "    fig.add_subplot(2,2,3)\n",
    "    plt.scatter(x,y,marker=\"o\",alpha=0.8)\n",
    "    fig.add_subplot(2,2,4)\n",
    "    plt.title('Joint X,Y')\n",
    "    plt.hist(y,bins=20,orientation='horizontal',color='red',alpha=0.8,align='mid')\n",
    "    plt.title('Y variable distribution')    \n",
    "    plt.show()\n",
    "\n",
    "def generateCopulas():\n",
    "    global x,y\n",
    "    fig = plt.figure()\n",
    "\n",
    "    frank = Copula(x,y,family='frank')\n",
    "    uf,vf = frank.generate_uv(1000)\n",
    "    fig.add_subplot(2,2,1)\n",
    "    plt.scatter(uf,vf,marker='.',color='blue')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Frank copula')\n",
    "\n",
    "    clayton = Copula(x,y,family='clayton')\n",
    "    uc,vc = clayton.generate_uv(1000)\n",
    "    fig.add_subplot(2,2,2)\n",
    "    plt.scatter(uc,vc,marker='.',color='red')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "    plt.title('Clayton copula')\n",
    "\n",
    "#     gumbel = Copula(x,y,family='gumbel')\n",
    "#     ug,vg = gumbel.generate_uv(1000)\n",
    "#     fig.add_subplot(2,2,3)\n",
    "#     plt.scatter(ug,vg,marker='.',color='green')\n",
    "#     plt.ylim(0,1)\n",
    "#     plt.xlim(0,1)\n",
    "#     plt.title('Gumbel copula')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateData()\n",
    "plotData()\n",
    "generateCopulas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
