{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c3c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import multiprocessing\n",
    "import time\n",
    "# sys.path.append(('/home/ak/Research/PaperCode/stylised_facts'))\n",
    "# sys.path.append('/home/ak/Research/PaperCode/stylised_facts')\n",
    "# import stylised_facts_data_utilities as sfd_utils\n",
    "# import lob_for_futures as lobfut\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# standard_scaler = StandardScaler()\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "# sys.path.insert(0, '/directory/tothe/handshakefile/')\n",
    "# sys.path.append('/home/ak/Documents/PaperCode/stylised_facts')\n",
    "# ## data files\n",
    "# laptop_OS_folder = '/media/ak/T71/FuturesDataSemiProcessed'\n",
    "# LaCie_ProcessedData = '/media/ak/LaCie/ProcessedSampledData/'\n",
    "# # returns_data = '/media/ak/T7/August11th2022Experiments/Returns/'\n",
    "t7 = '/media/ak/T71/'\n",
    "t7_folder = os.path.join(t7, 'FuturesDataSemiProcessed')\n",
    "# # june_ext = os.path.join(t7, 'June4th2022Experiments')\n",
    "# # returns_data = [f for f in os.listdir(june_ext) if '_returns' in f]\n",
    "# experimentsLocation = '/media/ak/T71/August11th2022Experiments/'\n",
    "\n",
    "# # here i start with RX1 to do all the experiments in one go\n",
    "# symbols = os.listdir(laptop_OS_folder)\n",
    "\n",
    "\n",
    "# # symbol_test_folder = os.path.join(laptop_OS_folder, symbols[0])\n",
    "# rx_folder = os.path.join(laptop_OS_folder, 'RX1')\n",
    "# du_folder = os.path.join(t7_folder,  'DU1')                                                                       , 'FB1')\n",
    "# make this a bit more dynamic to take any function in here\n",
    "# files = os.listdir(du_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316f3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_experiment_data(chosen_df):\n",
    "    \"\"\"\n",
    "    # this is somewhat unit-tested in the August 7th 2022 notebook\n",
    "    # function to produce dataframes for experiments\n",
    "    # input: chosen df - this is a dataframe that we apply the microstructure features and the vol estimation features\n",
    "    # output: experiment - dataframe with the features we want experiments for\n",
    "    # written in August 2022\n",
    "    # re-write it as part of the _init_ file\n",
    "\n",
    "    \"\"\"\n",
    "    chosen_df_micro = lobfut.apply_micro_structure_features(chosen_df)  # get micro structure df\n",
    "    vol_class = lobfut.volatilityEstimation(chosen_df)  # get the vol class\n",
    "\n",
    "    # features I need: micro_price changes / vols /skews /etc:\n",
    "\n",
    "    experiment_df = chosen_df_micro.loc[:, ['micro_price', 'price_imbalance',\n",
    "                                            'pct_change_micro_price', 'weighted_activity_spread', ]]\n",
    "    experiment_df['GK_vol'] = pd.Series(\n",
    "        list(vol_class.garmanKlass(5)))  # get a sample of Garman - Klass resampled for 5 clicks\n",
    "    experiment_df['arrival_rates'] = pd.Series(\n",
    "        vol_class.arrival_rates().reshape(vol_class.arrival_rates().shape[0], )).replace([np.inf, -np.inf],\n",
    "                                                                                         0).fillna(0)\n",
    "    X = experiment_df.pct_change_micro_price.replace([np.inf, -np.inf], 0).values.reshape(-1, 1)\n",
    "    norm_scaler = StandardScaler().fit(X)  # normalised scaling by mean and std\n",
    "    min_max_scaler = MinMaxScaler().fit(X)  # min max scaling\n",
    "    try:\n",
    "        experiment_df['returns_normalised'] = norm_scaler.transform(\n",
    "            X)  # use this format to get rid of the prior issues\n",
    "        experiment_df['returns_mix_max'] = min_max_scaler.transform(X)  # get both issues of\n",
    "        rs, rk = vol_class.realised_skewness_kurtosis()  # get skew/kurt\n",
    "\n",
    "        experiment_df['skew'] = pd.Series(list(rs))\n",
    "        experiment_df['kurt'] = pd.Series(list(rk))\n",
    "\n",
    "        experiment_df['median_traded_volume'] = chosen_df_micro[['total_traded_volume_open',\n",
    "                                                                 'total_traded_volume_high',\n",
    "                                                                 'total_traded_volume_low',\n",
    "                                                                 'total_traded_volume_close']].quantile(0.5, axis=1)\n",
    "        experiment_df['jumps_test'] = pd.Series(vol_class.jumps_test(rollingWindow=5, sampling_param=0))\n",
    "        experiment_df['relz_var'] = pd.Series(vol_class.realised_variance(rollingWindow=5))\n",
    "        experiment_df['trip_quart'] = pd.Series(vol_class.tripower_quarticity(rollingWindow=5, sampling_param=0))\n",
    "\n",
    "        experiment_df = experiment_df.replace([np.inf, -np.inf], 0).fillna(0)  # final clean up\n",
    "    except ValueError:\n",
    "        print(\"error\")\n",
    "        pass\n",
    "    experiment_df = experiment_df.replace([np.inf, -np.inf], 0).fillna(0)  # final clean up\n",
    "\n",
    "    return experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27e1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'RX1'\n",
    "def produce_and_dump(files_idx_, symbol_):\n",
    "    symbol = symbol_  # and this\n",
    "    symbol_folder_path = os.path.join(t7_folder, str(symbol))\n",
    "    all_files = os.listdir(symbol_folder_path)\n",
    "    files = [f for f in all_files if str('Returns_') not in f]\n",
    "\n",
    "    choice_bar = 'dollar'  # change this\n",
    "    date_idx = files[files_idx_].split(\".\")[0]\n",
    "    print(date_idx)\n",
    "\n",
    "    idx_file_path = os.path.join(symbol_folder_path,\n",
    "                                 files[files_idx_])  # the input here needs to be dynamic not du_folder or rx_folder\n",
    "    choice_df = pd.read_pickle(idx_file_path)[date_idx][choice_bar]\n",
    "    exp_df = produce_experiment_data(choice_df)\n",
    "    pickle_out_returns = os.path.join(experimentsLocation, \"\".join(\n",
    "        (str(symbol) + \"_\" + str(choice_bar) + \"_\" + str(date_idx) + \"_exp_df.pkl\")))\n",
    "    pickle.dump(exp_df, open(pickle_out_returns, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('saved:', pickle_out_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd5567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'YM1'  # and this\n",
    "symbol_folder_path = os.path.join(t7_folder, str(symbol))\n",
    "all_files = os.listdir(symbol_folder_path)\n",
    "files =[f for f in all_files if str('Returns_') not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513bfed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181022\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lobfut' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e46f73c7f126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproduce_and_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'YM1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-74058aa123a6>\u001b[0m in \u001b[0;36mproduce_and_dump\u001b[0;34m(files_idx_, symbol_)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                  files[files_idx_])  # the input here needs to be dynamic not du_folder or rx_folder\n\u001b[1;32m     14\u001b[0m     \u001b[0mchoice_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice_bar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mexp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduce_experiment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     pickle_out_returns = os.path.join(experimentsLocation, \"\".join(\n\u001b[1;32m     17\u001b[0m         (str(symbol) + \"_\" + str(choice_bar) + \"_\" + str(date_idx) + \"_exp_df.pkl\")))\n",
      "\u001b[0;32m<ipython-input-5-b01416f5a870>\u001b[0m in \u001b[0;36mproduce_experiment_data\u001b[0;34m(chosen_df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mchosen_df_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlobfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_micro_structure_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_df\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get micro structure df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvol_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlobfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatilityEstimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_df\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the vol class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lobfut' is not defined"
     ]
    }
   ],
   "source": [
    "produce_and_dump(1, 'YM1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de7b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
