{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c3c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import multiprocessing\n",
    "import time\n",
    "sys.path.append(('/home/ak/Research/PaperCode/stylised_facts'))\n",
    "sys.path.append('/home/ak/Research/PaperCode/stylised_facts')\n",
    "import stylised_facts_data_utilities as sfd_utils\n",
    "import lob_for_futures as lobfut\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "sys.path.insert(0, '/directory/tothe/handshakefile/')\n",
    "sys.path.append('/home/ak/Documents/PaperCode/stylised_facts')\n",
    "## data files\n",
    "laptop_OS_folder = '/media/ak/T71/FuturesDataSemiProcessed'\n",
    "LaCie_ProcessedData = '/media/ak/LaCie/ProcessedSampledData/'\n",
    "# returns_data = '/media/ak/T7/August11th2022Experiments/Returns/'\n",
    "t7 = '/media/ak/T71/'\n",
    "t7_folder = os.path.join(t7, 'FuturesDataSemiProcessed')\n",
    "# june_ext = os.path.join(t7, 'June4th2022Experiments')\n",
    "# returns_data = [f for f in os.listdir(june_ext) if '_returns' in f]\n",
    "experimentsLocation = '/media/ak/T71/August11th2022Experiments/'\n",
    "\n",
    "# here i start with RX1 to do all the experiments in one go\n",
    "symbols = os.listdir(laptop_OS_folder)\n",
    "\n",
    "\n",
    "# symbol_test_folder = os.path.join(laptop_OS_folder, symbols[0])\n",
    "# rx_folder = os.path.join(laptop_OS_folder, 'RX1')\n",
    "# du_folder = os.path.join(t7_folder,  'DU1')                                                                       , 'FB1')\n",
    "# make this a bit more dynamic to take any function in here\n",
    "# files = os.listdir(du_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316f3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_experiment_data(chosen_df):\n",
    "    \"\"\"\n",
    "    # this is somewhat unit-tested in the August 7th 2022 notebook\n",
    "    # function to produce dataframes for experiments\n",
    "    # input: chosen df - this is a dataframe that we apply the microstructure features and the vol estimation features\n",
    "    # output: experiment - dataframe with the features we want experiments for\n",
    "    # written in August 2022\n",
    "    # re-write it as part of the _init_ file\n",
    "\n",
    "    \"\"\"\n",
    "    chosen_df_micro = lobfut.apply_micro_structure_features(chosen_df)  # get micro structure df\n",
    "    vol_class = lobfut.volatilityEstimation(chosen_df)  # get the vol class\n",
    "\n",
    "    # features I need: micro_price changes / vols /skews /etc:\n",
    "\n",
    "    experiment_df = chosen_df_micro.loc[:, ['micro_price', 'price_imbalance',\n",
    "                                            'pct_change_micro_price', 'weighted_activity_spread', ]]\n",
    "    experiment_df['GK_vol'] = pd.Series(\n",
    "        list(vol_class.garmanKlass(5)))  # get a sample of Garman - Klass resampled for 5 clicks\n",
    "    experiment_df['arrival_rates'] = pd.Series(\n",
    "        vol_class.arrival_rates().reshape(vol_class.arrival_rates().shape[0], )).replace([np.inf, -np.inf],\n",
    "                                                                                         0).fillna(0)\n",
    "    X = experiment_df.pct_change_micro_price.replace([np.inf, -np.inf], 0).values.reshape(-1, 1)\n",
    "    norm_scaler = StandardScaler().fit(X)  # normalised scaling by mean and std\n",
    "    min_max_scaler = MinMaxScaler().fit(X)  # min max scaling\n",
    "    try:\n",
    "        experiment_df['returns_normalised'] = norm_scaler.transform(\n",
    "            X)  # use this format to get rid of the prior issues\n",
    "        experiment_df['returns_mix_max'] = min_max_scaler.transform(X)  # get both issues of\n",
    "        rs, rk = vol_class.realised_skewness_kurtosis()  # get skew/kurt\n",
    "\n",
    "        experiment_df['skew'] = pd.Series(list(rs))\n",
    "        experiment_df['kurt'] = pd.Series(list(rk))\n",
    "\n",
    "        experiment_df['median_traded_volume'] = chosen_df_micro[['total_traded_volume_open',\n",
    "                                                                 'total_traded_volume_high',\n",
    "                                                                 'total_traded_volume_low',\n",
    "                                                                 'total_traded_volume_close']].quantile(0.5, axis=1)\n",
    "        experiment_df['jumps_test'] = pd.Series(vol_class.jumps_test(rollingWindow=5, sampling_param=0))\n",
    "        experiment_df['relz_var'] = pd.Series(vol_class.realised_variance(rollingWindow=5))\n",
    "        experiment_df['trip_quart'] = pd.Series(vol_class.tripower_quarticity(rollingWindow=5, sampling_param=0))\n",
    "\n",
    "        experiment_df = experiment_df.replace([np.inf, -np.inf], 0).fillna(0)  # final clean up\n",
    "    except ValueError:\n",
    "        print(\"error\")\n",
    "        pass\n",
    "    experiment_df = experiment_df.replace([np.inf, -np.inf], 0).fillna(0)  # final clean up\n",
    "\n",
    "    return experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27e1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'RX1'\n",
    "def produce_and_dump(files_idx_, symbol_):\n",
    "    symbol = symbol_  # and this\n",
    "    symbol_folder_path = os.path.join(t7_folder, str(symbol))\n",
    "    all_files = os.listdir(symbol_folder_path)\n",
    "    files = [f for f in all_files if str('Returns_') not in f]\n",
    "\n",
    "    choice_bar = 'dollar'  # change this\n",
    "    date_idx = files[files_idx_].split(\".\")[0]\n",
    "    print(date_idx)\n",
    "\n",
    "    idx_file_path = os.path.join(symbol_folder_path,\n",
    "                                 files[files_idx_])  # the input here needs to be dynamic not du_folder or rx_folder\n",
    "    choice_df = pd.read_pickle(idx_file_path)[date_idx][choice_bar]\n",
    "    exp_df = produce_experiment_data(choice_df)\n",
    "    pickle_out_returns = os.path.join(experimentsLocation, \"\".join(\n",
    "        (str(symbol) + \"_\" + str(choice_bar) + \"_\" + str(date_idx) + \"_exp_df.pkl\")))\n",
    "    pickle.dump(exp_df, open(pickle_out_returns, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('saved:', pickle_out_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd5567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'G_1'  # and this\n",
    "symbol_folder_path = os.path.join(t7_folder, str(symbol))\n",
    "all_files = os.listdir(symbol_folder_path)\n",
    "files =[f for f in all_files if str('Returns_') not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513bfed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180430\n",
      "Applying micro-structure features\n",
      "usd_volume_bucket\n",
      "1783.0        06:01:08.367000\n",
      "2674.0        06:01:08.372000\n",
      "3566.0        06:01:08.378000\n",
      "4457.0        06:01:08.379000\n",
      "5349.0        06:01:08.397000\n",
      "                   ...       \n",
      "14017892.0    19:59:53.006000\n",
      "14017893.0    19:59:55.151000\n",
      "14017901.0    19:59:56.074000\n",
      "14017917.0    20:00:00.052000\n",
      "14017933.0           20:03:17\n",
      "Name: TimeStamp_open, Length: 342223, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/anaconda3/envs/ds3_kernels/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ak/anaconda3/envs/ds3_kernels/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ak/anaconda3/envs/ds3_kernels/lib/python3.6/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /media/ak/T71/August11th2022Experiments/RX1_dollar_20180430_exp_df.pkl\n"
     ]
    }
   ],
   "source": [
    "produce_and_dump(1, 'RX1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de7b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
