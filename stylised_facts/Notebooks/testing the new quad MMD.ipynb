{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a8819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import freqopttest.util as util\n",
    "import freqopttest.data as data\n",
    "import freqopttest.kernel as kernel\n",
    "import freqopttest.tst as tst\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import freqopttest.glo as glo\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "# functions:\n",
    "\n",
    "def generate_column_pairs(num_columns):\n",
    "    \"\"\"\n",
    "    Generates pairs of columns for sliding window analysis.\n",
    "\n",
    "    Args:\n",
    "        num_columns (int): The total number of columns.\n",
    "\n",
    "    Yields:\n",
    "        tuple: A tuple containing the start index, end index, and shift for a pair of columns.\n",
    "               The start and end indices define the column pair, and the shift indicates the distance\n",
    "               by which one column is shifted with respect to the other.\n",
    "    \"\"\"\n",
    "    for window in range(1, num_columns):\n",
    "        for shift in range(1, num_columns - window + 1):\n",
    "            for start_point, end_point in itertools.combinations(range(num_columns), 2):\n",
    "                if end_point - start_point == window:\n",
    "                    yield start_point, end_point, shift\n",
    "\n",
    "\n",
    "def create_kgauss(sigma2, default_sigma2=None):\n",
    "    \"\"\"\n",
    "    Create a KGauss instance with the given sigma2 value, or use the default_sigma2 value if provided.\n",
    "\n",
    "    :param sigma2: float, the sigma2 value to use for creating the KGauss instance.\n",
    "    :param default_sigma2: float, optional, the default sigma2 value to use if the provided sigma2 is invalid.\n",
    "    :return: KGauss, the created KGauss instance.\n",
    "    :raise ValueError: if both sigma2 and default_sigma2 are invalid.\n",
    "    \"\"\"\n",
    "    if sigma2 > 0:\n",
    "        return kernel.KGauss(sigma2)\n",
    "    elif default_sigma2 is not None and default_sigma2 > 0:\n",
    "        print(\"Using default sigma2 value:\", default_sigma2)\n",
    "        return kernel.KGauss(default_sigma2)\n",
    "    else:\n",
    "        raise ValueError(\"Both sigma2 and default_sigma2 are invalid. Please provide a positive value for either.\")\n",
    "\n",
    "\n",
    "def simulate_null_spectral(weights, n_simulate=1000, seed=275):\n",
    "    \"\"\"\n",
    "    weights: chi-square weights (for the infinite weigted sum of chi squares)\n",
    "    Return the values of MMD^2 (NOT n*MMD^2) simulated from the null distribution by\n",
    "    the spectral method.\n",
    "    \"\"\"\n",
    "    # draw at most block_size values at a time\n",
    "    block_size = 400\n",
    "    D = weights.shape[0]  # len(weights)\n",
    "    mmds = np.zeros(n_simulate)\n",
    "    from_ind = 0\n",
    "\n",
    "    with util.NumpySeedContext(seed=seed):\n",
    "        while from_ind < n_simulate:\n",
    "            to_draw = min(block_size, n_simulate - from_ind)\n",
    "            # draw chi^2 random variables.\n",
    "            chi2 = np.random.randn(D, to_draw) ** 2\n",
    "            # an array of length to_draw\n",
    "            sim_mmds = 2.0 * weights.dot(chi2 - 1.0)\n",
    "            # store\n",
    "            end_ind = from_ind + to_draw\n",
    "            mmds[from_ind:end_ind] = sim_mmds\n",
    "            from_ind = end_ind\n",
    "    return mmds\n",
    "\n",
    "\n",
    "def chi_square_weights_H0(k, X):\n",
    "    \"\"\"\n",
    "    Return a numpy array of the weights to be used as the weights in the\n",
    "    weighted sum of chi-squares for the null distribution of MMD^2.\n",
    "    - k: a Kernel\n",
    "    - X: n x d number array of n data points\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    # Gram matrix\n",
    "    K = k.eval(X, X)\n",
    "    # centring matrix. Not the most efficient way.\n",
    "    H = np.eye(n) - np.ones((n, n)) / float(n)\n",
    "    HKH = H.dot(K).dot(H)\n",
    "    # https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.eigvals.html\n",
    "    evals = np.linalg.eigvals(HKH)\n",
    "    evals = np.real(evals)\n",
    "    # sort in decreasing order\n",
    "    evals = -np.sort(-evals)\n",
    "    weights = evals / float(n) ** 2\n",
    "    return weights\n",
    "\n",
    "\n",
    "class MMDTester:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_data(self, start_point, end_point, shift, window):\n",
    "        min_length = min(self.df.iloc[:, start_point:end_point].shape[0],\n",
    "                         self.df.iloc[:, end_point + shift:end_point + 2 * shift].shape[0],\n",
    "                         self.df.iloc[:, start_point + window:end_point + window].shape[0])\n",
    "\n",
    "        X = np.array(self.df.iloc[:min_length, start_point:end_point])\n",
    "        Y = np.array(self.df.iloc[:min_length, end_point + shift:end_point + 2 * shift])\n",
    "        Z = np.array(self.df.iloc[:min_length, start_point + window:end_point + window])\n",
    "\n",
    "        return X, Y, Z\n",
    "\n",
    "    def perform_tests(self, X, Y, Z):\n",
    "        data_sample = data.TSTData(X, Y)\n",
    "        test_data_one = data.TSTData(X, Z)\n",
    "        test_data_two = data.TSTData(Y, Z)\n",
    "\n",
    "        tr, te = data_sample.split_tr_te(tr_proportion=0.9, seed=100)\n",
    "\n",
    "        med = util.meddistance(tr.stack_xy())\n",
    "        widths = [(med * f) for f in 2.0 ** np.linspace(0, 4, 25)]\n",
    "        try:\n",
    "\n",
    "            list_kernels = [kernel.KGauss(w ** 2) for w in widths]\n",
    "            print('using these', list_kernels)\n",
    "        except AssertionError:\n",
    "            print('setting sigma2 =1 as sigma2 > 0, must be > 0')\n",
    "            list_kernels = [create_kgauss(w ** 2, default_sigma2=1) for w in widths]\n",
    "\n",
    "        besti, powers = tst.LinearMMDTest.grid_search_kernel(tr, list_kernels, alpha=0.01)\n",
    "\n",
    "        plt.plot(widths, powers, 'o-')\n",
    "        plt.xlabel('Gaussian width')\n",
    "        plt.ylabel('test power')\n",
    "        plt.title('median distance = %.3g. Best width: %.3g' % (med, widths[besti]))\n",
    "        plt.show()\n",
    "\n",
    "        best_ker = list_kernels[besti]\n",
    "        lin_mmd_test = tst.LinearMMDTest(best_ker, alpha=0.01)\n",
    "\n",
    "        test_results_one = {\n",
    "            'widths': widths,\n",
    "            'med': med,\n",
    "            'besti': besti,\n",
    "            'powers': powers,\n",
    "            'med_on_test_data': util.meddistance(test_data_one.stack_xy()),\n",
    "            'test_result': lin_mmd_test.perform_test(test_data_one),\n",
    "            'test_variance': lin_mmd_test.variance(X, Z, best_ker),\n",
    "            'two_moments': lin_mmd_test.two_moments(X, Z, best_ker),\n",
    "            'compute_unbiased_linear_estimator': lin_mmd_test.compute_stat(test_data_one)\n",
    "        }\n",
    "\n",
    "        test_results_two = {\n",
    "            'test_result': lin_mmd_test.perform_test(test_data_two),\n",
    "            'test_variance': lin_mmd_test.variance(Y, Z, best_ker),\n",
    "            'med_on_test_data': util.meddistance(test_data_two.stack_xy()),\n",
    "            'two_moments': lin_mmd_test.two_moments(Y, Z, best_ker),\n",
    "            'compute_unbiased_linear_estimator': lin_mmd_test.compute_stat(test_data_two)\n",
    "        }\n",
    "\n",
    "        return test_results_one, test_results_two\n",
    "\n",
    "\n",
    "\n",
    "    def perform_quad_mmd_tests(self, start_point, end_point, shift, window):\n",
    "\n",
    "\n",
    "        X, Y, Z = self.get_data(start_point, end_point, shift, window)\n",
    "\n",
    "        # Initialize a dictionary to store the results\n",
    "        mmd_train_test_results = defaultdict(dict)\n",
    "\n",
    "        try:\n",
    "            tr_data = data.TSTData(X, Y)\n",
    "            test_data_one = data.TSTData(X, Z)\n",
    "            test_data_two = data.TSTData(Y, Z)\n",
    "\n",
    "            # training dictionary results\n",
    "            tr, te = tr_data.split_tr_te(tr_proportion=0.95, seed=10)  # is this necessary?!\n",
    "\n",
    "            xtr, ytr = tr.xy()\n",
    "            xytr = tr.stack_xy()\n",
    "            sig2 = util.meddistance(xytr, subsample=1000)\n",
    "            k = kernel.KGauss(sig2)\n",
    "            mean, var = tst.QuadMMDTest.h1_mean_var(xtr, ytr, k, is_var_computed=True)\n",
    "            Kx = k.eval(xtr, xtr)\n",
    "            Ky = k.eval(ytr, ytr)\n",
    "            Kxy = k.eval(xtr, ytr)\n",
    "            mean_gram, var_gram = tst.QuadMMDTest.h1_mean_var_gram(Kx, Ky, Kxy, k, True)\n",
    "            chi2_weights = chi_square_weights_H0(k, xytr)\n",
    "            sim_mmds = simulate_null_spectral(chi2_weights, n_simulate=2000)\n",
    "            # choose the best parameter and perform a test with permutations\n",
    "            med = util.meddistance(tr.stack_xy(), 1000)\n",
    "            list_gwidth = np.hstack(((med ** 2) * (2.0 ** np.linspace(-4, 4, 20))))\n",
    "            list_gwidth.sort()\n",
    "            list_kernels = [kernel.KGauss(gw2) for gw2 in list_gwidth]\n",
    "            list_kernels_verbose = [kernel.KGauss(gw2).__str__() for gw2 in list_gwidth]\n",
    "\n",
    "            # grid search to choose the best Gaussian width\n",
    "            besti, powers = tst.QuadMMDTest.grid_search_kernel(tr, list_kernels, alpha=0.05)\n",
    "            # perform test\n",
    "            best_ker = list_kernels[besti]\n",
    "            mmd_train_test_results[start_point]['perm_mmds1'] = tst.QuadMMDTest.permutation_list_mmd2(xtr, ytr, k,\n",
    "                                                                                                      n_permute=2000)\n",
    "\n",
    "        # Save the results in the mmd_train_test_results dictionary\n",
    "            mmd_train_test_results[start_point]['perm_mmds1'] = tst.QuadMMDTest.permutation_list_mmd2(xtr, ytr, k,\n",
    "                                                                                                      n_permute=2000)\n",
    "            mmd_train_test_results[start_point]['chi2_weights'] = chi2_weights\n",
    "            mmd_train_test_results[start_point]['sim_mmds'] = sim_mmds\n",
    "            mmd_train_test_results[start_point]['sig2'] = sig2\n",
    "            mmd_train_test_results[start_point]['Kxy'] = k.eval(xtr, ytr)\n",
    "            mmd_train_test_results[start_point]['mean'] = mean\n",
    "            mmd_train_test_results[start_point]['var'] = var\n",
    "            mmd_train_test_results[start_point]['Kxx'] = k.eval(xtr, xtr)\n",
    "            mmd_train_test_results[start_point]['Kyy'] = k.eval(ytr, ytr)\n",
    "            mmd_train_test_results[start_point]['mean_gram'] = mean_gram\n",
    "            mmd_train_test_results[start_point]['var_gram'] = var_gram\n",
    "            mmd_train_test_results[start_point]['med'] = util.meddistance(tr.stack_xy(), 1000)\n",
    "            mmd_train_test_results[start_point]['list_gwidth'] = list_gwidth.sort()\n",
    "            mmd_train_test_results[start_point]['list_kernels'] = list_kernels_verbose\n",
    "            mmd_train_test_results[start_point]['besti'] = besti\n",
    "            mmd_train_test_results[start_point]['powers'] = powers\n",
    "            mmd_train_test_results[start_point]['best_ker'] = best_ker.__str__()\n",
    "\n",
    "            alpha = 0.05\n",
    "            mmd_test = tst.QuadMMDTest(best_ker, n_permute=2000, alpha=alpha)\n",
    "            mmd_train_test_results[start_point]['XZ_test'] = mmd_test.perform_test(test_data_one)\n",
    "            mmd_train_test_results[start_point]['YZ_test'] = mmd_test.perform_test(test_data_two)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        return mmd_train_test_results\n",
    "\n",
    "    def analyze(self, start_point, end_point, shift, window):\n",
    "        X, Y, Z = self.get_data(start_point, end_point, shift, window)\n",
    "        return self.perform_tests(X, Y, Z)\n",
    "\n",
    "\n",
    "def analyze_column(mmd_tester, unpickled_df, start_point, end_point, shift, window):\n",
    "    try:\n",
    "        test_results_one, test_results_two = mmd_tester.analyze(start_point, end_point, shift, window)\n",
    "        col1, col2 = unpickled_df.columns[start_point], unpickled_df.columns[end_point + shift]\n",
    "        result_key = f\"{col1} vs {col2}, window={window}, shift={shift}\"\n",
    "        return {result_key: (test_results_one, test_results_two)}\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "class QuadMMDAnalysis(MMDTester):\n",
    "    def __init__(self, df, symbol, LinearMMDOutputFiles, bar_choice, variable, start_point, end_point, shift, window):\n",
    "        \"\"\"\n",
    "        Initialize QuadMMDAnalysis with the input data frame and other parameters.\n",
    "\n",
    "        :param df: Input data frame containing the data to be analyzed.\n",
    "        :param symbol: A string representing the symbol of the financial instrument.\n",
    "        :param output_directory: A string representing the path to the output directory.\n",
    "        :param bar_choice: A string representing the choice of bars (e.g., \"BarChoice\").\n",
    "        :param variable: A string representing the variable (e.g., \"Variable\").\n",
    "        :param start_point: An integer representing the starting column index for the analysis.\n",
    "        :param end_point: An integer representing the ending column index for the analysis.\n",
    "        :param shift: An integer representing the shift to be applied during the analysis.\n",
    "        :param window: An integer representing the window size to be used during the analysis.\n",
    "        \"\"\"\n",
    "        super().__init__(df)\n",
    "        self.symbol = symbol\n",
    "        self.LinearMMDOutputFiles = LinearMMDOutputFiles\n",
    "        self.bar_choice = bar_choice\n",
    "        self.variable = variable\n",
    "        self.start_point = start_point\n",
    "        self.end_point = end_point\n",
    "        self.shift = shift\n",
    "        self.window = window\n",
    "\n",
    "    def run_quad_mmd_analysis(self):\n",
    "        \"\"\"\n",
    "        Run the perform_quad_mmd_tests method with the parameters set as class attributes.\n",
    "\n",
    "        :return: A dictionary containing the results of the quad MMD analysis.\n",
    "        \"\"\"\n",
    "        # Run perform_quad_mmd_tests with the parameters set as class attributes\n",
    "        mmd_train_test_results = self.perform_quad_mmd_tests(self.start_point, self.end_point, self.shift, self.window)\n",
    "\n",
    "        # Print the results\n",
    "        print(mmd_train_test_results)\n",
    "        \n",
    "    def run_single_analysis(self, start_point, end_point, shift, window):\n",
    "        \"\"\"\n",
    "        Run the perform_quad_mmd_tests method for a single combination of start_point, end_point, shift, and window.\n",
    "        run_single_analysis that takes the start_point, end_point, shift, and window as arguments and returns a tuple containing the combination and its corresponding result.\n",
    "\n",
    "        :param start_point: The starting index of the column pair.\n",
    "        :param end_point: The ending index of the column pair.\n",
    "        :param shift: The shift to be applied during the analysis.\n",
    "        :param window: The window size to be used during the analysis.\n",
    "        :return: A tuple containing the combination of start_point, end_point, shift, window, and the result.\n",
    "        \"\"\"\n",
    "        self.start_point = start_point\n",
    "        self.end_point = end_point\n",
    "        self.shift = shift\n",
    "        self.window = window\n",
    "        result = self.run_quad_mmd_analysis()\n",
    "        return (start_point, end_point, shift, window, result)\n",
    "    \n",
    "    def run_multiple_quad_mmd_analyses(self, windows, shifts, n_jobs=-1):\n",
    "        \"\"\"\n",
    "        Run the perform_quad_mmd_tests method for multiple combinations of shifts and windows with parallelization.\n",
    "\n",
    "        :param windows: A list of integers representing the window sizes to be used during the analysis.\n",
    "        :param shifts: A list of integers representing the shifts to be applied during the analysis.\n",
    "        :param n_jobs: The number of parallel processes to be used during the analysis.\n",
    "        :return: A dictionary containing the results of the quad MMD analysis for all combinations.\n",
    "        \"\"\"\n",
    "        # Generate all possible combinations of column pairs, window sizes, and shifts\n",
    "        column_pairs = list(combinations(self.df.columns, 2))\n",
    "\n",
    "        # Create a list of arguments for the analyze_column function\n",
    "        args_list = []\n",
    "        for start_point, end_point in column_pairs:\n",
    "            for window in windows:\n",
    "                for shift in shifts:\n",
    "                    args_list.append((start_point, end_point, shift, window))\n",
    "\n",
    "        # Run quad MMD analysis for all combinations and store the results in a dictionary\n",
    "        results_dict = {}\n",
    "        if n_jobs == -1:\n",
    "            n_jobs = os.cpu_count() or 1\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            for args, result in executor.map(lambda args: self.run_single_analysis(*args), args_list):\n",
    "                results_dict[args] = result\n",
    "\n",
    "        return results_dict\n",
    "\n",
    "    def save_results_to_pickle(self, results, file_name):\n",
    "        output_file = os.path.join(self.output_directory, file_name)\n",
    "\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "        print(\"Results saved to:\", output_file)\n",
    "\n",
    "\n",
    "\n",
    "def analyze_column(unpickled_df, start_point, end_point, shift, window, mmd_tester):\n",
    "    try:\n",
    "        test_results_one, test_results_two = mmd_tester.analyze(start_point, end_point, shift, window)\n",
    "        col1, col2 = unpickled_df.columns[start_point], unpickled_df.columns[end_point + shift]\n",
    "        result_key = f\"{col1} vs {col2}, window={window}, shift={shift}\"\n",
    "        return {result_key: {'Test Results 1': test_results_one, 'Test Results 2': test_results_two}}\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b13426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load a dataframe here\n",
    "symbol = 'XM1'\n",
    "LinearMMDInputFiles = '/media/ak/T7/August11th2022Experiments/LinearMMDInputFiles/'\n",
    "bar_choice = 'tick'\n",
    "file = os.path.join(LinearMMDInputFiles,\n",
    "                    [f for f in os.listdir(LinearMMDInputFiles) if (str(symbol) and str(bar_choice)) in f][0])\n",
    "outputDir = '/media/ak/T7/August11th2022Experiments/LinearMMDOutputFiles'\n",
    "variables = ['n_F', 'list_H', 'list_H_intercept', 'tau', 'alpha', 'mfSpect']\n",
    "data_dict = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "608d2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of DataFrames with names from the dictionary keys\n",
    "dataframes = [pd.DataFrame(data_dict[key]).assign(name=key) for key in data_dict]\n",
    "\n",
    "n_f = data_dict['n_F']\n",
    "list_H = data_dict['list_H']\n",
    "tau_df = pd.DataFrame.from_dict(data_dict['tau'])\n",
    "alpha_df = pd.DataFrame.from_dict(data_dict['alpha'])\n",
    "\n",
    "# # # this is the processing code!\n",
    "unpickled_dataframe = tau_df  # THIS IS THE KEY PART\n",
    "mfdfa_var = 'tau'\n",
    "output_name = \"_\".join((str(symbol), str(bar_choice), 'processedQUADMMDresults', str(mfdfa_var)))\n",
    "num_columns = unpickled_dataframe.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e93ae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define MMDTester object\n",
    "mmd_tester = MMDTester(unpickled_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c04026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate all possible combinations of column pairs, window sizes, and shifts\n",
    "column_pairs = list(combinations(unpickled_dataframe.columns, 2))\n",
    "windows = range(5, 201, 5)\n",
    "shifts = range(1, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f940585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-15:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/home/ak/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nAttributeError: Can't pickle local object 'QuadMMDAnalysis.run_multiple_quad_mmd_analyses.<locals>.<lambda>'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112293/705442832.py\u001b[0m in \u001b[0;36mrun_multiple_quad_mmd_analyses\u001b[0;34m(self, windows, shifts, n_jobs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(buffer, notempty, send_bytes, writelock, close, ignore_epipe, onerror, queue_sem)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         \u001b[0;31m# serialize the data before acquiring the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mwacquire\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'QuadMMDAnalysis.run_multiple_quad_mmd_analyses.<locals>.<lambda>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112293/1368814655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Run the analysis for multiple combinations of shifts and windows using parallelization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquad_mmd_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_multiple_quad_mmd_analyses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_112293/705442832.py\u001b[0m in \u001b[0;36mrun_multiple_quad_mmd_analyses\u001b[0;34m(self, windows, shifts, n_jobs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread_wakeup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_management_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/timeSeries/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "bar_choice = \"tick\"\n",
    "variable = outputDir\n",
    "start_point = 0\n",
    "end_point = 1\n",
    "shift = 1\n",
    "window = 10\n",
    "df = unpickled_dataframe\n",
    "output_directory =outputDir\n",
    "# Define the range of window sizes and shifts\n",
    "windows = range(5, 101, 5)\n",
    "shifts = range(1, 3)\n",
    "quad_mmd_analysis = QuadMMDAnalysis(df, symbol, output_directory, bar_choice, variable, 0, 1, 1, 10)\n",
    "\n",
    "# Run the analysis for multiple combinations of shifts and windows using parallelization\n",
    "all_results = quad_mmd_analysis.run_multiple_quad_mmd_analyses(windows, shifts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8710b804",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112293/3056958119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the perform_quad_mmd_tests method\n",
    "start_point = 0\n",
    "end_point = 1\n",
    "shift = 1\n",
    "window = 10\n",
    "\n",
    "# Run perform_quad_mmd_tests\n",
    "mmd_train_test_results = mmd_tester.perform_quad_mmd_tests(start_point, end_point, shift, window)\n",
    "\n",
    "# Print the results\n",
    "print(mmd_train_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c00f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_train_test_results[0]['list_kernels']\n",
    "mmd_train_test_results[0]['best_ker'].split(\"=\")[-1].split(\")\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QuadMMDAnalysis instance with the parameters\n",
    "# symbol = \"Symbol\"\n",
    "output_directory = \"path/to/output/directory\"\n",
    "bar_choice = \"tick\"\n",
    "variable = outputDir\n",
    "start_point = 0\n",
    "end_point = 1\n",
    "shift = 1\n",
    "window = 10\n",
    "df = unpickled_dataframe\n",
    "quad_mmd_analysis = QuadMMDAnalysis(df, symbol, output_directory, bar_choice, variable, start_point, end_point, shift, window)\n",
    "\n",
    "# Run the quad MMD analysis\n",
    "results = quad_mmd_analysis.run_quad_mmd_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_train_test_results[0]['list_gwidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Create an instance of the MMDTester class outside the analyze_column function\n",
    "#     mmd_tester = MMDTester(unpickled_dataframe)\n",
    "\n",
    "#     # Use multiprocessing to analyze the data in parallel\n",
    "#     with Pool(processes=cpu_count()) as pool:\n",
    "#         results = pool.starmap(analyze_column,\n",
    "#                                [(unpickled_dataframe, arg[0], arg[1], arg[2], arg[3], mmd_tester) for arg in args_list])\n",
    "\n",
    "#     # Combine the results into a single dictionary\n",
    "#     result_dict_nested = {}\n",
    "#     for r in results:\n",
    "#         if r:\n",
    "#             result_dict_nested.update(r)\n",
    "\n",
    "#     # Save the results to a pickle file\n",
    "#     output_file = os.path.join(outputDir, str(output_name) + \".pickle\")\n",
    "\n",
    "#     result_list = []\n",
    "#     for key, value in result_dict_nested.items():\n",
    "#         col_pair, window, shift = key.split(', ')\n",
    "#         result_list.append({\n",
    "#             \"Column Pair\": col_pair,\n",
    "#             \"Window\": window,\n",
    "#             \"Shift\": shift,\n",
    "#             \"Test Results 1\": value[\"Test Results 1\"],\n",
    "#             \"Test Results 2\": value[\"Test Results 2\"],\n",
    "#         })\n",
    "\n",
    "#     with open(output_file, \"wb\") as f:\n",
    "#         pickle.dump(result_list, f)\n",
    "\n",
    "#     print(\"Results saved to:\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:timeSeries] *",
   "language": "python",
   "name": "conda-env-timeSeries-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
