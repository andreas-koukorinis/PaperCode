{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'iris' (multiclass) dataset...done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a snippet of code showing how to select the hyper-parameters\n",
    "of a MKL method using boolean kernels\n",
    "Author: Ivano Lauriola, ivano.lauriola@phd.unipd.it\n",
    "'''\n",
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "\n",
    "\n",
    "\n",
    "#load data\n",
    "print ('loading \\'iris\\' (multiclass) dataset...', end='')\n",
    "from sklearn.datasets import load_iris\n",
    "ds = load_iris()\n",
    "X,Y = ds.data, ds.target\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...done\n",
      "computing monotone Conjunctive Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "#boolean kernels can be applied on binary-valued data, i.e. {0,1}.\n",
    "#in this example, we binarize a real-valued dataset\n",
    "#in this example, we binarize a real-valued dataset\n",
    "from MKLpy.preprocessing import binarization\n",
    "binarizer = binarization.AverageBinarizer()\n",
    "Xbin = binarizer.fit_transform(X,Y)\n",
    "print ('done')\n",
    "\n",
    "#compute normalized homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing monotone Conjunctive Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.preprocessing import kernel_normalization\n",
    "#WARNING: the maximum arity of the conjunctive kernel depends on the number of active variables for each example,\n",
    "# that is 4 in the case of iris dataset binarized\n",
    "KL = [kernel_normalization(pairwise.monotone_conjunctive_kernel(Xbin, c=c)) for c in range(5)]\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning lambda for EasyMKL..."
     ]
    }
   ],
   "source": [
    "\n",
    "#train/test KL split (N.B. here we split a kernel list directly)\n",
    "from MKLpy.model_selection import train_test_split\n",
    "KLtr,KLte,Ytr,Yte = train_test_split(KL, Y, test_size=.3, random_state=42)\n",
    "\n",
    "#MKL algorithms\n",
    "from MKLpy.algorithms import EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "print ('tuning lambda for EasyMKL...', end='')\n",
    "base_learner = SVC(C=10000)\t#simil hard-margin svm\n",
    "best_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL...done\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "training EasyMKL...done\n",
      "[-9.71714556e-17  6.14493694e-02  1.64774518e-01  3.03677199e-01\n",
      "  4.70098913e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "# #select the base-learner\n",
    "# #MKL algorithms use a hard-margin as base learned (or KOMD in the case of EasyMKL). It is possible to define a different base learner\n",
    "# from sklearn.svm import SVC\n",
    "# base_learner = SVC(C=0.1)\n",
    "# clf = EasyMKL(learner=base_learner)\n",
    "# clf = clf.fit(KLtr,Ytr)\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)\n",
    "\n",
    "# #evaluate the solution\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# y_pred = clf.predict(KLte)\t\t\t\t\t#predictions\n",
    "# y_score = clf.decision_function(KLte)\t\t#rank\n",
    "# accuracy = accuracy_score(Yte, y_pred)\n",
    "# roc_auc = roc_auc_score(Yte, y_score)\n",
    "# print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=AverageMKL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'iris' dataset...done [3 classes]\n",
      "computing Homogeneous Polynomial Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "print ('loading \\'iris\\' dataset...', end='')\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "ds = load_iris()\n",
    "X,Y = ds.data, ds.target\n",
    "classes = np.unique(Y)\n",
    "print ('done [%d classes]' % len(classes))\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "KL = [pairwise.homogeneous_polynomial_kernel(X, degree=d) for d in range(1,4)]\n",
    "KLconjuctive = [kernel_normalization(pairwise.monotone_conjunctive_kernel(Xbin, c=c)) for c in range(5)]\n",
    "print ('done')\n",
    "\n",
    "\n",
    "# #MKL algorithms\n",
    "# from MKLpy.algorithms import EasyMKL\n",
    "# print ('training EasyMKL...', end='')\n",
    "# clf = EasyMKL(lam=0.1).fit(KL,Y)\t\t#combining kernels with the EasyMKL algorithm\n",
    "# #multiclass_strategy should be 'ovo' for one-vs-one decomposition strategy, and 'ova' for one-vs-all/rest strategy\n",
    "# print ('done')\n",
    "\n",
    "# print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'breast cancer' dataset...done\n",
      "preprocessing data...done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load data\n",
    "print ('loading \\'breast cancer\\' dataset...', end='')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "ds = load_breast_cancer()\n",
    "X,Y = ds.data, ds.target\n",
    "print ('done')\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "X = rescale_01(X)\t#feature scaling in [0,1]\n",
    "X = normalization(X) #||X_i||_2^2 = 1\n",
    "\n",
    "#train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtr,Xte,Ytr,Yte = train_test_split(X,Y, test_size=.25, random_state=42)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0         1         2         3         4         5         6   \\\n",
       " 0    0.186819  0.008124  0.195765  0.130417  0.212891  0.283987  0.252112   \n",
       " 1    0.350623  0.148599  0.335707  0.273452  0.158034  0.099095  0.111001   \n",
       " 2    0.265229  0.172085  0.262692  0.198170  0.226784  0.190056  0.203944   \n",
       " 3    0.068534  0.117710  0.076171  0.033569  0.264663  0.264676  0.184507   \n",
       " 4    0.321793  0.079991  0.322352  0.249963  0.219853  0.177728  0.237001   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 564  0.293842  0.182614  0.289016  0.241245  0.224405  0.126078  0.243362   \n",
       " 565  0.297467  0.299697  0.288727  0.226579  0.194918  0.123186  0.161273   \n",
       " 566  0.276412  0.377192  0.270666  0.184042  0.174963  0.154426  0.131604   \n",
       " 567  0.209616  0.215777  0.216436  0.154705  0.191330  0.256976  0.267753   \n",
       " 568  0.039172  0.532851  0.030323  0.016900  0.000000  0.078996  0.000000   \n",
       " \n",
       "            7         8         9   ...        20        21        22  \\\n",
       " 0    0.262142  0.246097  0.217110  ...  0.222580  0.050744  0.239624   \n",
       " 1    0.190132  0.207055  0.077045  ...  0.330865  0.165498  0.294293   \n",
       " 2    0.280305  0.224706  0.093149  ...  0.245338  0.158775  0.224197   \n",
       " 3    0.170564  0.253227  0.326213  ...  0.081002  0.125894  0.078730   \n",
       " 4    0.264830  0.193253  0.095438  ...  0.265521  0.063314  0.258984   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 564  0.293995  0.143243  0.056237  ...  0.265423  0.163215  0.245369   \n",
       " 565  0.232607  0.167057  0.054062  ...  0.267991  0.334164  0.248985   \n",
       " 566  0.159999  0.162523  0.083376  ...  0.238675  0.357631  0.230691   \n",
       " 567  0.245682  0.219596  0.138356  ...  0.206044  0.237490  0.217338   \n",
       " 568  0.000000  0.282788  0.198709  ...  0.057678  0.519624  0.046300   \n",
       " \n",
       "            23        24        25        26        27        28        29  \n",
       " 0    0.161599  0.215539  0.222048  0.203877  0.327010  0.214580  0.150185  \n",
       " 1    0.237266  0.189476  0.084263  0.105202  0.348459  0.127346  0.121507  \n",
       " 2    0.165139  0.213238  0.169931  0.158629  0.368215  0.178014  0.094113  \n",
       " 3    0.030667  0.298639  0.265541  0.178974  0.288659  0.326213  0.252394  \n",
       " 4    0.174500  0.223436  0.088082  0.163217  0.285279  0.080462  0.072847  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 564  0.192771  0.196379  0.076027  0.139697  0.324296  0.041553  0.044999  \n",
       " 565  0.181598  0.143402  0.076478  0.122744  0.267415  0.094883  0.035522  \n",
       " 566  0.140092  0.171327  0.166183  0.165030  0.295861  0.078154  0.092233  \n",
       " 567  0.130744  0.201506  0.265289  0.243826  0.296149  0.161673  0.147095  \n",
       " 568  0.021778  0.131835  0.038295  0.000000  0.000000  0.273523  0.106972  \n",
       " \n",
       " [569 rows x 30 columns], None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X), print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Homogeneous Polynomial Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(11)]\n",
    "KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(11)]\n",
    "print ('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL...done\n",
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "training EasyMKL...done\n",
      "[-1.08387208e-24  1.35673700e-02  2.76971359e-02  4.30853034e-02\n",
      "  6.02816730e-02  7.96701534e-02  1.01481855e-01  1.25820437e-01\n",
      "  1.52689783e-01  1.82019528e-01  2.13686761e-01]\n"
     ]
    }
   ],
   "source": [
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923, roc AUC score: 0.988\n"
     ]
    }
   ],
   "source": [
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = clf.predict(KLte) #predictions\n",
    "y_score = clf.decision_function(KLte) #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "\n",
    "#select the base-learner\n",
    "#MKL algorithms use a hard-margin as base learned (or KOMD in the case of EasyMKL). It is possible to define a different base learner\n",
    "from sklearn.svm import SVC\n",
    "base_learner = SVC(C=0.1, kernel='rbf')\n",
    "clf = EasyMKL(learner=base_learner)\n",
    "clf = clf.fit(KLtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.predict(KLte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lam in [0, 0.01, 0.1, 0.2, 0.9, 1]:\t#possible lambda values for the EasyMKL algorithm\n",
    "    #MKLpy.model_selection.cross_val_predict performs the cross validation automatically, it optimizes the accuracy\n",
    "    #the counterpart cross_val_score optimized the roc_auc_score (use score='roc_auc')\n",
    "    #WARNING: these functions will change in the next version\n",
    "    scores = cross_val_predict(KLtr, Ytr, EasyMKL(learner=base_learner, lam=lam), n_folds=5, score='accuracy')\n",
    "    acc = np.mean(scores)\n",
    "    if not best_results or best_results['score'] < acc:\n",
    "        best_results = {'lam' : lam, 'score' : acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "accuracy on the test set: 0.923, with lambda=0.00\n"
     ]
    }
   ],
   "source": [
    "#evaluation on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('done')\n",
    "clf = EasyMKL(learner=base_learner, lam=best_results['lam']).fit(KLtr,Ytr)\n",
    "y_pred = clf.predict(KLte)\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "print ('accuracy on the test set: %.3f, with lambda=%.2f' % (accuracy, best_results['lam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#   data_dir: main directory , data_only_drive: the big drive where everything is saved\n",
    "# data only dir: main drive that has the\n",
    "data_dir = os.getenv('FINANCE_DATA')\n",
    "data_only_drive = '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'  # external date only drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-07c68aecf263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_only_drive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'"
     ]
    }
   ],
   "source": [
    "os.listdir(data_only_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
