{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'iris' (multiclass) dataset...done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a snippet of code showing how to select the hyper-parameters\n",
    "of a MKL method using boolean kernels\n",
    "Author: Ivano Lauriola, ivano.lauriola@phd.unipd.it\n",
    "'''\n",
    "import MKLpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm as svm\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "#load data\n",
    "print ('loading \\'iris\\' (multiclass) dataset...', end='')\n",
    "from sklearn.datasets import load_iris\n",
    "ds = load_iris()\n",
    "X,Y = ds.data, ds.target\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...done\n",
      "computing monotone Conjunctive Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "#boolean kernels can be applied on binary-valued data, i.e. {0,1}.\n",
    "#in this example, we binarize a real-valued dataset\n",
    "#in this example, we binarize a real-valued dataset\n",
    "from MKLpy.preprocessing import binarization\n",
    "binarizer = binarization.AverageBinarizer()\n",
    "Xbin = binarizer.fit_transform(X,Y)\n",
    "print ('done')\n",
    "\n",
    "#compute normalized homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing monotone Conjunctive Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.preprocessing import kernel_normalization\n",
    "#WARNING: the maximum arity of the conjunctive kernel depends on the number of active variables for each example,\n",
    "# that is 4 in the case of iris dataset binarized\n",
    "KL = [kernel_normalization(pairwise.monotone_conjunctive_kernel(Xbin, c=c)) for c in range(5)]\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning lambda for EasyMKL..."
     ]
    }
   ],
   "source": [
    "\n",
    "#train/test KL split (N.B. here we split a kernel list directly)\n",
    "from MKLpy.model_selection import train_test_split\n",
    "KLtr,KLte,Ytr,Yte = train_test_split(KL, Y, test_size=.3, random_state=42)\n",
    "\n",
    "#MKL algorithms\n",
    "from MKLpy.algorithms import EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "print ('tuning lambda for EasyMKL...', end='')\n",
    "base_learner = SVC(C=10000)\t#simil hard-margin svm\n",
    "best_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL..."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AverageMKL' object has no attribute 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-64088d973ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# clf = clf.fit(KLtr,Ytr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'training AverageMKL...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMKL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKLtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#a wrapper for averaging kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m#print the weights of the combination of base kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/resrPyth3/lib/python3.6/site-packages/MKLpy/algorithms/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass_\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mmetaClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsOneMKLClassifier\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass_strategy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OvO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1v1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOneVsRestMKLClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetaClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mker_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mker_matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/resrPyth3/lib/python3.6/site-packages/MKLpy/multiclass.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, clf1, verbose)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AverageMKL' object has no attribute 'estimator'"
     ]
    }
   ],
   "source": [
    "\n",
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "# #select the base-learner\n",
    "# #MKL algorithms use a hard-margin as base learned (or KOMD in the case of EasyMKL). It is possible to define a different base learner\n",
    "# from sklearn.svm import SVC\n",
    "# base_learner = SVC(C=0.1)\n",
    "# clf = EasyMKL(learner=base_learner)\n",
    "# clf = clf.fit(KLtr,Ytr)\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)\n",
    "\n",
    "# #evaluate the solution\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# y_pred = clf.predict(KLte)\t\t\t\t\t#predictions\n",
    "# y_score = clf.decision_function(KLte)\t\t#rank\n",
    "# accuracy = accuracy_score(Yte, y_pred)\n",
    "# roc_auc = roc_auc_score(Yte, y_score)\n",
    "# print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "clf=AverageMKL()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'iris' dataset...done [3 classes]\n",
      "computing Homogeneous Polynomial Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "print ('loading \\'iris\\' dataset...', end='')\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "ds = load_iris()\n",
    "X,Y = ds.data, ds.target\n",
    "classes = np.unique(Y)\n",
    "print ('done [%d classes]' % len(classes))\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "KL = [pairwise.homogeneous_polynomial_kernel(X, degree=d) for d in range(1,4)]\n",
    "KLconjuctive = [kernel_normalization(pairwise.monotone_conjunctive_kernel(Xbin, c=c)) for c in range(5)]\n",
    "print ('done')\n",
    "\n",
    "\n",
    "# #MKL algorithms\n",
    "# from MKLpy.algorithms import EasyMKL\n",
    "# print ('training EasyMKL...', end='')\n",
    "# clf = EasyMKL(lam=0.1).fit(KL,Y)\t\t#combining kernels with the EasyMKL algorithm\n",
    "# #multiclass_strategy should be 'ovo' for one-vs-one decomposition strategy, and 'ova' for one-vs-all/rest strategy\n",
    "# print ('done')\n",
    "\n",
    "# print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 'breast cancer' dataset...done\n",
      "preprocessing data...done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load data\n",
    "print ('loading \\'breast cancer\\' dataset...', end='')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "ds = load_breast_cancer()\n",
    "X,Y = ds.data, ds.target\n",
    "print ('done')\n",
    "\n",
    "'''\n",
    "WARNING: be sure that your matrix is not sparse! EXAMPLE:\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X,Y = load_svmlight_file(...)\n",
    "X = X.toarray()\n",
    "'''\n",
    "\n",
    "#preprocess data\n",
    "print ('preprocessing data...', end='')\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "X = rescale_01(X) #feature scaling in [0,1]\n",
    "X = normalization(X) #||X_i||_2^2 = 1\n",
    "\n",
    "#train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtr,Xte,Ytr,Yte = train_test_split(X,Y, test_size=.25, random_state=42)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(X), print(np.unique(Y))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Homogeneous Polynomial Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(11)]\n",
    "KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(11)]\n",
    "print ('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL...done\n",
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "training EasyMKL...done\n",
      "[-1.08387208e-24  1.35673700e-02  2.76971359e-02  4.30853034e-02\n",
      "  6.02816730e-02  7.96701534e-02  1.01481855e-01  1.25820437e-01\n",
      "  1.52689783e-01  1.82019528e-01  2.13686761e-01]\n"
     ]
    }
   ],
   "source": [
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923, roc AUC score: 0.988\n"
     ]
    }
   ],
   "source": [
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = clf.predict(KLte) #predictions\n",
    "y_score = clf.decision_function(KLte) #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "\n",
    "#select the base-learner\n",
    "#MKL algorithms use a hard-margin as base learned (or KOMD in the case of EasyMKL). It is possible to define a different base learner\n",
    "from sklearn.svm import SVC\n",
    "base_learner = SVC(C=0.1, kernel='rbf')\n",
    "clf = EasyMKL(learner=base_learner)\n",
    "clf = clf.fit(KLtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.predict(KLte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lam in [0, 0.01, 0.1, 0.2, 0.9, 1]:\t#possible lambda values for the EasyMKL algorithm\n",
    "    #MKLpy.model_selection.cross_val_predict performs the cross validation automatically, it optimizes the accuracy\n",
    "    #the counterpart cross_val_score optimized the roc_auc_score (use score='roc_auc')\n",
    "    #WARNING: these functions will change in the next version\n",
    "    scores = cross_val_predict(KLtr, Ytr, EasyMKL(learner=base_learner, lam=lam), n_folds=5, score='accuracy')\n",
    "    acc = np.mean(scores)\n",
    "    if not best_results or best_results['score'] < acc:\n",
    "        best_results = {'lam' : lam, 'score' : acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "accuracy on the test set: 0.923, with lambda=0.00\n"
     ]
    }
   ],
   "source": [
    "#evaluation on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('done')\n",
    "clf = EasyMKL(learner=base_learner, lam=best_results['lam']).fit(KLtr,Ytr)\n",
    "y_pred = clf.predict(KLte)\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "print ('accuracy on the test set: %.3f, with lambda=%.2f' % (accuracy, best_results['lam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#   data_dir: main directory , data_only_drive: the big drive where everything is saved\n",
    "# data only dir: main drive that has the\n",
    "workDrive = '/media/ak/WorkDrive/'\n",
    "mountDrive = '/media/ak/e7ab6eee-f896-4a12-9128-b31bcfb0cd38'  \n",
    "dataOnlyDrive = '/media/ak/DataOnly'# external date only drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only_drive = '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'  # external date only drive\n",
    "data_dir = os.getenv('FINANCE_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ak/FinData/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b6beaae69e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ak/FinData/'"
     ]
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ak/FinData/Labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-648ce50c1926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0midxSymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeaturesDates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxSymbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MODEL_BASED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midxDate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ak/FinData/Labels'"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = os.path.join(data_dir,'Labels')\n",
    "symbols =os.listdir(labels)\n",
    "idxSymbol = 2\n",
    "featuresDates = os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED')\n",
    "idxDate= 9\n",
    "\n",
    "featuresDateList = os.listdir(os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED'))\n",
    "\n",
    "\n",
    "featuresDateItems = os.path.join(os.path.join(data_dir,symbols[idxSymbol],'MODEL_BASED'), featuresDateList[3])\n",
    "\n",
    "listFeaturesPickle = os.listdir(featuresDateItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featuresDateItems' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b17ca778fd3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturesPickle\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesDateItems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlistFeaturesPickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'featuresDateItems' is not defined"
     ]
    }
   ],
   "source": [
    "featuresPickle =os.path.join(featuresDateItems,listFeaturesPickle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_file(file_, numb_):\n",
    "    return os.path.splitext(file_[numb_])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listFeaturesPickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7f19bacb8510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabelsDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistFeaturesPickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'listFeaturesPickle' is not defined"
     ]
    }
   ],
   "source": [
    "labelsDate = os.path.splitext(listFeaturesPickle[0])[0].split(\"_\")[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featuresPickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7a582657d0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle_to_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesPickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'featuresPickle' is not defined"
     ]
    }
   ],
   "source": [
    "pickle_to_file = pickle.load(open(featuresPickle, \"rb\"), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle_to_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8680f21218f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfischerFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_to_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgammaFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_to_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minformationFeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpickle_to_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mksiFeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpickle_to_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle_to_file' is not defined"
     ]
    }
   ],
   "source": [
    "fischerFeatures = pickle_to_file[0]\n",
    "gammaFeatures = pickle_to_file[2]\n",
    "informationFeatures= pickle_to_file[1]\n",
    "ksiFeatures= pickle_to_file[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symbols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-bf5da76184f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbolLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxSymbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NON_DIRECTIONAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'symbols' is not defined"
     ]
    }
   ],
   "source": [
    "symbolLabel = os.path.join(labels,symbols[idxSymbol],'NON_DIRECTIONAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symbolLabel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d611df42e89e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabelsFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelsDate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'symbolLabel' is not defined"
     ]
    }
   ],
   "source": [
    "labelsFile = os.path.join(symbolLabel,labelsDate+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labelsFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-44a4e67de85f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabelsDf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labelsFile' is not defined"
     ]
    }
   ],
   "source": [
    "labelsDf= pd.read_csv(labelsFile).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labelsDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3291f61f6055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlabelsDf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_PrMov__window_5__thres_arbitrary__0.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labelsDf' is not defined"
     ]
    }
   ],
   "source": [
    "labels =labelsDf['label_PrMov__window_5__thres_arbitrary__0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fischerFeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9c63ea1c276d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfischerFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fischerFeatures' is not defined"
     ]
    }
   ],
   "source": [
    "X_all = np.asarray(fischerFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5a5d90f4a41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_all' is not defined"
     ]
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b5bbf4a5f1ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescale_01\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#feature scaling in [0,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_normz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_rescaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#||X_i||_2^2 = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# X_normz= np.asanyarray(X_normz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# #train/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_all' is not defined"
     ]
    }
   ],
   "source": [
    "X_rescaled = rescale_01(X_all) #feature scaling in [0,1]\n",
    "X_normz = normalization(X_rescaled) #||X_i||_2^2 = 1\n",
    "# X_normz= np.asanyarray(X_normz)\n",
    "# #train/test split\n",
    "\n",
    "Xtr,Xte,Ytr,Yte = train_test_split(X_normz,Y_all, test_size=.85, random_state=42)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Homogeneous Polynomial Kernels...done\n"
     ]
    }
   ],
   "source": [
    "#compute homogeneous polynomial kernels with degrees 0,1,2,...,10.\n",
    "print ('computing Homogeneous Polynomial Kernels...', end='')\n",
    "from MKLpy.metrics import pairwise\n",
    "KLtr = [pairwise.homogeneous_polynomial_kernel(Xtr, degree=d) for d in range(11)]\n",
    "KLte = [pairwise.homogeneous_polynomial_kernel(Xte,Xtr, degree=d) for d in range(11)]\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL...done\n",
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "training EasyMKL...done\n",
      "[-1.08387208e-24  1.35673700e-02  2.76971359e-02  4.30853034e-02\n",
      "  6.02816730e-02  7.96701534e-02  1.01481855e-01  1.25820437e-01\n",
      "  1.52689783e-01  1.82019528e-01  2.13686761e-01]\n"
     ]
    }
   ],
   "source": [
    "#MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923, roc AUC score: 0.988\n"
     ]
    }
   ],
   "source": [
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_pred = clf.predict(KLte) #predictions\n",
    "y_score = clf.decision_function(KLte) #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "roc_auc = roc_auc_score(Yte, y_score)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "\n",
    "#select the base-learner\n",
    "#MKL algorithms use a hard-margin as base learned (or KOMD in the case of EasyMKL). It is possible to define a different base learner\n",
    "from sklearn.svm import SVC\n",
    "base_learner = SVC(C=0.1, kernel='rbf')\n",
    "clf = EasyMKL(learner=base_learner)\n",
    "clf = clf.fit(KLtr,Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training AverageMKL...done\n",
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "training EasyMKL...done\n",
      "[-1.08387208e-24  1.35673700e-02  2.76971359e-02  4.30853034e-02\n",
      "  6.02816730e-02  7.96701534e-02  1.01481855e-01  1.25820437e-01\n",
      "  1.52689783e-01  1.82019528e-01  2.13686761e-01]\n"
     ]
    }
   ],
   "source": [
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD\t#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "print ('training AverageMKL...', end='')\n",
    "clf = AverageMKL().fit(KLtr,Ytr)\t#a wrapper for averaging kernels\n",
    "print ('done')\n",
    "print(clf.weights)\t\t\t#print the weights of the combination of base kernels\n",
    "K_average = clf.ker_matrix\t#the combined kernel matrix\n",
    "\n",
    "\n",
    "print ('training EasyMKL...', end='')\n",
    "clf = EasyMKL(lam=0.1).fit(KLtr,Ytr)\t\t#combining kernels with the EasyMKL algorithm\n",
    "#lam is a hyper-parameter in [0,1]\n",
    "print ('done')\n",
    "print (clf.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
