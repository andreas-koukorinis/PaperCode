{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import sys\n",
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/MultiKernelLearning')\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "import jsonpickle\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "\n",
    "from fileutils import new_feature_utils as nfu\n",
    "from fileutils.new_feature_utils import CreateMarketFeatures\n",
    "import multiprocessing\n",
    "import mkl_data_processing as mkldp\n",
    "from matplotlib.ticker import ScalarFormatter,AutoMinorLocator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "styleFiles = os.listdir(mpl.get_configdir())\n",
    "styleFileIdx = 0\n",
    "\n",
    "plt.style.use(os.path.join(mpl.get_configdir(), styleFiles[styleFileIdx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_filepath(pickle_file):\n",
    "    pickle_to_file = pickle.load(open(pickle_file, \"rb\"), encoding='latin1')\n",
    "\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSPredictions/SimpleMKL/'\n",
    "symbols = sorted(os.listdir(files_location))\n",
    "#processed results path\n",
    "processed_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are doing symbol KGF.L and label Label_idx:_6\n",
      "total files for the symbol: 1836\n",
      "and for this label\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "symbolIDX =  12 #pick a symbol\n",
    "label_idx = 6 #pick a label\n",
    "label_string= 'Label_idx:_'+str(label_idx)\n",
    "print('you are doing symbol', symbols[symbolIDX], 'and label', label_string)\n",
    "# now we take out the files for the symbol \n",
    "symbol_path = os.path.join(files_location,str(sorted(symbols)[symbolIDX]))\n",
    "symbolFiles = os.listdir(os.path.join(files_location,str(sorted(symbols)[symbolIDX])))\n",
    "# now isolate all the label+ symbol combos\n",
    "symbolLabelFiles = [f for f in symbolFiles if str(label_string) in f]\n",
    "path_to_store = os.path.join(processed_location, symbols[symbolIDX])\n",
    "number_of_files = len(symbolLabelFiles) \n",
    "\n",
    "# this is the number of files that correspond to the label/symbol combo\n",
    "\n",
    "print('total files for the symbol:', len(symbolFiles))\n",
    "print('and for this label')\n",
    "print(number_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed/KGF.L'"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_chunks_keys = dict()\n",
    "chunks_list =list()\n",
    "keys_list = list()\n",
    "\n",
    "for file_to_load_idx in range(0,number_of_files):\n",
    "    # go through all of the files that are a combination of symbols and labels\n",
    "    file_to_load_path = os.path.join(os.path.join(files_location, str(symbols[symbolIDX])), symbolLabelFiles[file_to_load_idx])\n",
    "    if os.path.getsize(file_to_load_path)> 0:\n",
    "        # extract the key - these are the symbol feature path keys in the  main code\n",
    "        file_keys = list(open_pickle_filepath(file_to_load_path).keys()) # keys\n",
    "        keys_list.append(file_keys[0])\n",
    "        dates_chunks_keys[file_to_load_idx] = file_keys\n",
    "        chunks_list.append(open_pickle_filepath(file_to_load_path)[file_keys[0]])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame((np.unique(list(dates_chunks_keys.values()))))\n",
    "list_of_dfs_across_days = list()\n",
    "for chunk_list_item in range(0,len(chunks_list)-1):\n",
    "    chunk_list_item_dict = chunks_list[chunk_list_item]\n",
    "    chunk_list_item_keys = list(chunk_list_item_dict.keys())\n",
    "    list_of_dicts=list()\n",
    "    for key in chunk_list_item_keys:\n",
    "        list_of_dicts.append(pd.DataFrame(chunk_list_item_dict[key]))\n",
    "    list_of_dfs_across_days.append(pd.concat(list_of_dicts,axis=1).median(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.525\n",
       " accuracy        0.475\n",
       " f1- macro       0.220\n",
       " f1- micro       0.475\n",
       " f1- weighted    0.330\n",
       " precision       0.310\n",
       " recall          0.475\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.535\n",
       " accuracy        0.465\n",
       " f1- macro       0.220\n",
       " f1- micro       0.465\n",
       " f1- weighted    0.320\n",
       " precision       0.280\n",
       " recall          0.465\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.520\n",
       " accuracy        0.480\n",
       " f1- macro       0.220\n",
       " f1- micro       0.480\n",
       " f1- weighted    0.330\n",
       " precision       0.305\n",
       " recall          0.480\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.31\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.295\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.31\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.535\n",
       " accuracy        0.465\n",
       " f1- macro       0.220\n",
       " f1- micro       0.465\n",
       " f1- weighted    0.320\n",
       " precision       0.300\n",
       " recall          0.465\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.30\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.330\n",
       " precision       0.305\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.295\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.52\n",
       " accuracy        0.48\n",
       " f1- macro       0.22\n",
       " f1- micro       0.48\n",
       " f1- weighted    0.33\n",
       " precision       0.31\n",
       " recall          0.48\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.510\n",
       " accuracy        0.490\n",
       " f1- macro       0.225\n",
       " f1- micro       0.490\n",
       " f1- weighted    0.330\n",
       " precision       0.320\n",
       " recall          0.490\n",
       " dtype: float64, Hamming Loss    0.535\n",
       " accuracy        0.465\n",
       " f1- macro       0.220\n",
       " f1- micro       0.465\n",
       " f1- weighted    0.330\n",
       " precision       0.280\n",
       " recall          0.465\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.31\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.515\n",
       " accuracy        0.485\n",
       " f1- macro       0.220\n",
       " f1- micro       0.485\n",
       " f1- weighted    0.330\n",
       " precision       0.335\n",
       " recall          0.485\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.305\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.525\n",
       " accuracy        0.475\n",
       " f1- macro       0.220\n",
       " f1- micro       0.475\n",
       " f1- weighted    0.330\n",
       " precision       0.285\n",
       " recall          0.475\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.31\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.31\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.535\n",
       " accuracy        0.465\n",
       " f1- macro       0.220\n",
       " f1- micro       0.465\n",
       " f1- weighted    0.325\n",
       " precision       0.280\n",
       " recall          0.465\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.295\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.32\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.31\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.305\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.305\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.325\n",
       " precision       0.295\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.275\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.520\n",
       " accuracy        0.480\n",
       " f1- macro       0.220\n",
       " f1- micro       0.480\n",
       " f1- weighted    0.330\n",
       " precision       0.325\n",
       " recall          0.480\n",
       " dtype: float64, Hamming Loss    0.53\n",
       " accuracy        0.47\n",
       " f1- macro       0.22\n",
       " f1- micro       0.47\n",
       " f1- weighted    0.33\n",
       " precision       0.30\n",
       " recall          0.47\n",
       " dtype: float64, Hamming Loss    0.510\n",
       " accuracy        0.490\n",
       " f1- macro       0.225\n",
       " f1- micro       0.490\n",
       " f1- weighted    0.335\n",
       " precision       0.320\n",
       " recall          0.490\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.285\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.28\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.30\n",
       " recall          0.46\n",
       " dtype: float64, Hamming Loss    0.540\n",
       " accuracy        0.460\n",
       " f1- macro       0.220\n",
       " f1- micro       0.460\n",
       " f1- weighted    0.320\n",
       " precision       0.295\n",
       " recall          0.460\n",
       " dtype: float64, Hamming Loss    0.54\n",
       " accuracy        0.46\n",
       " f1- macro       0.22\n",
       " f1- micro       0.46\n",
       " f1- weighted    0.32\n",
       " precision       0.29\n",
       " recall          0.46\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dfs_across_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.54\n",
       "accuracy        0.46\n",
       "f1- macro       0.22\n",
       "f1- micro       0.46\n",
       "f1- weighted    0.32\n",
       "precision       0.30\n",
       "recall          0.46\n",
       "dtype: float64"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.concat(list_of_dfs_across_days, axis =1)\n",
    "df.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file_name.csv\n",
    "location_for_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_all_chunks.csv\")\n",
    "df.to_csv(location_for_df, index= True)\n",
    "location_for_dates_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_dates.csv\")\n",
    "dates_df.to_csv(location_for_dates_df, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.54\n",
       "accuracy        0.46\n",
       "f1- macro       0.22\n",
       "f1- micro       0.46\n",
       "f1- weighted    0.32\n",
       "precision       0.30\n",
       "recall          0.46\n",
       "dtype: float64"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(location_for_df, index_col=0)\n",
    "df_test.median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do:\n",
    "1. write a loop to go through all the labels for each symbol and store them in a seperate file\n",
    "2. concentrate only on the symbols we know we have labels\n",
    "3. pull the file from Single Kernel and compare them.\n",
    "4. re-do the labels and the plots for the symbols that you are picking and describe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path\n",
    "def create_path(parent_dir, symbol):\n",
    "    path = os.path.join(parent_dir, symbol)\n",
    "    if os.path.isdir(path)==False:\n",
    "        # Create the directory\n",
    "    \n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '%s' created\" %path)\n",
    "    else:\n",
    "        print(\"Directory Exist\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbolIDX in range(0, len(symbols)):\n",
    "#     create_path(processed_location, symbols[symbolIDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_load = os.listdir(processed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = list()\n",
    "string = str('_Label_2')\n",
    "for idx in range(0,40):\n",
    "    files =os.listdir(os.path.join(processed_location, symbols_to_load[idx]))\n",
    "    list_files.append([f for f in files if string in f])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LGEN.L_Label_2_all_chunks.csv', 'LGEN.L_Label_2_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " ['BLT.L_Label_2_all_chunks.csv', 'BLT.L_Label_2_dates.csv'],\n",
       " ['KGF.L_Label_2_all_chunks.csv', 'KGF.L_Label_2_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['CEY.L_Label_2_all_chunks.csv', 'CEY.L_Label_2_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " ['ITV.L_Label_2_all_chunks.csv', 'ITV.L_Label_2_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " ['APF.L_Label_2_all_chunks.csv', 'APF.L_Label_2_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['CPG.L_Label_2_dates.csv', 'CPG.L_Label_2_all_chunks.csv'],\n",
       " ['BARC.L_Label_2_dates.csv', 'BARC.L_Label_2_all_chunks.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['MAB.L_Label_2_dates.csv', 'MAB.L_Label_2_all_chunks.csv'],\n",
       " [],\n",
       " ['LAND.L_Label_2_dates.csv', 'LAND.L_Label_2_all_chunks.csv']]"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_files = ['BARC.L_Label_1_all_chunks.csv',\n",
    "    'APF.L_Label_1_all_chunks.csv', \n",
    "                 'CCL.L_Label_1_all_chunks.csv',\n",
    "                 'AV.L_Label_1_all_chunks.csv',\n",
    "                'BLT.L_Label_1_all_chunks.csv',\n",
    "                'AZN.L_Label_1_all_chunks.csv',\n",
    "                'KGF.L_Label_1_all_chunks.csv']\n",
    "\n",
    "label_5_files = ['PSON.L_Label_5_all_chunks.csv', \n",
    "                 'PRU.L_Label_5_all_chunks.csv',\n",
    "                 'AV.L_Label_5_all_chunks.csv', \n",
    "                 'APF.L_Label_5_all_chunks.csv', \n",
    "                 'MKS.L_Label_5_all_chunks.csv']\n",
    "\n",
    "label_4_files =  ['NG.L_Label_4_all_chunks.csv',\n",
    "  'BLT.L_Label_4_all_chunks.csv',\n",
    "  'KGF.L_Label_4_all_chunks.csv', \n",
    "  'PRU.L_Label_4_all_chunks.csv',\n",
    "  'RTO.L_Label_4_all_chunks.csv',\n",
    " 'RR.L_Label_4_all_chunks.csv',\n",
    " 'RSA.L_Label_4_all_chunks.csv',\n",
    "'CEY.L_Label_4_all_chunks.csv',\n",
    "'RB.L_Label_4_all_chunks.csv',\n",
    "'ITV.L_Label_4_all_chunks.csv',\n",
    "'PSON.L_Label_4_all_chunks.csv',\n",
    "  'SDR.L_Label_4_all_chunks.csv',\n",
    "  'APF.L_Label_4_all_chunks.csv',\n",
    "'REL.L_Label_4_all_chunks.csv', \n",
    "'AZN.L_Label_4_all_chunks.csv',\n",
    "'CCL.L_Label_4_all_chunks.csv',\n",
    " 'SGE.L_Label_4_all_chunks.csv', \n",
    " 'RDSb.L_Label_4_all_chunks.csv', \n",
    " 'CPG.L_Label_4_all_chunks.csv',\n",
    "'AV.L_Label_4_all_chunks.csv',\n",
    "'MAB.L_Label_4_all_chunks.csv',\n",
    "  'LAND.L_Label_4_all_chunks.csv']\n",
    "\n",
    "label_2_files = ['BLT.L_Label_2_all_chunks.csv', \n",
    "                 'KGF.L_Label_2_all_chunks.csv',\n",
    "                'CEY.L_Label_2_all_chunks.csv',\n",
    "                 'CPG.L_Label_2_all_chunks.csv',\n",
    "                 'BARC.L_Label_2_all_chunks.csv',\n",
    "                 'ITV.L_Label_2_all_chunks.csv',\n",
    "                 'APF.L_Label_2_all_chunks.csv' ,\n",
    "                'LAND.L_Label_2_all_chunks.csv',\n",
    "                'LGEN.L_Label_2_all_chunks.csv',\n",
    "                 'MAB.L_Label_2_all_chunks.csv'\n",
    "                ]\n",
    "\n",
    "\n",
    "label_3_files =['LGEN.L_Label_3_all_chunks.csv',\n",
    "                'APF.L_Label_3_all_chunks.csv',\n",
    "                'AV.L_Label_3_all_chunks.csv',\n",
    "                'MAB.L_Label_3_all_chunks.csv',\n",
    "                'LAND.L_Label_3_all_chunks.csv',\n",
    "               'LLOY.L_Label_3_all_chunks.csv',\n",
    "               'RBS.L_Label_3_all_chunks.csv']\n",
    "\n",
    "label_6_files = ['RSA.L_Label_6_all_chunks.csv',\n",
    "                'WPP.L_Label_6_all_chunks.csv',\n",
    "                'MKS.L_Label_6_all_chunks.csv',\n",
    "                'RR.L_Label_6_all_chunks.csv',\n",
    "                'LAND.L_Label_6_all_chunks.csv',\n",
    "                'CEY.L_Label_6_all_chunks.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Hamming Loss',\n",
    " 'accuracy',\n",
    " 'f1- macro',\n",
    " 'f1- micro',\n",
    " 'f1- weighted',\n",
    " 'precision',\n",
    " 'recall']\n",
    "\n",
    "\n",
    "label_dfs = {'1':label_1_dfs,\n",
    "             '2':label_2_dfs,\n",
    "             '3':label_3_dfs,\n",
    "             '4':label_4_dfs,\n",
    "             '5':label_5_dfs,\n",
    "             '6':label_6_dfs\n",
    "            }\n",
    "\n",
    "label_dicts = {'1':label_1_dicts,\n",
    "             '2':label_2_dicts,\n",
    "             '3':label_3_dicts,\n",
    "             '4':label_4_dicts,\n",
    "             '5':label_5_dicts,\n",
    "             '6':label_6_dicts\n",
    "            }\n",
    "\n",
    "label_files ={'1':label_1_files,\n",
    "              '2':label_2_files,\n",
    "              '3':label_3_files,\n",
    "              '4':label_4_files,\n",
    "              '5':label_5_files,\n",
    "              '6':label_6_files\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIdx = str(6)\n",
    "label_Idx_files = label_files[labelIdx]\n",
    "label_Idx_dfs = label_dfs[labelIdx]\n",
    "label_Idx_dicts = label_dicts[labelIdx]\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(0, len(label_Idx_files)):\n",
    "    symbol = label_Idx_files[idx].split(\"_\")[0]\n",
    "    \n",
    "    file_to_load = \\\n",
    "    pd.read_csv(os.path.join(processed_location, symbol, label_Idx_files[idx])).median(axis=1)\n",
    "    label_Idx_dfs.append(file_to_load)\n",
    "    file_to_load.index = row_labels\n",
    "    label_Idx_dicts[symbol] = file_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dicts_processed = {'One': pd.DataFrame.from_dict(label_dicts['1']),\n",
    "               'Two':  pd.DataFrame.from_dict(label_dicts['2']),\n",
    "               'Three':  pd.DataFrame.from_dict(label_dicts['3']),\n",
    "               'Four':  pd.DataFrame.from_dict(label_dicts['4']),\n",
    "               'Five':  pd.DataFrame.from_dict(label_dicts['5']),\n",
    "               'Six':  pd.DataFrame.from_dict(label_dicts['6']),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_for_label_one = list(labels_dicts_processed['One'].columns.values)\n",
    "symbols_for_label_two = list(labels_dicts_processed['Two'].columns.values)\n",
    "symbols_for_label_three = list(labels_dicts_processed['Three'].columns.values)\n",
    "symbols_for_label_four = list(labels_dicts_processed['Four'].columns.values)\n",
    "symbols_for_label_five = list(labels_dicts_processed['Five'].columns.values)\n",
    "symbols_for_label_six = list(labels_dicts_processed['Six'].columns.values)\n",
    "\n",
    "common_symbols = set(symbols_for_label_one)  - set(symbols_for_label_five) - \\\n",
    "set(symbols_for_label_four)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BARC.L']\n"
     ]
    }
   ],
   "source": [
    "print(list(common_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for key in list(labels_dicts_processed.keys()):\n",
    "    df[key] =labels_dicts_processed[str(key)].median(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &   One &    Two &  Three &  Four &   Five &    Six \\\\\n",
      "\\midrule\n",
      "Hamming Loss &  0.02 &  0.115 &   0.62 &  0.16 &  0.525 &  0.535 \\\\\n",
      "accuracy     &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "f1- macro    &  0.49 &  0.470 &   0.26 &  0.46 &  0.240 &  0.220 \\\\\n",
      "f1- micro    &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "f1- weighted &  0.97 &  0.840 &   0.31 &  0.77 &  0.330 &  0.320 \\\\\n",
      "precision    &  0.96 &  0.790 &   0.30 &  0.71 &  0.290 &  0.265 \\\\\n",
      "recall       &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
