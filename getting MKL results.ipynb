{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import sys\n",
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/MultiKernelLearning')\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "import jsonpickle\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "\n",
    "from fileutils import new_feature_utils as nfu\n",
    "from fileutils.new_feature_utils import CreateMarketFeatures\n",
    "import multiprocessing\n",
    "import mkl_data_processing as mkldp\n",
    "from matplotlib.ticker import ScalarFormatter,AutoMinorLocator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "styleFiles = os.listdir(mpl.get_configdir())\n",
    "styleFileIdx = 0\n",
    "\n",
    "plt.style.use(os.path.join(mpl.get_configdir(), styleFiles[styleFileIdx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_filepath(pickle_file):\n",
    "    pickle_to_file = pickle.load(open(pickle_file, \"rb\"), encoding='latin1')\n",
    "\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSPredictions/SimpleMKL/'\n",
    "symbols = sorted(os.listdir(files_location))\n",
    "#processed results path\n",
    "processed_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are doing symbol BLT.L and label Label_idx:_5\n",
      "total files for the symbol: 3304\n",
      "and for this label\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "symbolIDX =  6 #pick a symbol\n",
    "label_idx = 5 #pick a label\n",
    "label_string= 'Label_idx:_'+str(label_idx)\n",
    "print('you are doing symbol', symbols[symbolIDX], 'and label', label_string)\n",
    "# now we take out the files for the symbol \n",
    "symbol_path = os.path.join(files_location,str(sorted(symbols)[symbolIDX]))\n",
    "symbolFiles = os.listdir(os.path.join(files_location,str(sorted(symbols)[symbolIDX])))\n",
    "# now isolate all the label+ symbol combos\n",
    "symbolLabelFiles = [f for f in symbolFiles if str(label_string) in f]\n",
    "path_to_store = os.path.join(processed_location, symbols[symbolIDX])\n",
    "number_of_files = len(symbolLabelFiles) \n",
    "\n",
    "# this is the number of files that correspond to the label/symbol combo\n",
    "\n",
    "print('total files for the symbol:', len(symbolFiles))\n",
    "print('and for this label')\n",
    "print(number_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed/BLT.L'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_chunks_keys = dict()\n",
    "chunks_list =list()\n",
    "keys_list = list()\n",
    "\n",
    "for file_to_load_idx in range(0,number_of_files):\n",
    "    # go through all of the files that are a combination of symbols and labels\n",
    "    file_to_load_path = os.path.join(os.path.join(files_location, str(symbols[symbolIDX])), symbolLabelFiles[file_to_load_idx])\n",
    "    if os.path.getsize(file_to_load_path)> 0:\n",
    "        # extract the key - these are the symbol feature path keys in the  main code\n",
    "        file_keys = list(open_pickle_filepath(file_to_load_path).keys()) # keys\n",
    "        keys_list.append(file_keys[0])\n",
    "        dates_chunks_keys[file_to_load_idx] = file_keys\n",
    "        chunks_list.append(open_pickle_filepath(file_to_load_path)[file_keys[0]])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame((np.unique(list(dates_chunks_keys.values()))))\n",
    "list_of_dfs_across_days = list()\n",
    "for chunk_list_item in range(0,len(chunks_list)-1):\n",
    "    chunk_list_item_dict = chunks_list[chunk_list_item]\n",
    "    chunk_list_item_keys = list(chunk_list_item_dict.keys())\n",
    "    list_of_dicts=list()\n",
    "    for key in chunk_list_item_keys:\n",
    "        list_of_dicts.append(pd.DataFrame(chunk_list_item_dict[key]))\n",
    "    list_of_dfs_across_days.append(pd.concat(list_of_dicts,axis=1).median(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.22\n",
       "accuracy        0.78\n",
       "f1- macro       0.29\n",
       "f1- micro       0.78\n",
       "f1- weighted    0.69\n",
       "precision       0.61\n",
       "recall          0.78\n",
       "dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.concat(list_of_dfs_across_days, axis =1)\n",
    "df.median(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file_name.csv\n",
    "location_for_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_all_chunks.csv\")\n",
    "df.to_csv(location_for_df, index= True)\n",
    "location_for_dates_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_dates.csv\")\n",
    "dates_df.to_csv(location_for_dates_df, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.22\n",
       "accuracy        0.78\n",
       "f1- macro       0.29\n",
       "f1- micro       0.78\n",
       "f1- weighted    0.69\n",
       "precision       0.61\n",
       "recall          0.78\n",
       "dtype: float64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(location_for_df, index_col=0)\n",
    "df_test.median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do:\n",
    "1. write a loop to go through all the labels for each symbol and store them in a seperate file\n",
    "2. concentrate only on the symbols we know we have labels\n",
    "3. pull the file from Single Kernel and compare them.\n",
    "4. re-do the labels and the plots for the symbols that you are picking and describe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Hamming Loss',\n",
    " 'accuracy',\n",
    " 'f1- macro',\n",
    " 'f1- micro',\n",
    " 'f1- weighted',\n",
    " 'precision',\n",
    " 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path\n",
    "def create_path(parent_dir, symbol):\n",
    "    path = os.path.join(parent_dir, symbol)\n",
    "    if os.path.isdir(path)==False:\n",
    "        # Create the directory\n",
    "    \n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '%s' created\" %path)\n",
    "    else:\n",
    "        print(\"Directory Exist\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_load = os.listdir(processed_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " ['BLT.L_Label_1_dates.csv', 'BLT.L_Label_1_all_chunks.csv'],\n",
       " ['KGF.L_Label_1_dates.csv', 'KGF.L_Label_1_all_chunks.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['RDSa.L_Label_1_dates.csv', 'RDSa.L_Label_1_all_chunks.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ITV.L_Label_1_dates.csv', 'ITV.L_Label_1_all_chunks.csv'],\n",
       " [],\n",
       " [],\n",
       " ['APF.L_Label_1_dates.csv', 'APF.L_Label_1_all_chunks.csv'],\n",
       " [],\n",
       " [],\n",
       " ['AZN.L_Label_1_dates.csv', 'AZN.L_Label_1_all_chunks.csv'],\n",
       " ['CCL.L_Label_1_all_chunks.csv', 'CCL.L_Label_1_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " ['LLOY.L_Label_1_all_chunks.csv', 'LLOY.L_Label_1_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " ['CPG.L_Label_1_dates.csv', 'CPG.L_Label_1_all_chunks.csv'],\n",
       " ['BARC.L_Label_1_all_chunks.csv', 'BARC.L_Label_1_dates.csv'],\n",
       " ['AV.L_Label_1_all_chunks.csv', 'AV.L_Label_1_dates.csv'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = list()\n",
    "string = str('_Label_1')\n",
    "for idx in range(0,40):\n",
    "    files =os.listdir(os.path.join(processed_location, symbols_to_load[idx]))\n",
    "    list_files.append([f for f in files if string in f])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_files = ['BARC.L_Label_1_all_chunks.csv',\n",
    "    'APF.L_Label_1_all_chunks.csv', 'ITV.L_Label_1_all_chunks.csv',\n",
    "                 'CCL.L_Label_1_all_chunks.csv',\n",
    "                 'AV.L_Label_1_all_chunks.csv',\n",
    "                'BLT.L_Label_1_all_chunks.csv',\n",
    "                'AZN.L_Label_1_all_chunks.csv',\n",
    "                'KGF.L_Label_1_all_chunks.csv',\n",
    "                'CPG.L_Label_1_all_chunks.csv',\n",
    "                'RDSa.L_Label_1_all_chunks.csv']\n",
    "\n",
    "label_5_files = ['PSON.L_Label_5_all_chunks.csv', \n",
    "                 'PRU.L_Label_5_all_chunks.csv',\n",
    "                 'AV.L_Label_5_all_chunks.csv', \n",
    "                 'APF.L_Label_5_all_chunks.csv', \n",
    "                 'MKS.L_Label_5_all_chunks.csv']\n",
    "\n",
    "label_4_files =  ['NG.L_Label_4_all_chunks.csv',\n",
    "  'BLT.L_Label_4_all_chunks.csv',\n",
    "  'KGF.L_Label_4_all_chunks.csv', \n",
    "  'PRU.L_Label_4_all_chunks.csv',\n",
    "  'RTO.L_Label_4_all_chunks.csv',\n",
    " 'RR.L_Label_4_all_chunks.csv',\n",
    "'SHP.L_Label_4_all_chunks.csv',\n",
    " 'RSA.L_Label_4_all_chunks.csv',\n",
    "'CEY.L_Label_4_all_chunks.csv',\n",
    "'RB.L_Label_4_all_chunks.csv',\n",
    "'ITV.L_Label_4_all_chunks.csv',\n",
    "'PSON.L_Label_4_all_chunks.csv',\n",
    "  'SDR.L_Label_4_all_chunks.csv',\n",
    "  'APF.L_Label_4_all_chunks.csv',\n",
    "'REL.L_Label_4_all_chunks.csv', \n",
    "'AZN.L_Label_4_all_chunks.csv',\n",
    "'CCL.L_Label_4_all_chunks.csv',\n",
    " 'SGE.L_Label_4_all_chunks.csv', \n",
    " 'RDSb.L_Label_4_all_chunks.csv', \n",
    " 'CPG.L_Label_4_all_chunks.csv',\n",
    "'AV.L_Label_4_all_chunks.csv',\n",
    "'MAB.L_Label_4_all_chunks.csv',\n",
    "  'LAND.L_Label_4_all_chunks.csv', \n",
    "'LGEN.L_Label_4_all_chunks.csv']\n",
    "\n",
    "label_2_files = ['BLT.L_Label_2_all_chunks.csv', \n",
    "                 'KGF.L_Label_2_all_chunks.csv',\n",
    "                'CEY.L_Label_2_all_chunks.csv',\n",
    "                 'CPG.L_Label_2_all_chunks.csv',\n",
    "                 'BARC.L_Label_2_all_chunks.csv',\n",
    "                 'ITV.L_Label_2_all_chunks.csv',\n",
    "                 'APF.L_Label_2_all_chunks.csv' ,\n",
    "                'LAND.L_Label_2_all_chunks.csv',\n",
    "                'LGEN.L_Label_2_all_chunks.csv',\n",
    "                 'MAB.L_Label_2_all_chunks.csv'\n",
    "                ]\n",
    "\n",
    "\n",
    "label_3_files =['LGEN.L_Label_3_all_chunks.csv',\n",
    "                'APF.L_Label_3_all_chunks.csv',\n",
    "                'AV.L_Label_3_all_chunks.csv',\n",
    "                'MAB.L_Label_3_all_chunks.csv',\n",
    "                'LAND.L_Label_3_all_chunks.csv',\n",
    "               'LLOY.L_Label_3_all_chunks.csv',\n",
    "               'RBS.L_Label_3_all_chunks.csv']\n",
    "\n",
    "label_6_files = ['RSA.L_Label_6_all_chunks.csv',\n",
    "                'WPP.L_Label_6_all_chunks.csv',\n",
    "                'MKS.L_Label_6_all_chunks.csv',\n",
    "                'RR.L_Label_6_all_chunks.csv',\n",
    "                'LAND.L_Label_6_all_chunks.csv',\n",
    "                'CEY.L_Label_6_all_chunks.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more efficient way to do this\n",
    "label_1_dfs = list()\n",
    "label_1_dicts = dict()\n",
    "\n",
    "for idx in range(0, len(label_1_files)):\n",
    "    symbol = label_1_files[idx].split(\"_\")[0]\n",
    "    \n",
    "    file_to_load = \\\n",
    "    pd.read_csv(os.path.join(processed_location, symbol, label_1_files[idx])).median(axis=1)\n",
    "    label_1_dfs.append(file_to_load)\n",
    "    file_to_load.index = row_labels\n",
    "    label_1_dicts[symbol] = file_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.025\n",
       "accuracy        0.975\n",
       "f1- macro       0.490\n",
       "f1- micro       0.975\n",
       "f1- weighted    0.965\n",
       "precision       0.955\n",
       "recall          0.975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(label_1_dfs, axis =1).median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hamming Loss</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- macro</th>\n",
       "      <td>0.230</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- micro</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- weighted</th>\n",
       "      <td>0.245</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0     1     2      3     4\n",
       "Hamming Loss  0.670  0.27  0.53  0.525  0.45\n",
       "accuracy      0.330  0.73  0.47  0.475  0.55\n",
       "f1- macro     0.230  0.28  0.21  0.250  0.24\n",
       "f1- micro     0.330  0.73  0.47  0.475  0.55\n",
       "f1- weighted  0.245  0.62  0.30  0.330  0.40\n",
       "precision     0.290  0.53  0.23  0.250  0.31\n",
       "recall        0.330  0.73  0.47  0.475  0.55"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(label_5_dfs, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hamming Loss</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- macro</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- micro</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1- weighted</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0     1     2     3     4     5     6      7     8     9   \\\n",
       "Hamming Loss  0.11  0.20  0.14  0.16  0.13  0.18  0.07  0.210  0.11  0.11   \n",
       "accuracy      0.89  0.80  0.86  0.84  0.87  0.82  0.93  0.790  0.89  0.89   \n",
       "f1- macro     0.47  0.44  0.46  0.46  0.47  0.45  0.48  0.440  0.47  0.47   \n",
       "f1- micro     0.89  0.80  0.86  0.84  0.87  0.82  0.93  0.790  0.89  0.89   \n",
       "f1- weighted  0.84  0.71  0.80  0.77  0.82  0.74  0.89  0.700  0.84  0.84   \n",
       "precision     0.79  0.64  0.74  0.71  0.76  0.68  0.86  0.625  0.79  0.79   \n",
       "recall        0.89  0.80  0.86  0.84  0.87  0.82  0.93  0.790  0.89  0.89   \n",
       "\n",
       "              ...   13    14    15    16    17    18    19    20    21    22  \n",
       "Hamming Loss  ...  0.0  0.27  0.09  0.25  0.20  0.16  0.23  0.21  0.03  0.24  \n",
       "accuracy      ...  1.0  0.73  0.91  0.75  0.80  0.84  0.77  0.79  0.97  0.76  \n",
       "f1- macro     ...  1.0  0.42  0.48  0.43  0.44  0.46  0.44  0.44  0.49  0.43  \n",
       "f1- micro     ...  1.0  0.73  0.91  0.75  0.80  0.84  0.77  0.79  0.97  0.76  \n",
       "f1- weighted  ...  1.0  0.61  0.87  0.65  0.71  0.77  0.67  0.69  0.96  0.66  \n",
       "precision     ...  1.0  0.53  0.83  0.57  0.64  0.71  0.60  0.62  0.94  0.58  \n",
       "recall        ...  1.0  0.73  0.91  0.75  0.80  0.84  0.77  0.79  0.97  0.76  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(label_4_dfs, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = ['Hamming Loss',\n",
    " 'accuracy',\n",
    " 'f1- macro',\n",
    " 'f1- micro',\n",
    " 'f1- weighted',\n",
    " 'precision',\n",
    " 'recall']\n",
    "\n",
    "\n",
    "label_dfs = {'1':label_1_dfs,\n",
    "             '2':label_2_dfs,\n",
    "             '3':label_3_dfs,\n",
    "             '4':label_4_dfs,\n",
    "             '5':label_5_dfs,\n",
    "             '6':label_6_dfs\n",
    "            }\n",
    "\n",
    "label_dicts = {'1':label_1_dicts,\n",
    "             '2':label_2_dicts,\n",
    "             '3':label_3_dicts,\n",
    "             '4':label_4_dicts,\n",
    "             '5':label_5_dicts,\n",
    "             '6':label_6_dicts\n",
    "            }\n",
    "\n",
    "label_files ={'1':label_1_files,\n",
    "              '2':label_2_files,\n",
    "              '3':label_3_files,\n",
    "              '4':label_4_files,\n",
    "              '5':label_5_files,\n",
    "              '6':label_6_files\n",
    "             }\n",
    "\n",
    "labelIds = list(label_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dfs_across_all_symbols = dict()\n",
    "for idx in labelIds:\n",
    "    median_dfs_across_all_symbols['Label_'+str(idx)] = pd.DataFrame(label_dfs[str(idx)]).T.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  Hamming Loss &  accuracy &  f1- macro &  f1- micro &  f1- weighted &  precision &  recall \\\\\n",
      "\\midrule\n",
      "Label\\_1 &         0.020 &     0.980 &       0.49 &      0.980 &          0.97 &      0.960 &   0.980 \\\\\n",
      "Label\\_2 &         0.110 &     0.890 &       0.47 &      0.890 &          0.85 &      0.800 &   0.890 \\\\\n",
      "Label\\_3 &         0.620 &     0.380 &       0.26 &      0.380 &          0.31 &      0.300 &   0.380 \\\\\n",
      "Label\\_4 &         0.160 &     0.840 &       0.46 &      0.840 &          0.77 &      0.710 &   0.840 \\\\\n",
      "Label\\_5 &         0.525 &     0.475 &       0.24 &      0.475 &          0.33 &      0.290 &   0.475 \\\\\n",
      "Label\\_6 &         0.535 &     0.465 &       0.22 &      0.465 &          0.32 &      0.265 &   0.465 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(median_dfs_across_all_symbols).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIdx = str(1)\n",
    "label_Idx_files = label_files[labelIdx]\n",
    "label_Idx_dfs = label_dfs[labelIdx]\n",
    "label_Idx_dicts = label_dicts[labelIdx]\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(0, len(label_Idx_files)):\n",
    "    symbol = label_Idx_files[idx].split(\"_\")[0]\n",
    "    \n",
    "    file_to_load = \\\n",
    "    pd.read_csv(os.path.join(processed_location, symbol, label_Idx_files[idx])).median(axis=1)\n",
    "    label_Idx_dfs.append(file_to_load)\n",
    "    file_to_load.index = row_labels\n",
    "    label_Idx_dicts[symbol] = file_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BARC.L': Hamming Loss    0.01\n",
       " accuracy        0.99\n",
       " f1- macro       0.50\n",
       " f1- micro       0.99\n",
       " f1- weighted    0.98\n",
       " precision       0.98\n",
       " recall          0.99\n",
       " dtype: float64, 'APF.L': Hamming Loss    0.18\n",
       " accuracy        0.82\n",
       " f1- macro       0.45\n",
       " f1- micro       0.82\n",
       " f1- weighted    0.74\n",
       " precision       0.67\n",
       " recall          0.82\n",
       " dtype: float64, 'CCL.L': Hamming Loss    0.03\n",
       " accuracy        0.97\n",
       " f1- macro       0.49\n",
       " f1- micro       0.97\n",
       " f1- weighted    0.96\n",
       " precision       0.95\n",
       " recall          0.97\n",
       " dtype: float64, 'AV.L': Hamming Loss    0.03\n",
       " accuracy        0.97\n",
       " f1- macro       0.49\n",
       " f1- micro       0.97\n",
       " f1- weighted    0.96\n",
       " precision       0.95\n",
       " recall          0.97\n",
       " dtype: float64, 'BLT.L': Hamming Loss    0.01\n",
       " accuracy        0.99\n",
       " f1- macro       0.50\n",
       " f1- micro       0.99\n",
       " f1- weighted    0.99\n",
       " precision       0.98\n",
       " recall          0.99\n",
       " dtype: float64, 'AZN.L': Hamming Loss    0.01\n",
       " accuracy        0.99\n",
       " f1- macro       0.50\n",
       " f1- micro       0.99\n",
       " f1- weighted    0.99\n",
       " precision       0.98\n",
       " recall          0.99\n",
       " dtype: float64, 'KGF.L': Hamming Loss    0.02\n",
       " accuracy        0.98\n",
       " f1- macro       0.49\n",
       " f1- micro       0.98\n",
       " f1- weighted    0.97\n",
       " precision       0.96\n",
       " recall          0.98\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_Idx_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-8d8367ff39cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m labels_dicts_processed = {'One': pd.DataFrame.from_dict(label_Idx_dicts['1']),\n\u001b[0m\u001b[1;32m      2\u001b[0m                \u001b[0;34m'Two'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_Idx_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0;34m'Three'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_Idx_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m'Four'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_Idx_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0;34m'Five'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_Idx_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "labels_dicts_processed = {'One': pd.DataFrame.from_dict(label_Idx_dicts['1']),\n",
    "               'Two':  pd.DataFrame.from_dict(label_Idx_dicts['2']),\n",
    "               'Three':  pd.DataFrame.from_dict(label_Idx_dicts['3']),\n",
    "               'Four':  pd.DataFrame.from_dict(label_Idx_dicts['4']),\n",
    "               'Five':  pd.DataFrame.from_dict(label_Idx_dicts['5']),\n",
    "               'Six':  pd.DataFrame.from_dict(label_Idx_dicts['6']),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_dicts_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-9a6739d88062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbols_for_label_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'One'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msymbols_for_label_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Two'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msymbols_for_label_three\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Three'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msymbols_for_label_four\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Four'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msymbols_for_label_five\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Five'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_dicts_processed' is not defined"
     ]
    }
   ],
   "source": [
    "symbols_for_label_one = list(labels_dicts_processed['One'].columns.values)\n",
    "symbols_for_label_two = list(labels_dicts_processed['Two'].columns.values)\n",
    "symbols_for_label_three = list(labels_dicts_processed['Three'].columns.values)\n",
    "symbols_for_label_four = list(labels_dicts_processed['Four'].columns.values)\n",
    "symbols_for_label_five = list(labels_dicts_processed['Five'].columns.values)\n",
    "symbols_for_label_six = list(labels_dicts_processed['Six'].columns.values)\n",
    "\n",
    "common_symbols = set(symbols_for_label_one)  - set(symbols_for_label_five) - \\\n",
    "set(symbols_for_label_four)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_symbols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3b8c63349eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'common_symbols' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(common_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_dicts_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-685bbc98700a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlabels_dicts_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_dicts_processed' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for key in list(labels_dicts_processed.keys()):\n",
    "    df[key] =labels_dicts_processed[str(key)].median(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &   One &    Two &  Three &  Four &   Five &    Six \\\\\n",
      "\\midrule\n",
      "Hamming Loss &  0.02 &  0.115 &   0.62 &  0.16 &  0.525 &  0.535 \\\\\n",
      "accuracy     &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "f1- macro    &  0.49 &  0.470 &   0.26 &  0.46 &  0.240 &  0.220 \\\\\n",
      "f1- micro    &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "f1- weighted &  0.97 &  0.840 &   0.31 &  0.77 &  0.330 &  0.320 \\\\\n",
      "precision    &  0.96 &  0.790 &   0.30 &  0.71 &  0.290 &  0.265 \\\\\n",
      "recall       &  0.98 &  0.885 &   0.38 &  0.84 &  0.475 &  0.465 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
