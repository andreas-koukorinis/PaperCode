{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"axes.titlelocation\" on line 28 in\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/plot_style.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import sys\n",
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/MultiKernelLearning')\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "import jsonpickle\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "\n",
    "from fileutils import new_feature_utils as nfu\n",
    "from fileutils.new_feature_utils import CreateMarketFeatures\n",
    "import multiprocessing\n",
    "import mkl_data_processing as mkldp\n",
    "from matplotlib.ticker import ScalarFormatter,AutoMinorLocator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "styleFiles = os.listdir(mpl.get_configdir())\n",
    "styleFileIdx = 0\n",
    "\n",
    "plt.style.use(os.path.join(mpl.get_configdir(), styleFiles[styleFileIdx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_filepath(pickle_file):\n",
    "    pickle_to_file = pickle.load(open(pickle_file, \"rb\"), encoding='latin1')\n",
    "\n",
    "    return pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSPredictions/SimpleMKL/'\n",
    "symbols = sorted(os.listdir(files_location))\n",
    "#processed results path\n",
    "processed_location = '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are doing symbol APF.L and label Label_idx:_5\n",
      "total files for the symbol: 3192\n",
      "and for this label\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "symbolIDX =  1 #pick a symbol\n",
    "label_idx = 5 #ick a label\n",
    "label_string = 'Label_idx:_'+str(label_idx)\n",
    "print('you are doing symbol', symbols[symbolIDX], 'and label', label_string)\n",
    "# now we take out the files for the symbol \n",
    "symbol_path = os.path.join(files_location,str(sorted(symbols)[symbolIDX]))\n",
    "symbolFiles = os.listdir(os.path.join(files_location,str(sorted(symbols)[symbolIDX])))\n",
    "# now isolate all the label+ symbol combos\n",
    "symbolLabelFiles = [f for f in symbolFiles if str(label_string) in f]\n",
    "path_to_store = os.path.join(processed_location, symbols[symbolIDX])\n",
    "number_of_files = len(symbolLabelFiles) \n",
    "\n",
    "# this is the number of files that correspond to the label/symbol combo\n",
    "\n",
    "print('total files for the symbol:', len(symbolFiles))\n",
    "print('and for this label')\n",
    "print(number_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed/SDR.L'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_chunks_keys = dict()\n",
    "chunks_list =list()\n",
    "keys_list = list()\n",
    "\n",
    "for file_to_load_idx in range(0,number_of_files):\n",
    "    # go through all of the files that are a combination of symbols and labels\n",
    "    file_to_load_path = os.path.join(os.path.join(files_location, str(symbols[symbolIDX])), symbolLabelFiles[file_to_load_idx])\n",
    "    if os.path.getsize(file_to_load_path)> 0:\n",
    "        # extract the key - these are the symbol feature path keys in the  main code\n",
    "        file_keys = list(open_pickle_filepath(file_to_load_path).keys()) # keys\n",
    "        keys_list.append(file_keys[0])\n",
    "        dates_chunks_keys[file_to_load_idx] = file_keys\n",
    "        chunks_list.append(open_pickle_filepath(file_to_load_path)[file_keys[0]])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.DataFrame((np.unique(list(dates_chunks_keys.values()))))\n",
    "list_of_dfs_across_days = list()\n",
    "for chunk_list_item in range(0,len(chunks_list)-1):\n",
    "    chunk_list_item_dict = chunks_list[chunk_list_item]\n",
    "    chunk_list_item_keys = list(chunk_list_item_dict.keys())\n",
    "    list_of_dicts=list()\n",
    "    for key in chunk_list_item_keys:\n",
    "        list_of_dicts.append(pd.DataFrame(chunk_list_item_dict[key]))\n",
    "    list_of_dfs_across_days.append(pd.concat(list_of_dicts,axis=1).median(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.670\n",
       "accuracy        0.330\n",
       "f1- macro       0.230\n",
       "f1- micro       0.330\n",
       "f1- weighted    0.245\n",
       "precision       0.290\n",
       "recall          0.330\n",
       "dtype: float64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.concat(list_of_dfs_across_days, axis =1)\n",
    "df.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file_name.csv\n",
    "location_for_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_all_chunks.csv\")\n",
    "df.to_csv(location_for_df, index= True)\n",
    "location_for_dates_df = os.path.join(path_to_store, symbols[symbolIDX] +\"_Label_\"+str(label_idx)+\"_dates.csv\")\n",
    "dates_df.to_csv(location_for_dates_df, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hamming Loss    0.670\n",
       "accuracy        0.330\n",
       "f1- macro       0.230\n",
       "f1- micro       0.330\n",
       "f1- weighted    0.245\n",
       "precision       0.290\n",
       "recall          0.330\n",
       "dtype: float64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(location_for_df, index_col=0)\n",
    "df_test.median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do:\n",
    "1. write a loop to go through all the labels for each symbol and store them in a seperate file\n",
    "2. concentrate only on the symbols we know we have labels\n",
    "3. pull the file from Single Kernel and compare them.\n",
    "4. re-do the labels and the plots for the symbols that you are picking and describe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path\n",
    "def create_path(parent_dir, symbol):\n",
    "    path = os.path.join(parent_dir, symbol)\n",
    "    if os.path.isdir(path)==False:\n",
    "        # Create the directory\n",
    "    \n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '%s' created\" %path)\n",
    "    else:\n",
    "        print(\"Directory Exist\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APF.L'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[symbolIDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory Exist\n",
      "Directory '/media/ak/DataOnly/ExperimentCommonLocs/MKLOOSProcessed/WPP.L' created\n"
     ]
    }
   ],
   "source": [
    "for symbolIDX in range(0, len(symbols)):\n",
    "    create_path(processed_location, symbols[symbolIDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
