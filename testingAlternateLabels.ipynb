{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_labels_path(dataDrive,LabelNumber, symbol):\n",
    "    \"\"\"\n",
    "    path of labels and symbol to store data\n",
    "    labelNumber: label number pick from one two three\n",
    "    symbol: symbol in capital letters and .L in the end\n",
    "    \"\"\"\n",
    "    LabelAlternate = 'LabelsAlternate'+str(LabelNumber)\n",
    "    \n",
    "    path = os.path.join(dataDrive, LabelAlternate, str(symbol))\n",
    "    if os.path.exists(path):\n",
    "        return path\n",
    "    else: \n",
    "        print('path does not exist- add a .L to the symbol ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileutils as fileutils\n",
    "listDataPath =os.listdir(fileutils.data_path)\n",
    "symbols_listDataPath =[s for s in listDataPath if s.endswith('.L') or s.endswith('.I')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataDrive = '/media/ak/My Passport/Data/FinDataReal/'\n",
    "LabelDirectoryNames = [s for s in os.listdir(dataDrive) if ('LabelsAlternate') in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofLabelsSymbols = os.listdir(fileutils.labels_path)\n",
    "# print(\"A bunch of symbols from the listdir above:\",listofLabelsSymbols) \n",
    "LabelsPathsNames = ['Labels','LabelsAlternateOne','LabelsAlternateTwo','LabelsAlternateThree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pickle_files = [s for s in os.listdir(dataDrive) if ('AlternateLabels') in s] # pick all the alternate labels in the data drive\n",
    "symbols  = [s.split(\"_\")[0] for s in labels_pickle_files] # pick all the symbols from those folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_for_labels_folder(idx): \n",
    "    \"\"\"\n",
    "    return just a symbol from the labels_pickle_files- indexed by idx\n",
    "    \"\"\"\n",
    "    return labels_pickle_files[idx].split(\"_\")[0]+('.L')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pickle_file_idx = 0 # indexation of the above labels to get out a file that contains a dictionary of all the labels\n",
    "symbol_single_dict =pkl.load(open(\"/\".join((dataDrive, labels_pickle_files[label_pickle_file_idx])), \"rb\"),\n",
    "                                                encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolDataLabels =os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-10-9e8a48681fcd>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-9e8a48681fcd>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    #     return df.filter(like=str(label_string), axis=1)\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "df = symbol_single_dict[keys[0]]\n",
    "def labels_df(df, label_idx=0):\n",
    "#     differentLabelTypes=df.filter(like='label', axis=1).columns.values\n",
    "#     label_string = differentLabelTypes[label_idx]\n",
    "#     return df.filter(like=str(label_string), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "symbol = 'AAL.L'\n",
    "extPath = '/media/ak/My Passport/ExperimentData'\n",
    "featuresPath = \"/\".join((extPath, 'features'))\n",
    "labelsPath = alternate_labels_path(dataDrive, 'Two', symbol)\n",
    "MKLPath = \"/\".join((extPath, 'MKLExpPath'))\n",
    "# symbolsList = sorted(list(set(os.listdir(featuresPath)) & set(os.listdir(labelsPath))))\n",
    "# symbolsToRemove = ['AAL.L', 'BLT.L', 'BARC.L', 'AZN.L', 'CNA.L', 'APF.L','CCL.L','CPG.L','LAND.L','RTO.L','RSA.L','RDSb.L','PSON.L']\n",
    "# symbols = [x for x in symbolsList if x not in symbolsToRemove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbolIdx = 12# pick a symbol -1,2,4,7,9,10,12,15,17,19, 22, 26, 27\n",
    "# # for symbolIdx, _ in enumerate(symbols):\n",
    "# symbol = symbols[symbolIdx]\n",
    "print(symbol)\n",
    "\n",
    "# print(os.listdir(MKLSymbolPath))\n",
    "print(os.listdir(labelsPath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep track of various structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now lets go down into each HMM-model date, and pick all the forward futures (out of sample)\n",
    "hmmFeatureLocations = {}  # symbol-hmm-model-date index --> this is the indexation in symbolFeaturesDatesList\n",
    "commonDatesDict = {}  # this is a struct that will contain for each HMM date, the common labels/features- this\n",
    "# should\n",
    "# be used for training and testing\n",
    "createDate = []  # place holder for the hash key of when the features got created\n",
    "symbolEachModelFeaturesDates = {}\n",
    "HMMModelFeaturesLabelsCommon = {}  # location dictionary with 2 keys: HMM Date and Common Date\n",
    "commonDates = []\n",
    "\n",
    "LocDictsList = []  # symbol specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ''' specific symbol targets'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hmmDateIdx, hmmDate in enumerate(sorted(symbolHMMDatesList)):\n",
    "    symbolModelFeaturesDate = os.path.join(symbolFeaturesLocation, symbolHMMDatesList[hmmDateIdx])\n",
    "    if len(os.listdir(symbolModelFeaturesDate)) != 0:\n",
    "        create_date = os.listdir(symbolModelFeaturesDate)[0].split(\"_\")[-2]\n",
    "        # output looks like this: /media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20170710\n",
    "        symbolEachModelFeaturesDates[symbolHMMDatesList[hmmDateIdx]] = [file.split(\"_\")[5] for file in\n",
    "                                                                    os.listdir(symbolModelFeaturesDate)]\n",
    "        # output is a dictionary where the keys are the HMM models dates and the values a list of dates - for\n",
    "        # each HMM date we have a list of features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyHMMDate in sorted(list(symbolEachModelFeaturesDates.keys())):  # for each of the HMM model dates\n",
    "    print(keyHMMDate)\n",
    "    common_dates = list(set(symbolEachModelFeaturesDates[keyHMMDate]) & set(symbolLabelsDates))\n",
    "#     print(common_dates)\n",
    "    \n",
    "    # take the list of feature dates (conditional on HMM model date) + the list of labels -intersection!\n",
    "\n",
    "    '''we now produce a dict for each HMM model, where each value is a list of common dates and we are key-ed by\n",
    "    the HMM Date '''\n",
    "    commonDatesDict[keyHMMDate] = common_dates\n",
    "    \n",
    "    for commonDate in common_dates:\n",
    "        '''iterate through all the common dates and figure out the location of each file for labels and\n",
    "        features '''\n",
    "        labelsCommonFileLoc = os.path.join(symbolLabelsLocation, commonDate, \".\".join((commonDate, 'csv')))\n",
    "    #             comnDateFeatureLocMaster = os.path.join((symbolModelFeaturesDate, commonDate))\n",
    "#         commonDatesFeatureFile = \"\".join(\n",
    "#         (\n",
    "#         symbols[symbol], '_3_states_features_date:_', commonDate, \"_now:_\", create_date, \"_.pickle\"))\n",
    "#         FeatureFileLoc = os.path.join(symbolModelFeaturesDate, commonDatesFeatureFile)\n",
    "#         conditions = [os.path.exists(FeatureFileLoc), os.path.exists(labelsCommonFileLoc)]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
