{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ak/Documents/Research/hsmm/') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing as prep\n",
    "import time\n",
    "\n",
    "from hsmm_core.hmm import * \n",
    "from hsmm_core.prediction_engines import * \n",
    "from hsmm_core.consts import *\n",
    "from hsmm_core.statistics import *\n",
    "from hsmm_core.observation_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 16\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "#matplotlib.rc('text', usetex=True)\n",
    "#matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##format all floats to be to two points only##\n",
    "float_formatter = lambda x: \"%.2f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_states = 3\n",
    "startprob = np.array([0.5, 0.2, 0.3])\n",
    "\n",
    "transmat = np.array([[0.2, 0.4, 0.4], [0.5, 0.25, 0.25], [0.5, 0.4, 0.1]])\n",
    "\n",
    "\n",
    "\n",
    "init_params = {\n",
    "    \"obs_model_params\": {\n",
    "                                'obs_model_name': 'ExpUniGauss',\n",
    "                                'em_init_method': InitialisationMethod.cluster\n",
    "\n",
    "    },\n",
    "    \"hidden_model_params\": {\n",
    "                                'no_hidden_states': n_hidden_states,\n",
    "                                'pi':startprob,\n",
    "                                'tpm': transmat,\n",
    "                                'em_init_method': InitialisationMethod.uniform\n",
    "    },\n",
    "    \"update_tag\": 'tpsml'\n",
    "}\n",
    "obs_model_init = {\n",
    "    'sigmas': np.array([0.5, 0.003, 0.5]),\n",
    "    'lambdas': np.array([1., 0.01, 1.]),\n",
    "    'weights': np.array([0.2, 0.5, 0.3]),\n",
    "}\n",
    "obs_model = ExpUniGauss(n_hidden_states)\n",
    "\n",
    "# obs_model.set_up_initials(priors=obs_model_init)\n",
    "\n",
    "the_hmm = hmm_engine(obs_model, n_hidden_states)\n",
    "\n",
    "\n",
    "priors = {'tpm': transmat, 'pi': startprob}\n",
    "priors.update(obs_model_init)\n",
    "\n",
    "the_hmm.set_up_initials(priors=priors)\n",
    "\n",
    "data=performance_statistics(hmm=the_hmm).generate_observations(sequence_length=100, no_paths=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.360824</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875853</td>\n",
       "      <td>0.622444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003098</td>\n",
       "      <td>6.832262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.013624</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.869902</td>\n",
       "      <td>2.700484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.166253</td>\n",
       "      <td>0.157172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001587</td>\n",
       "      <td>4.070081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.119168</td>\n",
       "      <td>0.124496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.544381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.966089</td>\n",
       "      <td>0.032755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.177919</td>\n",
       "      <td>0.119580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.635032</td>\n",
       "      <td>2.338322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.992818</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003263</td>\n",
       "      <td>119.357034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>124.865790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.219401</td>\n",
       "      <td>0.183556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44.521746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.005447</td>\n",
       "      <td>130.773312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.576327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.455062</td>\n",
       "      <td>1.694153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.055007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.001410</td>\n",
       "      <td>57.535126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.174783</td>\n",
       "      <td>2.619763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.498785</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.053545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>218.027570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.780074</td>\n",
       "      <td>0.450808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.469372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.063565</td>\n",
       "      <td>1.094401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.200322</td>\n",
       "      <td>0.526289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>31.061113</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>19.516707</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.993488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>21.926019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-0.568531</td>\n",
       "      <td>1.230387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.106073</td>\n",
       "      <td>0.553897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.596782</td>\n",
       "      <td>0.992443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.684110</td>\n",
       "      <td>0.441592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.002675</td>\n",
       "      <td>134.102474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.282428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>28.474941</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.025025</td>\n",
       "      <td>1.222346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.371976</td>\n",
       "      <td>0.718177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.161370</td>\n",
       "      <td>0.104135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.188575</td>\n",
       "      <td>2.116322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.276262</td>\n",
       "      <td>2.456342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.576547</td>\n",
       "      <td>0.510601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000216</td>\n",
       "      <td>57.502891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.340654</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.306576</td>\n",
       "      <td>0.001545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.004593</td>\n",
       "      <td>78.023768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>175.335444</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.400944</td>\n",
       "      <td>0.939501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.582501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.293232</td>\n",
       "      <td>0.586904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.850174</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.120126</td>\n",
       "      <td>10.224348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.359452</td>\n",
       "      <td>1.186500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1\n",
       "0     0.360824    0.000000\n",
       "1    -0.875853    0.622444\n",
       "2     0.003098    6.832262\n",
       "3    26.013624    0.000000\n",
       "4    -0.869902    2.700484\n",
       "5     0.166253    0.157172\n",
       "6     0.725073    0.000000\n",
       "7     0.001587    4.070081\n",
       "8    -0.119168    0.124496\n",
       "9    18.544381    0.000000\n",
       "10    0.966089    0.032755\n",
       "11    0.177919    0.119580\n",
       "12   -0.635032    2.338322\n",
       "13    6.992818    0.000000\n",
       "14    0.003263  119.357034\n",
       "15  124.865790    0.000000\n",
       "16    0.219401    0.183556\n",
       "17   44.521746    0.000000\n",
       "18   -0.005447  130.773312\n",
       "19    0.045802    0.000000\n",
       "20    0.576327    0.000000\n",
       "21   -0.455062    1.694153\n",
       "22   14.055007    0.000000\n",
       "23   -0.001410   57.535126\n",
       "24    0.174783    2.619763\n",
       "25    0.498785    0.000000\n",
       "26    0.053545    0.000000\n",
       "27  218.027570    0.000000\n",
       "28   -0.780074    0.450808\n",
       "29    0.469372    0.000000\n",
       "..         ...         ...\n",
       "70   -0.063565    1.094401\n",
       "71   -0.200322    0.526289\n",
       "72   31.061113    0.000000\n",
       "73   19.516707    0.000000\n",
       "74    0.993488    0.000000\n",
       "75   21.926019    0.000000\n",
       "76   -0.568531    1.230387\n",
       "77   -0.106073    0.553897\n",
       "78   -0.596782    0.992443\n",
       "79    0.684110    0.441592\n",
       "80    0.002675  134.102474\n",
       "81    0.282428    0.000000\n",
       "82   28.474941    0.000000\n",
       "83   -0.025025    1.222346\n",
       "84    0.371976    0.718177\n",
       "85    0.161370    0.104135\n",
       "86   -0.188575    2.116322\n",
       "87    0.276262    2.456342\n",
       "88   -0.576547    0.510601\n",
       "89    0.000216   57.502891\n",
       "90    2.340654    0.000000\n",
       "91    0.306576    0.001545\n",
       "92   -0.004593   78.023768\n",
       "93  175.335444    0.000000\n",
       "94    0.400944    0.939501\n",
       "95    0.582501    0.000000\n",
       "96   -0.293232    0.586904\n",
       "97    0.850174    0.000000\n",
       "98    0.120126   10.224348\n",
       "99    0.359452    1.186500\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data[1,:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_states = 2\n",
    "no_observations = 1000\n",
    "\n",
    "obs_model_init = {\n",
    "    'sigmas': np.array([0.6, 0.013]),\n",
    "    'lambdas': np.array([1., 0.01]),\n",
    "    'weights': np.array([0.5, 0.5]),\n",
    "}\n",
    "\n",
    "    \n",
    "tpm_2s = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "startprob_2s = np.array([0.7, 0.3])\n",
    "obs_model_2s = ExpUniGauss(n_hidden_states)\n",
    "\n",
    "# obs_model.set_up_initials(priors=obs_model_init)\n",
    "\n",
    "the_hmm_two_states = hmm_engine(obs_model_2s, n_hidden_states)\n",
    "\n",
    "priors = {'tpm': tpm_2s, 'pi': startprob_2s}\n",
    "priors.update(obs_model_init)\n",
    "\n",
    "the_hmm.set_up_initials(priors=priors)\n",
    "\n",
    "data_2states=performance_statistics(hmm=the_hmm).generate_observations(sequence_length=no_observations, no_paths=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "open_time=  dt.time(8,00,00)\n",
    "close_time=  dt.time(16,30,00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2states.shape\n",
    "#pd.DataFrame(data[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(data_2states[1,:,:],columns=['ReturnTradedPrice', 'Duration'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def timestamps_(sequence_length):\n",
    "    dateTimeA = datetime.datetime.combine(datetime.date.today(), dt.time(8, 00, 00))\n",
    "    dateTimeB = datetime.datetime.combine(datetime.date.today(), dt.time(16, 30, 00))\n",
    "    delta_ = dt.timedelta(days=0,seconds=np.abs((dateTimeA - dateTimeB).total_seconds())/ sequence_length,microseconds=1.06)\n",
    "    timestamps_= [(dateTimeA+ delta_*x).strftime('%H:%M:%S:%f') for x in range (0,sequence_length)]\n",
    "    return timestamps_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TradedTime']=timestamps_(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReturnTradedPrice</th>\n",
       "      <th>Duration</th>\n",
       "      <th>TradedTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.287145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:00:00:000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003282</td>\n",
       "      <td>15.342952</td>\n",
       "      <td>08:00:30:600001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.227106</td>\n",
       "      <td>1.632876</td>\n",
       "      <td>08:01:01:200002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.883758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:01:31:800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.816687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:02:02:400004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.542905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:02:33:000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.003044</td>\n",
       "      <td>82.341536</td>\n",
       "      <td>08:03:03:600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.492284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:03:34:200007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.376294</td>\n",
       "      <td>1.853466</td>\n",
       "      <td>08:04:04:800008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003806</td>\n",
       "      <td>46.933710</td>\n",
       "      <td>08:04:35:400009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.010569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:05:06:000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.855503</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>08:05:36:600011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.413415</td>\n",
       "      <td>0.900490</td>\n",
       "      <td>08:06:07:200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.142327</td>\n",
       "      <td>0.307743</td>\n",
       "      <td>08:06:37:800013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>268.328190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:07:08:400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>218.378424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:07:39:000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>284.059916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:08:09:600016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34.394789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:08:40:200017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.000537</td>\n",
       "      <td>305.689382</td>\n",
       "      <td>08:09:10:800018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>273.095309</td>\n",
       "      <td>08:09:41:400019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000217</td>\n",
       "      <td>10.987476</td>\n",
       "      <td>08:10:12:000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.287450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:10:42:600021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>29.664444</td>\n",
       "      <td>08:11:13:200022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>18.077948</td>\n",
       "      <td>08:11:43:800023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>66.705100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:12:14:400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.001141</td>\n",
       "      <td>94.778814</td>\n",
       "      <td>08:12:45:000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001343</td>\n",
       "      <td>6.441824</td>\n",
       "      <td>08:13:15:600026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.649722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:13:46:200027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16.527216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:14:16:800028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200.333214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>08:14:47:400029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-0.418696</td>\n",
       "      <td>0.347464</td>\n",
       "      <td>16:14:42:000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>97.860390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:15:12:600971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.715707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:15:43:200972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>39.828074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:16:13:800973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>34.579960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:16:44:400974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.111329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:17:15:000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>135.118183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:17:45:600976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>222.696046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:18:16:200977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>-0.348040</td>\n",
       "      <td>0.792339</td>\n",
       "      <td>16:18:46:800978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.136670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:19:17:400979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>137.543276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:19:48:000980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.003552</td>\n",
       "      <td>19.561989</td>\n",
       "      <td>16:20:18:600981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.658947</td>\n",
       "      <td>0.639390</td>\n",
       "      <td>16:20:49:200982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.512394</td>\n",
       "      <td>0.241162</td>\n",
       "      <td>16:21:19:800983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>166.182230</td>\n",
       "      <td>16:21:50:400984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.004032</td>\n",
       "      <td>18.027683</td>\n",
       "      <td>16:22:21:000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>118.502785</td>\n",
       "      <td>16:22:51:600986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.001510</td>\n",
       "      <td>72.879303</td>\n",
       "      <td>16:23:22:200987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>-0.002472</td>\n",
       "      <td>36.502935</td>\n",
       "      <td>16:23:52:800988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>95.102436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:24:23:400989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.601520</td>\n",
       "      <td>0.763156</td>\n",
       "      <td>16:24:54:000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1.490940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:25:24:600991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-0.141320</td>\n",
       "      <td>0.661682</td>\n",
       "      <td>16:25:55:200992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:26:25:800993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.755567</td>\n",
       "      <td>0.817584</td>\n",
       "      <td>16:26:56:400994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.001391</td>\n",
       "      <td>103.034072</td>\n",
       "      <td>16:27:27:000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>169.444927</td>\n",
       "      <td>16:27:57:600996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>94.089651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:28:28:200997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.001309</td>\n",
       "      <td>197.393545</td>\n",
       "      <td>16:28:58:800998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>181.538134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16:29:29:400999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ReturnTradedPrice    Duration       TradedTime\n",
       "0            87.287145    0.000000  08:00:00:000000\n",
       "1             0.003282   15.342952  08:00:30:600001\n",
       "2             0.227106    1.632876  08:01:01:200002\n",
       "3             1.883758    0.000000  08:01:31:800003\n",
       "4             0.816687    0.000000  08:02:02:400004\n",
       "5             0.542905    0.000000  08:02:33:000005\n",
       "6            -0.003044   82.341536  08:03:03:600006\n",
       "7            27.492284    0.000000  08:03:34:200007\n",
       "8             0.376294    1.853466  08:04:04:800008\n",
       "9             0.003806   46.933710  08:04:35:400009\n",
       "10           24.010569    0.000000  08:05:06:000010\n",
       "11           -0.855503    0.035837  08:05:36:600011\n",
       "12            0.413415    0.900490  08:06:07:200012\n",
       "13           -0.142327    0.307743  08:06:37:800013\n",
       "14          268.328190    0.000000  08:07:08:400014\n",
       "15          218.378424    0.000000  08:07:39:000015\n",
       "16          284.059916    0.000000  08:08:09:600016\n",
       "17           34.394789    0.000000  08:08:40:200017\n",
       "18           -0.000537  305.689382  08:09:10:800018\n",
       "19            0.001442  273.095309  08:09:41:400019\n",
       "20            0.000217   10.987476  08:10:12:000020\n",
       "21            0.287450    0.000000  08:10:42:600021\n",
       "22            0.000044   29.664444  08:11:13:200022\n",
       "23            0.001089   18.077948  08:11:43:800023\n",
       "24           66.705100    0.000000  08:12:14:400024\n",
       "25           -0.001141   94.778814  08:12:45:000025\n",
       "26            0.001343    6.441824  08:13:15:600026\n",
       "27           21.649722    0.000000  08:13:46:200027\n",
       "28           16.527216    0.000000  08:14:16:800028\n",
       "29          200.333214    0.000000  08:14:47:400029\n",
       "..                 ...         ...              ...\n",
       "970          -0.418696    0.347464  16:14:42:000970\n",
       "971          97.860390    0.000000  16:15:12:600971\n",
       "972           0.715707    0.000000  16:15:43:200972\n",
       "973          39.828074    0.000000  16:16:13:800973\n",
       "974          34.579960    0.000000  16:16:44:400974\n",
       "975           1.111329    0.000000  16:17:15:000975\n",
       "976         135.118183    0.000000  16:17:45:600976\n",
       "977         222.696046    0.000000  16:18:16:200977\n",
       "978          -0.348040    0.792339  16:18:46:800978\n",
       "979           1.136670    0.000000  16:19:17:400979\n",
       "980         137.543276    0.000000  16:19:48:000980\n",
       "981           0.003552   19.561989  16:20:18:600981\n",
       "982          -0.658947    0.639390  16:20:49:200982\n",
       "983           0.512394    0.241162  16:21:19:800983\n",
       "984           0.000369  166.182230  16:21:50:400984\n",
       "985           0.004032   18.027683  16:22:21:000985\n",
       "986           0.001173  118.502785  16:22:51:600986\n",
       "987          -0.001510   72.879303  16:23:22:200987\n",
       "988          -0.002472   36.502935  16:23:52:800988\n",
       "989          95.102436    0.000000  16:24:23:400989\n",
       "990           0.601520    0.763156  16:24:54:000990\n",
       "991           1.490940    0.000000  16:25:24:600991\n",
       "992          -0.141320    0.661682  16:25:55:200992\n",
       "993           0.028603    0.000000  16:26:25:800993\n",
       "994           0.755567    0.817584  16:26:56:400994\n",
       "995           0.001391  103.034072  16:27:27:000995\n",
       "996           0.001197  169.444927  16:27:57:600996\n",
       "997          94.089651    0.000000  16:28:28:200997\n",
       "998          -0.001309  197.393545  16:28:58:800998\n",
       "999         181.538134    0.000000  16:29:29:400999\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in range(0,1):\n",
    "    df_features_all=pd.concat([features[fkeys[key]][0], features[fkeys[key]][2], \n",
    "                                    features[fkeys[key]][3]],axis=1).dropna()\n",
    "    df_features_all.drop('fischer_score_dweight', axis=1, inplace=True)\n",
    "    train_labels =data_dic[fkeys[key]].dropna()['trend_label_quantiles']\n",
    "    diff= len(df_features_all) -len(train_labels)\n",
    "    \n",
    "    #########\n",
    "    X= df_features_all.iloc[diff:]\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    y= train_labels\n",
    "    n_classes = train_labels.shape[0]\n",
    "    y_minus = (y==-1).astype(int)\n",
    "    y_zeros = (y==0).astype(int)\n",
    "    y_plus = (y==1).astype(int)\n",
    "    ####splitting data into train and test sets####\n",
    "    #### normalise\n",
    "    X_train, X_test, y_train_minus, y_test_minus = \\\n",
    "    train_test_split(sc.fit_transform(X), y_minus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "    X_train, X_test, y_train_plus, y_test_plus = \\\n",
    "    train_test_split(sc.fit_transform(X), y_plus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "    t0 = time.time()\n",
    "    print t0\n",
    "   \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pick number of combinations of features##\n",
    "no_i=2\n",
    "df2= [df_features_all[list(pair)]for pair in list(iter.combinations(df_features_all, no_i)) ]\n",
    "##list to store results###\n",
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in range(0,3):\n",
    "    df_features_all=pd.concat([features[fkeys[key]][0], features[fkeys[key]][2], \n",
    "                                    features[fkeys[key]][3]],axis=1).dropna()\n",
    "    df_features_all.drop('fischer_score_dweight', axis=1, inplace=True)\n",
    "    train_labels =data_dic[fkeys[key]].dropna()['trend_label_quantiles']\n",
    "    \n",
    "    \n",
    "    for j in range(0,90):\n",
    "        no_i=2\n",
    "        df2[j]= [df_features_all[list(pair)]for pair in list(iter.combinations(df_features_all, no_i)) ] \n",
    "        #print key+1, 'KEY'\n",
    "        #print j, 'index of combo of pair of features'\n",
    "        #print df2[key][j].columns.values\n",
    "        diff= len(df2[key][j]) -len(train_labels)\n",
    "        #print'######'\n",
    "  \n",
    "        #########\n",
    "        X= df2[key][j].iloc[diff:]\n",
    "        y= label_binarize(train_labels, classes=[0,1,2])\n",
    "        y= train_labels\n",
    "        n_classes = train_labels.shape[0]\n",
    "        y_minus = (y==-1).astype(int)\n",
    "        y_zeros = (y==0).astype(int)\n",
    "        y_plus = (y==1).astype(int)\n",
    "        ####splitting data into train and test sets####\n",
    "        #### normalise\n",
    "        \n",
    "        X_train, X_test, y_train_minus, y_test_minus = \\\n",
    "        train_test_split(sc.fit_transform(X), y_minus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "        \n",
    "        X_train, X_test, y_train_plus, y_test_plus = \\\n",
    "        train_test_split(sc.fit_transform(X), y_plus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "        \n",
    "#         n_classes =y.shape[1]\n",
    "#         n_samples, n_features = X.shape\n",
    "#         #### normalise\n",
    "#         X_train, X_test, y_train, y_test = \\\n",
    "#         train_test_split(sc.fit_transform(X), y, test_size=0.1, random_state=0) #splitting training and test labels for y_minus\n",
    "# #         parameters = {'kernel':('linear', 'rbf'),'gamma' : np.logspace(-2, 1, 5), 'C':[1, 10]}\n",
    "        clf = svm.SVC(kernel ='rbf', C=10, gamma='auto', random_state=0, class_weight=\"balanced\", cache_size=1024)\n",
    "        clf.fit(X_train, y_train_plus)\n",
    "        #print 'Best parameters %s' %clf.best_params_\n",
    "        #print 'Cross validation accuracy: mean = %0.3f' % clf.best_score_\n",
    "        t0 = time.time()\n",
    "        scores = cross_val_score(clf, X_train, y_train_plus, cv=5,scoring='accuracy', n_jobs=-1)\n",
    "        #print key +1\n",
    "        #print \"Training Set\"\n",
    "        #print \"SVC with rbf kernel -> cross validation accuracy: mean = %0.3f std = %0.3f\" % (np.mean(scores), np.std(scores))\n",
    "        #print \"Test Set\"\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        #print clf.score(X_test, y_test_plus)  \n",
    "        test_mse =mean_squared_error(y_test_plus, y_pred)\n",
    "        test_fbeta= fbeta_score(y_test_plus, y_pred, average='macro', beta=0.5)\n",
    "        accuracy_ = accuracy_score(y_test_plus, y_pred)\n",
    "        cnf_matrix=confusion_matrix(y_test_plus, y_pred).astype('float')\n",
    "        cnf_matrix =cnf_matrix/cnf_matrix.sum(axis=1) #normalised confusion matrix\n",
    "        #print \"R2_score: %3f\" %r2_score(y_test_plus, y_pred)\n",
    "        results_list.append({'Features':df2[key][j].columns.values,'accuracy':accuracy_,'confusion matrix':cnf_matrix,'test_mse':test_mse, 'fbeta':test_fbeta})\n",
    "        ##### parameters###\n",
    "\n",
    "    print 'Time passed:'\n",
    "    print time.time()- t0\n",
    "    print '####'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,90):\n",
    "        no_i=2\n",
    "        df2[j]= [df_features_all[list(pair)]for pair in list(iter.combinations(df_features_all, no_i)) ] \n",
    "        #print key+1, 'KEY'\n",
    "        #print j, 'index of combo of pair of features'\n",
    "        #print df2[key][j].columns.values\n",
    "        diff= len(df2[key][j]) -len(train_labels)\n",
    "        #print'######'\n",
    "  \n",
    "        #########\n",
    "        X= df2[key][j].iloc[diff:]\n",
    "        y= label_binarize(train_labels, classes=[0,1,2])\n",
    "        y= train_labels\n",
    "        n_classes = train_labels.shape[0]\n",
    "        y_minus = (y==-1).astype(int)\n",
    "        y_zeros = (y==0).astype(int)\n",
    "        y_plus = (y==1).astype(int)\n",
    "        ####splitting data into train and test sets####\n",
    "        #### normalise\n",
    "        \n",
    "        X_train, X_test, y_train_minus, y_test_minus = \\\n",
    "        train_test_split(sc.fit_transform(X), y_minus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "        \n",
    "        X_train, X_test, y_train_plus, y_test_plus = \\\n",
    "        train_test_split(sc.fit_transform(X), y_plus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "        \n",
    "#         n_classes =y.shape[1]\n",
    "#         n_samples, n_features = X.shape\n",
    "#         #### normalise\n",
    "#         X_train, X_test, y_train, y_test = \\\n",
    "#         train_test_split(sc.fit_transform(X), y, test_size=0.1, random_state=0) #splitting training and test labels for y_minus\n",
    "# #         parameters = {'kernel':('linear', 'rbf'),'gamma' : np.logspace(-2, 1, 5), 'C':[1, 10]}\n",
    "        clf = svm.SVC(kernel ='rbf', C=10, gamma='auto', random_state=0, class_weight=\"balanced\", cache_size=1024)\n",
    "        clf.fit(X_train, y_train_plus)\n",
    "        #print 'Best parameters %s' %clf.best_params_\n",
    "        #print 'Cross validation accuracy: mean = %0.3f' % clf.best_score_\n",
    "        t0 = time.time()\n",
    "        scores = cross_val_score(clf, X_train, y_train_plus, cv=5,scoring='accuracy', n_jobs=-1)\n",
    "        #print key +1\n",
    "        #print \"Training Set\"\n",
    "        #print \"SVC with rbf kernel -> cross validation accuracy: mean = %0.3f std = %0.3f\" % (np.mean(scores), np.std(scores))\n",
    "        #print \"Test Set\"\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        #print clf.score(X_test, y_test_plus)  \n",
    "        test_mse =mean_squared_error(y_test_plus, y_pred)\n",
    "        test_fbeta= fbeta_score(y_test_plus, y_pred, average='macro', beta=0.5)\n",
    "        accuracy_ = accuracy_score(y_test_plus, y_pred)\n",
    "        cnf_matrix=confusion_matrix(y_test_plus, y_pred).astype('float')\n",
    "        cnf_matrix =cnf_matrix/cnf_matrix.sum(axis=1) #normalised confusion matrix\n",
    "        #print \"R2_score: %3f\" %r2_score(y_test_plus, y_pred)\n",
    "        results_list.append({'Features':df2[key][j].columns.values,'accuracy':accuracy_,'confusion matrix':cnf_matrix,'test_mse':test_mse, 'fbeta':test_fbeta})\n",
    "        ##### parameters###\n",
    "\n",
    "print 'Time passed:'\n",
    "print time.time()- t0\n",
    "print '####'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_list)\n",
    "type(results_list)\n",
    "list_df=pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Other Classifiers for Comparison***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sc.fit_transform(df_features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=5)\n",
    "S_pca_ = pca.fit(X).transform(X)\n",
    "\n",
    "ica = FastICA(n_components=4)\n",
    "S_ica_ = ica.fit_transform(X)  # Estimate the sources\n",
    "\n",
    "S_ica_ /= S_ica_.std(axis=0)\n",
    "A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "\n",
    "\n",
    "###PCA\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "var_exp= pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(S, axis_list=None):\n",
    "    plt.scatter(S[:, 0], S[:, 1], s=2, marker='o', zorder=10,\n",
    "                color='steelblue', alpha=0.5)\n",
    "    if axis_list is not None:\n",
    "        colors = ['orange', 'red']\n",
    "        for color, axis in zip(colors, axis_list):\n",
    "            axis /= axis.std()\n",
    "            x_axis, y_axis = axis\n",
    "            # Trick to get legend to work\n",
    "            plt.plot(0.1 * x_axis, 0.1 * y_axis, linewidth=2, color=color)\n",
    "            plt.quiver(0, 0, x_axis, y_axis, zorder=11, width=0.01, scale=6,\n",
    "                       color=color)\n",
    "\n",
    "    plt.hlines(0, -3, 3)\n",
    "    plt.vlines(0, -3, 3)\n",
    "    plt.xlim(-3, 3)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_samples(X / X.std())\n",
    "plt.title('True Independent Sources')\n",
    "axis_list = [pca.components_.T, ica.mixing_]\n",
    "plt.subplot(2, 2, 2)\n",
    "#plot_samples(S_ica_ / S_ica_.std(), axis_list=axis_list)\n",
    "#legend = plt.legend(['PCA', 'ICA'], loc='upper right')\n",
    "#legend.set_zorder(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(S_ica_[:, 0]/S_ica_.std(), S_ica_[:, 1]/S_ica_.std(), s=2, marker='o', zorder=10,\n",
    "                color='steelblue', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerSVM:\n",
    "    def __init__(self, training_data, training_labels,kernel_type):\n",
    "        self.training_data_= training_data\n",
    "        self.training_labels_ = training_labels\n",
    "        self.kernel_type_ = kernel_type\n",
    "        self.param_grid_ = {'C':[1, 10]} #once code is stable moving over to using this\n",
    "        \n",
    "    def hyperparam_tune(self):\n",
    "        pipe_svc = Pipeline([('scl', max_abs_scaler),('clf', SVC(random_state=1))])\n",
    "        param_range = [0.1, 1.0, 10.0, 100.0]\n",
    "        param_grid = [{'clf__C': param_range,'clf__gamma': param_range,'clf__kernel': ['rbf']}]\n",
    "        gs = GridSearchCV(estimator=pipe_svc,param_grid=param_grid,scoring='accuracy',cv=10,n_jobs=-1)\n",
    "        gs= gs.fit(self.training_data_, self.training_labels_)\n",
    "        tuned_param_= gs.best_params_\n",
    "        return tuned_param_\n",
    "    \n",
    "    def tuned_predictor(self):\n",
    "        C_tuned_=self.hyperparam_tune()['clf__C']\n",
    "        gamma_tuned_=self.hyperparam_tune()['clf__gamma']\n",
    "        kernel_best_ =self.hyperparam_tune()['clf__kernel']\n",
    "        best_clf_ = svm.SVC(C=C_tuned_, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "                            decision_function_shape=None, degree=3, gamma=gamma_tuned_, kernel=kernel_best_,\n",
    "                            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                            tol=0.001, verbose=False)\n",
    "        best_clf_.fit(self.training_data_, self.training_labels_)\n",
    "        return best_clf_\n",
    "           \n",
    "        \n",
    "    def learn_best_parameters(self):\n",
    "            \n",
    "            svc = svm.SVC(kernel=self.kernel_type_)\n",
    "            grid = GridSearchCV(svc, param_grid=self.param_grid_)\n",
    "            grid.fit(self.training_data_, self.training_labels_)\n",
    "            svc.fit(self.training_data_, self.training_labels_)\n",
    "            print(\"The best parameters are %s with a score of %0.2f\"\n",
    "                % (grid.best_params_, grid.best_score_))\n",
    "            train_result_=svc.predict(self.training_data_)\n",
    "            if self.kernel_type_ =='linear':\n",
    "                print 'Linear Kernel Results'\n",
    "                print classification_report(self.training_labels_, train_result_)\n",
    "                print confusion_matrix(self.training_labels_, train_result_)\n",
    "                \n",
    "            \n",
    "            elif self.kernel_type_ == 'rbf':\n",
    "                print 'RBF Kernel Results'\n",
    "                print classification_report(self.training_labels_, train_result_)\n",
    "                confmat= confusion_matrix(self.training_labels_, train_result_)\n",
    "                fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "                ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "                for i in range(confmat.shape[0]):\n",
    "                    for j in range(confmat.shape[1]):\n",
    "                        ax.text(x=j, y=i,s=confmat[i, j],va='center', ha='center')\n",
    "                plt.xlabel('predicted label')\n",
    "                plt.ylabel('true label')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def my_kernel(X, Y):\n",
    "    \"\"\"\n",
    "    We create a custom kernel:\n",
    "\n",
    "                 (2  0)\n",
    "    k(X, Y) = X  (    ) Y.T\n",
    "                 (0  1)\n",
    "    \"\"\"\n",
    "    M = np.array([[2, 0], [0, 1.0]])\n",
    "    return np.dot(np.dot(X, M), Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "test_object=TrainerSVM(X_train, y_train_minus, 'rbf').hyperparam_tune()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "%time test_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object.keys()\n",
    "#test_object['clf__C']\n",
    "#test_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predictor=TrainerSVM(X_train, y_train_minus,'linear').tuned_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_labels =clf_predictor.predict(X_test)\n",
    "print clf_labels\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification_report(y_train, clf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf_predictor, 'sample_predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/ak/Documents/Research/QFPaper/aknotebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_clf = joblib.load('sample_predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_i=2\n",
    "df2= [df_features_all[list(pair)]for pair in list(iter.combinations(df_features_all, no_i)) ]\n",
    "#take all the combination of features in pairs\n",
    "#print df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=1\n",
    "train_labels =data_dic[fkeys[key]].dropna()['trend_label_quantiles']\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_len= 10 #len(df2)\n",
    "for j in range(0,k_len):\n",
    "    df2= [df_features_all[list(pair)]for pair in list(iter.combinations(df_features_all, no_i)) ] \n",
    "    #take all the combination of features in pairs\n",
    "    print df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels =data_dic[fkeys[key]].dropna()['trend_label_quantiles']\n",
    "    diff= len(df_features_all) -len(train_labels)\n",
    "    \n",
    "    #########\n",
    "    X= df_features_all.iloc[diff:]\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    y= train_labels\n",
    "    n_classes = train_labels.shape[0]\n",
    "    y_minus = (y==-1).astype(int)\n",
    "    y_zeros = (y==0).astype(int)\n",
    "    y_plus = (y==1).astype(int)\n",
    "    ####splitting data into train and test sets####\n",
    "    #### normalise\n",
    "    X_train, X_test, y_train_minus, y_test_minus = \\\n",
    "    train_test_split(sc.fit_transform(X), y_minus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "    X_train, X_test, y_train_plus, y_test_plus = \\\n",
    "    train_test_split(sc.fit_transform(X), y_plus, test_size=0.25, random_state=0) #splitting training and test labels for y_minus\n",
    "    t0 = time.time()\n",
    "    print t0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
