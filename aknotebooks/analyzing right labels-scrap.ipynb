{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "from hsmm_core.hmm import hmm_engine\n",
    "from hsmm_core.observation_models import ExpIndMixDiracGauss\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.feature_spaces import hmm_features\n",
    "from hsmm_core.hmm import hmm_calibration\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.labelling import DataLabellingSimple\n",
    "from hsmm_core.consts import ThresholdMethod, LabellingChoice\n",
    "import pickle\n",
    "from hsmm_core.consts import InitialisationMethod\n",
    "import datetime as dt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(features_tuple, labels, idx=1):\n",
    "    # not the cleanest but useful\n",
    "    # function to clean up nans as I seem to use it a lot, so better to have one function\n",
    "    # combines the features and labels and removes rows with nans across so we dont lose the ordering\n",
    "    # returns features and labels\n",
    "    features_df = pd.concat([features_tuple[0], features_tuple[1], features_tuple[2], \\\n",
    "                             features_tuple[3]], axis=1, sort=False)\n",
    "    labels_only = labels.drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice', 'ticker'], axis=1)\n",
    "    df_concat = pd.concat([features_df, labels_only.iloc[:, 0:idx]], axis=1, sort='False')\n",
    "    # only using 1st set of labels- but we can re-write this a bit\n",
    "    df_x_nan = df_concat.dropna()  # dropping all nans\n",
    "    label_column_loc_ = df_x_nan.shape[1] - 1  # location of labels column in the clean df\n",
    "    labels_ = df_x_nan.iloc[:, label_column_loc_:label_column_loc_ + 1]  # keep pure labels\n",
    "    features_ = df_x_nan.drop(df_x_nan.columns[label_column_loc_], axis=1)  # keeping the features only\n",
    "\n",
    "    return features_, labels_ #return features and labels in the X,y order that scikit takes the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker = 'test_SYNT_2states'\n",
    "\n",
    "\n",
    "data_dir = os.getenv('FINANCE_DATA')\n",
    "features_path='/home/ak/Data/features_models/features/'\n",
    "labels_path= '/home/ak/Data/features_models/labels'\n",
    "\n",
    "ticker_labels_path = os.path.join(labels_path,ticker+'/NON_DIRECTIONAL')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, ticker)):\n",
    "    os.makedirs(os.path.join(data_dir, ticker))\n",
    "    \n",
    "if not os.path.exists(ticker_labels_path):\n",
    "    os.makedirs(ticker_labels_path)\n",
    "\n",
    "    ####paths####\n",
    "main_path = '/home/ak/Data/features_models/'\n",
    "\n",
    "models_path=os.path.join(main_path,'models')\n",
    "ticker_models_path = os.path.join(models_path, ticker)\n",
    "# hmm_models_path = os.path.join(models_path,'hmm_models')\n",
    "# features_ticker_path = os.path.join(features_path, ticker)\n",
    "# predictions_path = os.path.join(main_path, 'predictions')\n",
    "if not os.path.exists(ticker_models_path):\n",
    "    os.makedirs(ticker_models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_states = 2\n",
    "sigmas = [0.05, 0.002] # fast and slow\n",
    "# Duration is measured in seconds for now (to be revised). lambda units are seconds^{-1}\n",
    "# so here we consider\n",
    "\n",
    "lambdas = [1./35., 1./10.]\n",
    "weights = [0.1, 0.6]\n",
    "\n",
    "obs_model = ExpIndMixDiracGauss(no_states)\n",
    "obs_model.set_up_initials(priors={'sigmas': sigmas, 'lambdas': lambdas, 'weights': weights})\n",
    "\n",
    "hmm_ = hmm_engine(obs_model, no_states)\n",
    "\n",
    "# set up some priors\n",
    "tpm = np.array([[0.4, 0.6], [0.7, 0.3]])\n",
    "pi = np.array([0.4, 0.6])\n",
    "hmm_.set_up_initials(priors={'tpm': tpm, 'pi': pi})\n",
    "\n",
    "no_dates = 30\n",
    "start_date = pd.datetime(2017, 6, 1)\n",
    "dummy_dates = [start_date + BDay(i) for i in range(no_dates)]\n",
    "\n",
    "no_points = 5000\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# silly hack, add 1 millisecond so that the initial timestamp is printed with milliseconds and does not\n",
    "# break the parsing of Timestamps when loading\n",
    "\n",
    "morning_start = dt.time(8, 0, 0, 1)\n",
    "\n",
    "initial_price = 100\n",
    "\n",
    "for dd in dummy_dates:\n",
    "    random_states = hmm_.sample_states(rng=rng, length=no_points)\n",
    "    observation_points = obs_model.sample_data(no_points, rng=rng, state=random_states)\n",
    "    # The first duration is always zero\n",
    "    observation_points[0, 0] = 0.\n",
    "\n",
    "    file_path = os.path.join(data_dir, ticker)\n",
    "    file_name = '.'.join([dd.strftime('%Y%m%d'), 'csv'])\n",
    "\n",
    "    data_to_save = pd.DataFrame({'states': random_states,\n",
    "                                 'Duration': observation_points[:, 0],\n",
    "                                 'ReturnTradedPrice': observation_points[:, 1],\n",
    "                                 })\n",
    "    data_to_save['TradedTime'] = pd.Series()\n",
    "\n",
    "    # Now calculate the Traded prices and traded times in reverse order as to what would happen\n",
    "    # with real data.\n",
    "    # data_to_save.loc[0, 'TradedTime'] = dt.datetime.combine(dd.date(), morning_start)\n",
    "    data_to_save['TradedTime'] = data_to_save['Duration'].cumsum().apply(lambda dur:\n",
    "                                                                         (dt.datetime.combine(dd.date(), morning_start)+\\\n",
    "                                                                                     dt.timedelta(seconds=dur)).time())\n",
    "\n",
    "    data_to_save['TradedPrice'] = initial_price * (1. + data_to_save['ReturnTradedPrice']).cumprod()\n",
    "    data_to_save.to_csv(os.path.join(file_path, file_name), index=False)\n",
    "\n",
    "print \"ok\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_hidden_states = no_states\n",
    "\n",
    "init_params = {\n",
    "    \"obs_model_params\": {\n",
    "                                'obs_model_name': 'ExpIndMixDiracGauss',\n",
    "                                'em_init_method': InitialisationMethod.cluster\n",
    "\n",
    "    },\n",
    "    \"hidden_model_params\": {\n",
    "                                'no_hidden_states': no_states,\n",
    "                                'pi':pi,\n",
    "                                'tpm': tpm,\n",
    "                                'em_init_method': InitialisationMethod.uniform\n",
    "    },\n",
    "    \"update_tag\": 'tpsml'\n",
    "}\n",
    "\n",
    "\n",
    "data = load_data(ticker, which_trading_hours=TradingHours.all_trading_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from itertools import permutations, product\n",
    "windows =[2, 5, 10, 25, 100]\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "print list(product(windows, thresholds))\n",
    "type(zip(windows,thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'SYNT_2states'\n",
    "# ticker = 'SYNT_4states'\n",
    "\n",
    "features_path = os.path.join(main_path, 'features')\n",
    "ticker_labels_path = os.path.join(labels_path, ticker)\n",
    "# ticker_models_path = os.path.join(models_path, ticker)\n",
    "# ticker_predictions_path = os.path.join(predictions_path, ticker)\n",
    "\n",
    "ticker_features_path = os.path.join(features_path, ticker)\n",
    "\n",
    "###\n",
    "\n",
    "# list of files    \n",
    "labels_list = os.listdir(ticker_labels_path)\n",
    "\n",
    "# features_list = os.listdir(ticker_features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "for label_init in label_perms:\n",
    "    print label_init\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "#     DataLabellingSimple(label_init).label_training_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window =10\n",
    "threshold =0.05\n",
    "\n",
    "\n",
    "# labelling_method_params = [{\n",
    "\n",
    "#     'labelling_method': LabellingChoice.price_move_in_window,\n",
    "#     'rolling_window': window,\n",
    "#     # Uncomment below if you want to check a price move only above a certain level\n",
    "#     'updown_threshold': threshold, #this is multiplied by 100\n",
    "#     'threshold_method': ThresholdMethod.arbitrary,\n",
    "# }]\n",
    "\n",
    "# for label_init in labelling_method_params:\n",
    "#     print label_init\n",
    "#     labeller = DataLabellingSimple(label_init)\n",
    "#     labeller.label_training_data(data)\n",
    "\n",
    "# keys_ = data.keys()\n",
    "\n",
    "# for key_, _ in enumerate(keys_):\n",
    "#     data[keys_[key_]].to_csv(ticker_labels_path+'/'+str(keys_[key_])+'.csv', index=False)\n",
    "def labelling_method_params(window, threshold):\n",
    "    labelling_method_params = {\n",
    "        'labelling_method': LabellingChoice.price_move_in_window,\n",
    "        'rolling_window': window,\n",
    "        # Uncomment below if you want to check a price move only above a certain level\n",
    "        'updown_threshold': threshold, #this is multiplied by 100\n",
    "        'threshold_method': ThresholdMethod.arbitrary,\n",
    "    }\n",
    "    return labelling_method_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8c15f15f1a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test=labelling_method_params(window, threshold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdictlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabelling_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "windows =[5, 10, 15, 25, 50, 100]\n",
    "thresholds =[0.001, 0.01, 0.1, 0.05]\n",
    "# test=labelling_method_params(window, threshold)\n",
    "from itertools import product\n",
    "dictlist = [labelling_method_params(window, threshold) for window, threshold in zip((windows, thresholds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=data.keys()\n",
    "no=2\n",
    "labels=data[dates[no]].drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice', 'ticker'], axis=1).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_directional =os.path.join(ticker_labels_path, labels_list[0])\n",
    "# no=1 #which file to load- this needs to correspond to a date\n",
    "def simple_labels(dates_folder,no=1 ):\n",
    "    label_dates=os.listdir(dates_folder)\n",
    "    file_name= os.path.join(non_directional,label_dates[no])\n",
    "    labels = pd.read_csv(file_name).drop(columns=['ReturnTradedPrice','Duration','states','TradedTime','TradedPrice','ticker'], axis=1).iloc[:,0]\n",
    "    return labels.iloc[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('l1').count().reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[dates[no]].drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice', 'ticker'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=df[df.iloc[:,0]==0].count()\n",
    "ones=df[df.iloc[:,0]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_PrMov__window_10__thres_arbitrary__5.0    0.600706\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (zeros/ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_PrMov__window_10__thres_arbitrary__5.0    4991\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
