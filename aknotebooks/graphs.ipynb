{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "# Added version check for recent scikit-learn 0.18 checksok ca\n",
    "from distutils.version import LooseVersion as Version\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "\n",
    "from collections import OrderedDict\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dir= ('/home/ak/Documents/Research/metrics/')\n",
    "\n",
    "#search only for npy files+make a list --> will use this later\n",
    "pickle_files=[s for s in os.listdir(metrics_dir) if s.endswith('metrics.pickle')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_idx=3\n",
    "column_results={}\n",
    "row_results ={}\n",
    "for pickle_idx, pickle_file in enumerate(pickle_files):\n",
    "    name = pickle_file.split(\"_\")[0]\n",
    "    pickle_file_loc = os.path.join(metrics_dir, pickle_files[pickle_idx])\n",
    "    with open(pickle_file_loc, \"rb\") as input_file:\n",
    "        load_pickle = pickle.load(input_file)\n",
    "    recall_dict = load_pickle[\"recall\"]\n",
    "    f1_score_dict = load_pickle[\"F1-score\"]\n",
    "    accuracy_dict = load_pickle['accuracy']\n",
    "    accuracy_df_columns = pd.DataFrame(pd.DataFrame(accuracy_dict).apply(lambda x: np.nanmean( x), axis=1)) #along the columns\n",
    "    accuracy_df_rows = pd.DataFrame(pd.DataFrame(accuracy_dict).apply(lambda x: np.nanmean( x), axis=0)) #along the rows\n",
    "    row_results[name] = accuracy_df_rows.mean()\n",
    "    column_results[name] = accuracy_df_columns.mean()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means= pd.DataFrame(row_results).T\n",
    "# df_means.reset_index(level=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tips = sns.load_dataset(\"tips\")\n",
    "# tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means = df_means.rename(columns={'index':'Symbol', 0:'Accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_means['Accuracy']\n",
    "# \n",
    "\n",
    "df_means['Accuracy'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in df_means['Accuracy']], index = df_means.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_context(\"talk\", font_scale=1.4, rc={\"lines.linewidth\": 2})\n",
    "# sns.set('talk','darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papercode_dir= '/home/ak/Documents/Research/Papers/figures/'\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.light_palette(\"navy\", reverse=True)\n",
    "#sns.set_palette(\"husl\")\n",
    "sns.color_palette(\"PuBuGn_d\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.title('Out of Sample Performance')\n",
    "ax = sns.barplot(y='Symbol', x='Accuracy',data=df_means)\n",
    "ax.tick_params(right=False, top=False)\n",
    "line_level = float(df_means.mean())\n",
    "plt.axvline(line_level, color= 'r', alpha=0.8, linestyle='dashed',linewidth=1.5)\n",
    "# manipulate\n",
    "ax.set_xticklabels(['{:,.02%}'.format(x) for x in df_means['Accuracy']])\n",
    "# [\"{0:.2f}%\".format(val * 100) for val in df_means['Accuracy']]\n",
    "filename='oos_performance.png'\n",
    "plt.savefig(\"\".join((papercode_dir,filename)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.plot.bar()\n",
    "plt.title('Out of sample Accuracy')\n",
    "plt.xlabel('symbol')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
