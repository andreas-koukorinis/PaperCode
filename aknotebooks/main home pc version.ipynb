{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "sc = StandardScaler()\n",
    "import os\n",
    "import pickle\n",
    "import fnmatch\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##useful functions\n",
    "\n",
    "def fwd_dates(_dates_list, _key_date):\n",
    "    # returns a list of dates that are forward from the key_date\n",
    "    fwd_dates_list = [i for i in _dates_list if i > _key_date]\n",
    "    return fwd_dates_list\n",
    "\n",
    "def common_member(a, b): \n",
    "      \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "      \n",
    "    # check length  \n",
    "    if len(a_set.intersection(b_set)) > 0: \n",
    "        return(a_set.intersection(b_set))   \n",
    "    else: \n",
    "        return(\"no common elements\") \n",
    "\n",
    "\n",
    "def remove_nans(features_tuple, labels, idx=1):\n",
    "    # not the cleanest but useful\n",
    "    # function to clean up nans as I seem to use it a lot, so better to have one function\n",
    "    # combines the features and labels and removes rows with nans across so we dont lose the ordering\n",
    "    # returns features and labels\n",
    "    features_df = pd.concat([features_tuple[0], features_tuple[1], features_tuple[2], \\\n",
    "                             features_tuple[3]], axis=1, sort=False)\n",
    "    labels_only = labels.drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice'], axis=1)\n",
    "    df_concat = pd.concat([features_df, labels_only.iloc[:, 0:idx]], axis=1, sort='False')\n",
    "    # only using 1st set of labels- but we can re-write this a bit\n",
    "    df_x_nan = df_concat.dropna()  # dropping all nans\n",
    "    label_column_loc_ = df_x_nan.shape[1] - 1  # location of labels column in the clean df\n",
    "    labels_ = df_x_nan.iloc[:, label_column_loc_:label_column_loc_ + 1]  # keep pure labels\n",
    "    features_ = df_x_nan.drop(df_x_nan.columns[label_column_loc_], axis=1)  # keeping the features only\n",
    "    return features_, labels_\n",
    "\n",
    "\n",
    "def prec_recall_report(y_true, y_predict):\n",
    "    # function to ge the sci-kit learn classification metrics into a pretty DF for csv!\n",
    "    report = pd.DataFrame(list(precision_recall_fscore_support(y_true, y_predict)),\n",
    "                          index=['Precision', 'Recall', 'F1-score', 'Support']).T\n",
    "    # Now add the 'Avg/Total' row\n",
    "    report.loc['Avg/Total', :] = precision_recall_fscore_support(y_true, y_predict, average='weighted')\n",
    "    report.loc['Avg/Total', 'Support'] = report['Support'].sum()\n",
    "    return report\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, path_main, ticker):\n",
    "        self.main_path = path_main\n",
    "        self.ticker = ticker\n",
    "\n",
    "        self.features_labels_path = os.path.join(self.main_path, 'features_models')\n",
    "        self.features_path = os.path.join(self.features_labels_path, 'features')\n",
    "        # collection of per symbol non directional labels\n",
    "        self.labels_path = os.path.join(self.features_labels_path, 'labels', self.ticker, 'NON_DIRECTIONAL')\n",
    "        self.symbol_features_path = os.path.join(self.features_labels_path, 'features', self.ticker, 'MODEL_BASED')\n",
    "        # list of all the model -oos hmm feature dates - each folder is a collection of oos feature dates\n",
    "        self.hmm_dates_list = os.listdir(self.symbol_features_path)  # each folder are the OOS features from each HMM\n",
    "        self.compute_date = os.listdir(os.path.join( \\\n",
    "            self.symbol_features_path, \\\n",
    "            os.listdir(self.symbol_features_path)[1]))[1].split(\"_\")[7]\n",
    "\n",
    "    def ticker_features(self, model_date, date):\n",
    "        # need to make this a lot more flexible with number of states\n",
    "        if model_date < date:\n",
    "            file_name = \"_\".join(\n",
    "                (self.ticker, '3', 'states', 'features', 'date:', date, 'now:', self.compute_date, '.pickle'))\n",
    "            file_loc = os.path.join(self.symbol_features_path, str(model_date), file_name)\n",
    "            with open(file_loc, 'rb') as handle:\n",
    "                ticker_features = pickle.load(handle)\n",
    "        else:\n",
    "            print('Loading Feature Date which is in-sample. Change your Model Date')\n",
    "        return ticker_features\n",
    "\n",
    "    def ticker_labels_csv(self, date):\n",
    "        file_loc = os.path.join(self.labels_path, str(date) + '.csv')\n",
    "        ticker_labels = pd.read_csv(file_loc, index_col=0)\n",
    "        return ticker_labels\n",
    "\n",
    "    @staticmethod\n",
    "    def open_pickle_file(path, pickle_file):\n",
    "        file_loc = os.path.join(path, pickle_file)\n",
    "        pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "        return pickle_to_file\n",
    "\n",
    "    @staticmethod\n",
    "    def get_date_from_file(file_, numb_):\n",
    "        return os.path.splitext(file_[numb_])[0]\n",
    "\n",
    "class MarketFeatures(object):\n",
    "    # a class to be expanded that uses features for base case -market based only-indicators/features\n",
    "    \"\"\"\"Requires:\n",
    "    a dataframe that has TradedPrice And Volume columns\n",
    "    symbol - A stock symbol on which to form a strategy on.\n",
    "    short_window - Lookback period for short moving average.\n",
    "    long_window - Lookback period for long moving average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        #         self.ticker = ticker\n",
    "        self.df = df\n",
    "\n",
    "    def load_data(self):\n",
    "        pass\n",
    "\n",
    "    def ma_spread(self, short_window=5, long_window=20):\n",
    "        # function that produces the MA spread, which can be used on its own or as an input for MACD\n",
    "        short_rolling_px = self.df['TradedPrice'].rolling(window=short_window).mean()\n",
    "        long_rolling_px = self.df['TradedPrice'].rolling(window=long_window).mean()\n",
    "        px_name = \"_\".join(('px_indx', str(short_window), str(long_window)))\n",
    "        self.df[px_name] = long_rolling_px - short_rolling_px\n",
    "        return self.df\n",
    "\n",
    "    def ma_spread_duration(self, short_window=5, long_window=20):\n",
    "        # function that produces the MA spread, which can be used on its own or as an input for MACD\n",
    "        short_rolling_px = self.df['Duration'].rolling(window=short_window).mean()\n",
    "        long_rolling_px = self.df['Duration'].rolling(window=long_window).mean()\n",
    "        dur_name = \"_\".join(('dur_indx', str(short_window), str(long_window)))\n",
    "        self.df[dur_name] = long_rolling_px - short_rolling_px\n",
    "        return self.df\n",
    "\n",
    "    def obv_calc(self):\n",
    "        # on balance volume indicator\n",
    "        self.df['SignedVolume'] = self.df['Volume'] * np.sign(self.df['TradedPrice'].diff()).cumsum()\n",
    "        self.df['SignedVolume'].iat[1] = 0\n",
    "        self.df['OBV'] = self.df['SignedVolume']  # .cumsum()\n",
    "        self.df = self.df.drop(columns=['SignedVolume'])\n",
    "        return self.df\n",
    "\n",
    "    def chaikin_mf(self, period=5):\n",
    "        # Chaikin money flow indicator\n",
    "        self.df[\"MF Multiplier\"] = (self.df['TradedPrice'] - (self.df['TradedPrice'].expanding(period).min()) \\\n",
    "                                    - (self.df['TradedPrice'].expanding(period).max() \\\n",
    "                                       - self.df['TradedPrice'])) / (\n",
    "                                           self.df['TradedPrice'].expanding(period).max() - self.df[ \\\n",
    "                                       'TradedPrice'].expanding(period).min())\n",
    "        self.df[\"MF Volume\"] = self.df['MF Multiplier'] * self.df['Volume']\n",
    "        self.df['CMF_' + str(period)] = self.df['MF Volume'].sum() / self.df[\"Volume\"].rolling(period).sum()\n",
    "        self.df = self.df.drop(columns=['MF Multiplier', 'MF Volume'])\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations\n",
    "\n",
    "data_dir = os.getenv('FINANCE_DATA')  # main directory referenced in all the code\n",
    "data_only_drive = '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'  # external date only drive\n",
    "\n",
    "# this is the central location for all the features/models/predictions\n",
    "features_models = os.path.join(data_dir,\n",
    "                               'features_models')\n",
    "features_models_dod = os.path.join(data_only_drive, 'features_models')\n",
    "# main path where all the sub-directories are (features, models, labels)\n",
    "\n",
    "# this is the central location for all the labels\n",
    "labels = os.path.join(features_models, 'labels')  # label subdirectory\n",
    "# this is the central location for all the features #feature subdirectory\n",
    "features = os.path.join(features_models, 'features')\n",
    "\n",
    "# location to save results\n",
    "model_save_loc = os.path.join(data_only_drive, 'Data', 'features_models', 'models')\n",
    "\n",
    "# location where all the models are:\n",
    "\n",
    "model_save_loc = os.path.join(data_only_drive, 'Data', 'features_models','models')\n",
    "# from the main directory select all the symbols that are finishing in .L for FTSE\n",
    "symbols_ftse = [s for s in os.listdir(features) if s.endswith('.L')]\n",
    "\n",
    "main_path = os.path.join(data_dir, 'features_models')  # main directory\n",
    "\n",
    "# location to save results\n",
    "model_loc = os.path.join(data_only_drive, 'Data', 'features_models', 'models')\n",
    "\n",
    "metrics_loc = os.path.join(data_only_drive, 'Data','features_models','metrics')\n",
    "\n",
    "features_path = os.path.join(main_path, 'features')  # all the features - same as above -redundant\n",
    "\n",
    "labels_path = os.path.join(main_path, 'labels')  # all the labels\n",
    "\n",
    "# same as above- new target directory, where all the models and output is saved\n",
    "# on the data only drive\n",
    "\n",
    "model_paths = os.path.join(data_only_drive, 'Data', 'features_models',\n",
    "                           'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#symbols\n",
    "os.listdir(features_models+'/predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a symbol that works\n",
    "symbol ='REL.L'\n",
    "\n",
    "# test symbol path, which essentially produces the path where all the fitted models are.\n",
    "# '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2/Data/features_models/models/SPT.L/SINGLE_KERNEL'\n",
    "symbol_labels_path = os.path.join(labels_path, symbol, 'NON_DIRECTIONAL')\n",
    "labels_dates = [os.listdir(symbol_labels_path)[idx].split(\".\")[0] \n",
    "                for idx, _ in enumerate(os.listdir(symbol_labels_path))]\n",
    "\n",
    "# specific symbol features list of directories. so this has all the model-based directories of features\n",
    "# each date on this list corresponds to an hmm model, and each date-directory contains all the features \n",
    "# constructed out of sample\n",
    "\n",
    "symbol_features_dates_path = os.path.join(features, symbol, 'MODEL_BASED')\n",
    "symbol_model_path = os.path.join(model_paths,symbol,'SINGLE_KERNEL')\n",
    "symbol_model_locations = [os.path.join(symbol_model_path,os.listdir(symbol_model_path)[idx]) for idx,\n",
    "                          _ in enumerate(os.listdir(symbol_model_path))]\n",
    "\n",
    "# we construct a list of all the hmm-model-date directories, each containing OOS features\n",
    "features_dates = os.listdir(symbol_features_dates_path)\n",
    "model_dates = os.listdir(symbol_model_path)\n",
    "common_dates= sorted(list(common_member(sorted(list(common_member(features_dates, model_dates)))\n",
    "          , labels_dates))) #dates common for labels, features, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "syml_features_loc = os.path.join(features,symbol,'MODEL_BASED') #create the symbol feature locations\n",
    "syml_models_loc = os.path.join(model_paths,symbol,'SINGLE_KERNEL') #create the symbol model locations\n",
    "syml_labels_loc = os.path.join(labels_path, symbol, 'NON_DIRECTIONAL')# create the symbol labels location\n",
    "# features_dates = os.listdir(symbol_features_dates_path)\n",
    "# model_dates = os.listdir(symbol_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of dates\n",
    "labels_dates = [os.listdir(syml_labels_loc)[idx].split(\".\")[0] for idx, _ in enumerate(os.listdir(syml_labels_loc))]\n",
    "features_dates= os.listdir(syml_features_loc)\n",
    "model_dates= os.listdir(syml_models_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates=sorted(list(common_member(sorted(list(common_member(features_dates, model_dates))),labels_dates)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol_compute_date\n",
    "symbol_compute_date = os.listdir(os.path.join(syml_features_loc,os.listdir(syml_features_loc)[1]))[1].split(\"_\")[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REL.L\n"
     ]
    }
   ],
   "source": [
    "#model date- this date corresponds to the model which was used for out of sample\n",
    "date_idx = 1 \n",
    "# #contains the list of detailed features for the specific model date\n",
    "# os.listdir(os.path.join(syml_features_loc, common_dates[date_idx])) \n",
    "print symbol\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#create a time-delta which will be needed for the common date\n",
    "daysdelta=timedelta(days=1)\n",
    "\n",
    "accuracy_results=defaultdict(dict)\n",
    "accuracy_models_results=defaultdict(dict)\n",
    "recall_models_results=defaultdict(dict)\n",
    "f1_models_results=defaultdict(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for common_date in common_dates:\n",
    "#     #move the common date (which is the hmm date, and folder name) one dat forward\n",
    "#     common_day_start=datetime.strptime(common_date, '%Y%m%d') +daysdelta\n",
    "#     #convert it back to a string (prob we can do in one go)\n",
    "#     first_oos_day= common_day_start.strftime('%Y%m%d')\n",
    "#     # getting the model\n",
    "#     model_name =\"_\".join((symbol,common_date,'label_PrMov__window_5__thres_arbitrary__0.1_clf_fitted_.pickle'))\n",
    "#     model_pickle=os.path.join(syml_models_loc,common_date, model_name)\n",
    "#     pickle_to_file = pickle.load(open(model_pickle, \"rb\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170704')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170705')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170706')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170707')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170710')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170711')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170712')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170713')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170714')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170717')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170718')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170719')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170720')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170721')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170724')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170725')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170726')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170727')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170728')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170731')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170801')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170802')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170803')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170804')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170807')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170808')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170809')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170810')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170811')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170814')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170815')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170816')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170817')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170818')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170821')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170822')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170823')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170824')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170825')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170829')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170830')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170831')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170901')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170904')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170905')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170906')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170907')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170908')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170911')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170912')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170913')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170914')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170915')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170918')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170919')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170920')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170921')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170922')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170925')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170926')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170927')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170928')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20170929')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171201')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171204')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171205')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171206')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171207')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171208')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171211')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171212')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171213')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171214')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171215')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171218')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171219')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171220')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171221')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171222')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171227')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171228')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20171229')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20180403')\n",
      "skipping\n",
      "skipping\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20180404')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20180405')\n",
      "skipping\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20180406')\n",
      "('Your symbol is:', 'REL.L', 'and the model date is:', '20180418')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# now lets take all the model directories and locations##\n",
    "\n",
    "for common_date in common_dates:\n",
    "    #move the common date (which is the hmm date, and folder name) one dat forward\n",
    "    common_day_start=datetime.strptime(common_date, '%Y%m%d') +daysdelta\n",
    "    #convert it back to a string (prob we can do in one go)\n",
    "    first_oos_day= common_day_start.strftime('%Y%m%d')\n",
    "    # getting the model\n",
    "    model_name =\"_\".join((symbol,common_date,'label_PrMov__window_5__thres_arbitrary__0.1_clf_fitted_.pickle'))\n",
    "    model_pickle=os.path.join(syml_models_loc,common_date, model_name)\n",
    "    \n",
    "    pickle_to_file = pickle.load(open(model_pickle, \"rb\")) #load your model\n",
    "    \n",
    "    best_estimator = pickle_to_file['SVC'] #.best_estimator_\n",
    "    print('Your symbol is:', symbol, 'and the model date is:' ,common_date)\n",
    "    # set a few OOS dates\n",
    "    \n",
    "    fwd_dates_list = sorted([i for i in common_dates if i > first_oos_day])[:3]\n",
    "    \n",
    "    fitted_models_results = {\n",
    "            'accuracy': defaultdict(dict),\n",
    "            'recall': defaultdict(dict),\n",
    "            'F1-score': defaultdict(dict)\n",
    "    }\n",
    "    oos_features_path= os.path.join(syml_features_loc, common_date)\n",
    "    for dic_idx, fwd_date in enumerate(fwd_dates_list):\n",
    "        feature_file = \"_\".join((symbol,'3_states_features_date:',fwd_date,'now:',symbol_compute_date,'.pickle'))\n",
    "        features_loc = os.path.join(syml_features_loc,common_date, feature_file)\n",
    "        features_tuple=pickle.load(open(features_loc, \"rb\"))\n",
    "        market_data_oos= pd.read_csv(os.path.join(syml_labels_loc, \n",
    "                                                  '.'.join((fwd_date,'csv'))),index_col=0)\n",
    "        features_df = pd.concat([features_tuple[0], features_tuple[1],\n",
    "                             features_tuple[2], features_tuple[3]], axis=1)\n",
    "        df_w_market_features = MarketFeatures(df=MarketFeatures(\\\n",
    "                                                                df=MarketFeatures(\n",
    "                        df=MarketFeatures(df=market_data_oos).obv_calc()).chaikin_mf()).ma_spread()).ma_spread_duration()\n",
    "# fix the sort issue!!\n",
    "        df_concat = pd.concat([features_df, df_w_market_features], axis=1).dropna()\n",
    "\n",
    "        label_name = str(df_concat.columns[df_concat.columns.str.contains(pat='label')].values[0])\n",
    "\n",
    "        df_final = df_concat.drop(columns=['TradedPrice', 'Duration', 'TradedTime', 'ReturnTradedPrice', \\\n",
    "                                           'Volume', label_name])\n",
    "        if len(df_final)> 5:\n",
    "            X = MinMaxScaler().fit_transform(df_final)\n",
    "\n",
    "            y_labels = df_concat[df_concat.columns[df_concat.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "            y_predict = best_estimator.predict(X)\n",
    "            accuracy_models_results[common_date][datetime.strptime(fwd_date, '%Y%m%d').strftime('%Y%m%d')] =(accuracy_score(y_labels, y_predict))\n",
    "            recall_models_results[common_date][datetime.strptime(fwd_date, '%Y%m%d').strftime('%Y%m%d')] =(recall_score(y_labels,y_predict))\n",
    "            f1_models_results[common_date][datetime.strptime(fwd_date, '%Y%m%d').strftime('%Y%m%d')]=f1_score(y_true= y_labels, y_pred=y_predict)\n",
    "        else:\n",
    "            print ('skipping')\n",
    "fitted_models_results['accuracy']= accuracy_models_results\n",
    "fitted_models_results['recall']= recall_models_results\n",
    "fitted_models_results['F1-score']= f1_models_results\n",
    "\n",
    "results_loc = str(os.path.join(metrics_loc, \"_\".join((symbol,\"results_metrics.pickle\"))))\n",
    "\n",
    "with open(results_loc, 'wb') as f:\n",
    "    pickle.dump(fitted_models_results, f)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1-score': defaultdict(dict,\n",
       "             {'20170713': {'20170717': 0.053877551020408164,\n",
       "               '20170718': 0.03382880574064582,\n",
       "               '20170719': 0.05140562248995984},\n",
       "              '20170714': {'20170717': 0.07428571428571429,\n",
       "               '20170718': 0.060836501901140684,\n",
       "               '20170719': 0.09701492537313432},\n",
       "              '20170717': {'20170719': 0.0, '20170720': 0.0, '20170721': 0.0},\n",
       "              '20170718': {'20170720': 0.03422982885085575,\n",
       "               '20170721': 0.07726075504828799,\n",
       "               '20170724': 0.05075337034099921},\n",
       "              '20170719': {'20170721': 0.07513988808952837,\n",
       "               '20170724': 0.04933051444679352,\n",
       "               '20170725': 0.04656862745098039},\n",
       "              '20170721': {'20170724': 0.0, '20170725': 0.0, '20170726': 0.0},\n",
       "              '20170727': {'20170731': 0.0, '20170801': 0.0, '20170802': 0.0},\n",
       "              '20170801': {'20170803': 0.0, '20170804': 0.0, '20170807': 0.0},\n",
       "              '20170804': {'20170807': 0.03701067615658363,\n",
       "               '20170808': 0.017061611374407586,\n",
       "               '20170809': 0.05737704918032786},\n",
       "              '20170807': {'20170809': 0.04780114722753346,\n",
       "               '20170810': 0.03764115432873275,\n",
       "               '20170811': 0.07355516637478109},\n",
       "              '20170808': {'20170810': 0.08917197452229299,\n",
       "               '20170811': 0.059880239520958084,\n",
       "               '20170814': 0.005089058524173028},\n",
       "              '20170810': {'20170814': 0.03361344537815126,\n",
       "               '20170815': 0.03255813953488372,\n",
       "               '20170816': 0.05143721633888048},\n",
       "              '20170811': {'20170814': 0.0,\n",
       "               '20170815': 0.046511627906976744,\n",
       "               '20170816': 0.029126213592233007},\n",
       "              '20170814': {'20170816': 0.03643724696356276,\n",
       "               '20170817': 0.03460207612456747,\n",
       "               '20170818': 0.06542056074766354},\n",
       "              '20170821': {'20170823': 0.0, '20170824': 0.0, '20170825': 0.0},\n",
       "              '20170822': {'20170824': 0.03164556962025317,\n",
       "               '20170825': 0.2,\n",
       "               '20170829': 0.05214723926380368},\n",
       "              '20170824': {'20170829': 0.0, '20170830': 0.0, '20170831': 0.0},\n",
       "              '20170829': {'20170831': 0.07809847198641764,\n",
       "               '20170901': 0.07090719499478625,\n",
       "               '20170904': 0.048192771084337345},\n",
       "              '20170831': {'20170904': 0.0, '20170905': 0.0, '20170906': 0.0},\n",
       "              '20170901': {'20170904': 0.04305283757338552,\n",
       "               '20170905': 0.07109737248840804,\n",
       "               '20170906': 0.034408602150537634},\n",
       "              '20170904': {'20170906': 0.0, '20170907': 0.0, '20170908': 0.0},\n",
       "              '20170905': {'20170907': 0.0, '20170908': 0.0, '20170911': 0.0},\n",
       "              '20170906': {'20170908': 0.055749128919860634,\n",
       "               '20170911': 0.07878787878787878,\n",
       "               '20170912': 0.03773584905660377},\n",
       "              '20170908': {'20170911': 0.05555555555555556,\n",
       "               '20170912': 0.046811945117029866,\n",
       "               '20170913': 0.03457814661134163},\n",
       "              '20170913': {'20170915': 0.09057971014492755,\n",
       "               '20170918': 0.06341463414634146,\n",
       "               '20170919': 0.1010989010989011},\n",
       "              '20170914': {'20170918': 0.0588235294117647,\n",
       "               '20170919': 0.10256410256410256,\n",
       "               '20170920': 0.05309734513274336},\n",
       "              '20170919': {'20170921': 0.03843605036447979,\n",
       "               '20170922': 0.037486218302094816,\n",
       "               '20170925': 0.03298611111111111},\n",
       "              '20170920': {'20170922': 0.037486218302094816,\n",
       "               '20170925': 0.03298611111111111,\n",
       "               '20170926': 0.029574861367837338},\n",
       "              '20170921': {'20170925': 0.03298611111111111,\n",
       "               '20170926': 0.029574861367837338,\n",
       "               '20170927': 0.037037037037037035},\n",
       "              '20170922': {'20170925': 0.03298611111111111,\n",
       "               '20170926': 0.029657089898053754,\n",
       "               '20170927': 0.037037037037037035},\n",
       "              '20170925': {'20170927': 0.0, '20170928': 0.0, '20170929': 0.0},\n",
       "              '20170928': {'20171201': 0.04140127388535032,\n",
       "               '20171204': 0.08921161825726141,\n",
       "               '20171205': 0.049164208456243856},\n",
       "              '20171201': {'20171204': 0.060769750168804856,\n",
       "               '20171205': 0.09608091024020228,\n",
       "               '20171206': 0.01876172607879925},\n",
       "              '20171204': {'20171206': 0.01965601965601966,\n",
       "               '20171207': 0.047808764940239036,\n",
       "               '20171208': 0.05765765765765765},\n",
       "              '20171213': {'20171215': 0.0, '20171218': 0.0, '20171219': 0.0},\n",
       "              '20171218': {'20171220': 0.0,\n",
       "               '20171221': 0.014184397163120569,\n",
       "               '20171222': 0.08771929824561404},\n",
       "              '20171222': {'20171227': 0.053166536356528536,\n",
       "               '20171228': 0.04227212681638045,\n",
       "               '20171229': 0.062275449101796415},\n",
       "              '20171227': {'20171229': 0.062275449101796415,\n",
       "               '20180403': 0.003980099502487562,\n",
       "               '20180404': 0.013953488372093023},\n",
       "              '20180404': {'20180406': 0.02439024390243903,\n",
       "               '20180418': 0.012541806020066888},\n",
       "              '20180406': {'20180418': 0.023724792408066426}}),\n",
       " 'accuracy': defaultdict(dict,\n",
       "             {'20170713': {'20170717': 0.027684563758389263,\n",
       "               '20170718': 0.017205422314911366,\n",
       "               '20170719': 0.026380873866446827},\n",
       "              '20170714': {'20170717': 0.7281879194630873,\n",
       "               '20170718': 0.8712200208550573,\n",
       "               '20170719': 0.8004946413849959},\n",
       "              '20170717': {'20170719': 0.9736191261335532,\n",
       "               '20170720': 0.9748803827751196,\n",
       "               '20170721': 0.9609634551495017},\n",
       "              '20170718': {'20170720': 0.29126794258373206,\n",
       "               '20170721': 0.1270764119601329,\n",
       "               '20170724': 0.1351156069364162},\n",
       "              '20170719': {'20170721': 0.03903654485049834,\n",
       "               '20170724': 0.025289017341040464,\n",
       "               '20170725': 0.02383939774153074},\n",
       "              '20170721': {'20170724': 0.9747109826589595,\n",
       "               '20170725': 0.9761606022584692,\n",
       "               '20170726': 0.9596244131455399},\n",
       "              '20170727': {'20170731': 0.9793103448275862,\n",
       "               '20170801': 0.9867498051441933,\n",
       "               '20170802': 0.9862604540023895},\n",
       "              '20170801': {'20170803': 0.9670442842430484,\n",
       "               '20170804': 0.9779874213836478,\n",
       "               '20170807': 0.9789702683103698},\n",
       "              '20170804': {'20170807': 0.01885424220449601,\n",
       "               '20170808': 0.008604206500956023,\n",
       "               '20170809': 0.029535864978902954},\n",
       "              '20170807': {'20170809': 0.15949367088607594,\n",
       "               '20170810': 0.2428430404738401,\n",
       "               '20170811': 0.4396186440677966},\n",
       "              '20170808': {'20170810': 0.8588351431391905,\n",
       "               '20170811': 0.6673728813559322,\n",
       "               '20170814': 0.5918580375782881},\n",
       "              '20170810': {'20170814': 0.8799582463465553,\n",
       "               '20170815': 0.7125086385625432,\n",
       "               '20170816': 0.23255813953488372},\n",
       "              '20170811': {'20170814': 0.7588726513569938,\n",
       "               '20170815': 0.8583275742916379,\n",
       "               '20170816': 0.8776009791921665},\n",
       "              '20170814': {'20170816': 0.7086903304773562,\n",
       "               '20170817': 0.7607204116638079,\n",
       "               '20170818': 0.8357963875205254},\n",
       "              '20170821': {'20170823': 0.9787878787878788,\n",
       "               '20170824': 0.9865439093484419,\n",
       "               '20170825': 0.9878504672897196},\n",
       "              '20170822': {'20170824': 0.78328611898017,\n",
       "               '20170825': 0.9551401869158879,\n",
       "               '20170829': 0.597918022121015},\n",
       "              '20170824': {'20170829': 0.9772283669486012,\n",
       "               '20170830': 0.9835205992509364,\n",
       "               '20170831': 0.9644670050761421},\n",
       "              '20170829': {'20170831': 0.5406091370558376,\n",
       "               '20170901': 0.31932773109243695,\n",
       "               '20170904': 0.3803921568627451},\n",
       "              '20170831': {'20170904': 0.9790849673202614,\n",
       "               '20170905': 0.9625570776255707,\n",
       "               '20170906': 0.9837997054491899},\n",
       "              '20170901': {'20170904': 0.3607843137254902,\n",
       "               '20170905': 0.4511415525114155,\n",
       "               '20170906': 0.3387334315169367},\n",
       "              '20170904': {'20170906': 0.9837997054491899,\n",
       "               '20170907': 0.976027397260274,\n",
       "               '20170908': 0.9793233082706767},\n",
       "              '20170905': {'20170907': 0.976027397260274,\n",
       "               '20170908': 0.9793233082706767,\n",
       "               '20170911': 0.9714285714285714},\n",
       "              '20170906': {'20170908': 0.7453007518796992,\n",
       "               '20170911': 0.719815668202765,\n",
       "               '20170912': 0.5995867768595041},\n",
       "              '20170908': {'20170911': 0.02857142857142857,\n",
       "               '20170912': 0.023966942148760332,\n",
       "               '20170913': 0.017593244194229415},\n",
       "              '20170913': {'20170915': 0.8114199849737039,\n",
       "               '20170918': 0.6954797779540047,\n",
       "               '20170919': 0.6672091131000814},\n",
       "              '20170914': {'20170918': 0.7716098334655036,\n",
       "               '20170919': 0.9145646867371847,\n",
       "               '20170920': 0.9056437389770723},\n",
       "              '20170919': {'20170921': 0.019594594594594596,\n",
       "               '20170922': 0.019101123595505618,\n",
       "               '20170925': 0.01676963812886143},\n",
       "              '20170920': {'20170922': 0.019101123595505618,\n",
       "               '20170925': 0.01676963812886143,\n",
       "               '20170926': 0.0150093808630394},\n",
       "              '20170921': {'20170925': 0.01676963812886143,\n",
       "               '20170926': 0.0150093808630394,\n",
       "               '20170927': 0.018867924528301886},\n",
       "              '20170922': {'20170925': 0.01676963812886143,\n",
       "               '20170926': 0.017823639774859287,\n",
       "               '20170927': 0.018867924528301886},\n",
       "              '20170925': {'20170927': 0.9811320754716981,\n",
       "               '20170928': 0.9727065959059894,\n",
       "               '20170929': 0.9890016920473773},\n",
       "              '20170928': {'20171201': 0.5899182561307902,\n",
       "               '20171204': 0.6717757009345794,\n",
       "               '20171205': 0.27862737784408803},\n",
       "              '20171201': {'20171204': 0.48,\n",
       "               '20171205': 0.7333084669899291,\n",
       "               '20171206': 0.6140221402214022},\n",
       "              '20171204': {'20171206': 0.7055350553505535,\n",
       "               '20171207': 0.8781855249745159,\n",
       "               '20171208': 0.7950626959247649},\n",
       "              '20171213': {'20171215': 0.9844253490870032,\n",
       "               '20171218': 0.9728049728049728,\n",
       "               '20171219': 0.9862258953168044},\n",
       "              '20171218': {'20171220': 0.865234375,\n",
       "               '20171221': 0.6233062330623306,\n",
       "               '20171222': 0.8377535101404057},\n",
       "              '20171222': {'20171227': 0.027309236947791166,\n",
       "               '20171228': 0.021592442645074223,\n",
       "               '20171229': 0.032138442521631644},\n",
       "              '20171227': {'20171229': 0.032138442521631644,\n",
       "               '20180403': 0.0019940179461615153,\n",
       "               '20180404': 0.00702576112412178},\n",
       "              '20180404': {'20180406': 0.9724802201582388,\n",
       "               '20180418': 0.2963955913017575},\n",
       "              '20180406': {'20180418': 0.7548406315162347}}),\n",
       " 'recall': defaultdict(dict,\n",
       "             {'20170713': {'20170717': 1.0, '20170718': 1.0, '20170719': 1.0},\n",
       "              '20170714': {'20170717': 0.3939393939393939,\n",
       "               '20170718': 0.24242424242424243,\n",
       "               '20170719': 0.40625},\n",
       "              '20170717': {'20170719': 0.0, '20170720': 0.0, '20170721': 0.0},\n",
       "              '20170718': {'20170720': 0.5,\n",
       "               '20170721': 0.9361702127659575,\n",
       "               '20170724': 0.9142857142857143},\n",
       "              '20170719': {'20170721': 1.0, '20170724': 1.0, '20170725': 1.0},\n",
       "              '20170721': {'20170724': 0.0, '20170725': 0.0, '20170726': 0.0},\n",
       "              '20170727': {'20170731': 0.0, '20170801': 0.0, '20170802': 0.0},\n",
       "              '20170801': {'20170803': 0.0, '20170804': 0.0, '20170807': 0.0},\n",
       "              '20170804': {'20170807': 1.0, '20170808': 1.0, '20170809': 1.0},\n",
       "              '20170807': {'20170809': 0.7142857142857143,\n",
       "               '20170810': 0.8333333333333334,\n",
       "               '20170811': 0.7},\n",
       "              '20170808': {'20170810': 0.3888888888888889,\n",
       "               '20170811': 0.3333333333333333,\n",
       "               '20170814': 0.09090909090909091},\n",
       "              '20170810': {'20170814': 0.18181818181818182,\n",
       "               '20170815': 0.2413793103448276,\n",
       "               '20170816': 0.8717948717948718},\n",
       "              '20170811': {'20170814': 0.0,\n",
       "               '20170815': 0.1724137931034483,\n",
       "               '20170816': 0.07692307692307693},\n",
       "              '20170814': {'20170816': 0.23076923076923078,\n",
       "               '20170817': 0.12195121951219512,\n",
       "               '20170818': 0.1794871794871795},\n",
       "              '20170821': {'20170823': 0.0, '20170824': 0.0, '20170825': 0.0},\n",
       "              '20170822': {'20170824': 0.2631578947368421,\n",
       "               '20170825': 0.46153846153846156,\n",
       "               '20170829': 0.4857142857142857},\n",
       "              '20170824': {'20170829': 0.0, '20170830': 0.0, '20170831': 0.0},\n",
       "              '20170829': {'20170831': 0.5476190476190477,\n",
       "               '20170901': 0.6666666666666666,\n",
       "               '20170904': 0.75},\n",
       "              '20170831': {'20170904': 0.0, '20170905': 0.0, '20170906': 0.0},\n",
       "              '20170901': {'20170904': 0.6875,\n",
       "               '20170905': 0.5609756097560976,\n",
       "               '20170906': 0.7272727272727273},\n",
       "              '20170904': {'20170906': 0.0, '20170907': 0.0, '20170908': 0.0},\n",
       "              '20170905': {'20170907': 0.0, '20170908': 0.0, '20170911': 0.0},\n",
       "              '20170906': {'20170908': 0.36363636363636365,\n",
       "               '20170911': 0.41935483870967744,\n",
       "               '20170912': 0.3275862068965517},\n",
       "              '20170908': {'20170911': 1.0, '20170912': 1.0, '20170913': 1.0},\n",
       "              '20170913': {'20170915': 0.38461538461538464,\n",
       "               '20170918': 0.48148148148148145,\n",
       "               '20170919': 0.5348837209302325},\n",
       "              '20170914': {'20170918': 0.3333333333333333,\n",
       "               '20170919': 0.13953488372093023,\n",
       "               '20170920': 0.075},\n",
       "              '20170919': {'20170921': 1.0, '20170922': 1.0, '20170925': 1.0},\n",
       "              '20170920': {'20170922': 1.0, '20170925': 1.0, '20170926': 1.0},\n",
       "              '20170921': {'20170925': 1.0, '20170926': 1.0, '20170927': 1.0},\n",
       "              '20170922': {'20170925': 1.0, '20170926': 1.0, '20170927': 1.0},\n",
       "              '20170925': {'20170927': 0.0, '20170928': 0.0, '20170929': 0.0},\n",
       "              '20170928': {'20171201': 0.5416666666666666,\n",
       "               '20171204': 0.6142857142857143,\n",
       "               '20171205': 0.8333333333333334},\n",
       "              '20171201': {'20171204': 0.6428571428571429,\n",
       "               '20171205': 0.6333333333333333,\n",
       "               '20171206': 0.35714285714285715},\n",
       "              '20171204': {'20171206': 0.2857142857142857,\n",
       "               '20171207': 0.17142857142857143,\n",
       "               '20171208': 0.3137254901960784},\n",
       "              '20171213': {'20171215': 0.0, '20171218': 0.0, '20171219': 0.0},\n",
       "              '20171218': {'20171220': 0.0,\n",
       "               '20171221': 0.14285714285714285,\n",
       "               '20171222': 0.17857142857142858},\n",
       "              '20171222': {'20171227': 1.0, '20171228': 1.0, '20171229': 1.0},\n",
       "              '20171227': {'20171229': 1.0, '20180403': 1.0, '20180404': 1.0},\n",
       "              '20180404': {'20180406': 0.09090909090909091, '20180418': 1.0},\n",
       "              '20180406': {'20180418': 0.6666666666666666}})}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recall', 'F1-score', 'accuracy']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = fitted_models_results['accuracy']\n",
    "recall_dict = fitted_models_results['recall']\n",
    "f1_score_dict = fitted_models_results['F1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.566548\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(accuracy_dict).apply(lambda x:np.nanmean(x), axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.544685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.DataFrame(accuracy_dict).apply(lambda x:np.nanmean(x), axis=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAND.L_results_metrics.pickle',\n",
       " 'TSCO.L_results_metrics.pickle',\n",
       " 'CPI.L_results_metrics.pickle',\n",
       " 'DGE.L_results_metrics.pickle',\n",
       " 'AZN.L_results_metrics.pickle',\n",
       " 'AV.L_skipped_dates.pickle',\n",
       " 'BATS.L_skipped_dates.pickle',\n",
       " 'MKS.L_results_metrics.pickle',\n",
       " 'RBS.L_results_metrics.pickle',\n",
       " 'GKN.L_results_metrics.pickle',\n",
       " 'SMIN.L_results_metrics.pickle',\n",
       " 'RDSa.L_results_metrics.pickle',\n",
       " 'SDR.L_results_metrics.pickle',\n",
       " 'LGEN.L_results_metrics.pickle',\n",
       " 'AV.L_results_metrics.pickle',\n",
       " 'LGEN.L_skipped_dates.pickle',\n",
       " 'RR.L_results_metrics.pickle',\n",
       " 'TSCO.L_skipped_dates.pickle',\n",
       " 'RDSa.L_20170822_results_metrics.pickle',\n",
       " 'PRU.L_20170117_results_metrics.pickle',\n",
       " 'CEY.L_results_metrics.pickle',\n",
       " 'BATS.L_results_metrics.pickle',\n",
       " 'GKN.L_skipped_dates.pickle',\n",
       " 'PSON.L_results_metrics.pickle',\n",
       " 'MAB.L_results_metrics.pickle',\n",
       " 'ITV.L_results_metrics.pickle',\n",
       " 'PRU.L_20170124_results_metrics.pickle',\n",
       " 'BARC.L_results_metrics.pickle',\n",
       " 'AAL.L_results_metrics.pickle',\n",
       " 'REL.L_results_metrics.pickle',\n",
       " 'BLT.L_results_metrics.pickle',\n",
       " 'III.L_results_metrics.pickle',\n",
       " 'ULVR.L_results_metrics.pickle',\n",
       " 'ECM.L_results_metrics.pickle',\n",
       " 'RTO.L_results_metrics.pickle',\n",
       " 'LLOY.L_results_metrics.pickle',\n",
       " 'VOD.L_results_metrics.pickle']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(metrics_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
