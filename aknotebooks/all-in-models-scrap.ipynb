{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "from hsmm_core.hmm import hmm_engine\n",
    "from hsmm_core.observation_models import ExpIndMixDiracGauss\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.feature_spaces import hmm_features\n",
    "from hsmm_core.hmm import hmm_calibration\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.labelling import DataLabellingSimple\n",
    "from hsmm_core.consts import ThresholdMethod, LabellingChoice\n",
    "import pickle\n",
    "from hsmm_core.consts import InitialisationMethod\n",
    "import datetime as dt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,  GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(features_tuple, labels, idx=1):\n",
    "    # not the cleanest but useful\n",
    "    # function to clean up nans as I seem to use it a lot, so better to have one function\n",
    "    # combines the features and labels and removes rows with nans across so we dont lose the ordering\n",
    "    # returns features and labels\n",
    "    features_df = pd.concat([features_tuple[0], features_tuple[1], features_tuple[2], \\\n",
    "                             features_tuple[3]], axis=1, sort=False)\n",
    "    labels_only = labels.drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice', 'ticker'], axis=1)\n",
    "    df_concat = pd.concat([features_df, labels_only.iloc[:, 0:idx]], axis=1, sort='False')\n",
    "    # only using 1st set of labels- but we can re-write this a bit\n",
    "    df_x_nan = df_concat.dropna()  # dropping all nans\n",
    "    label_column_loc_ = df_x_nan.shape[1] - 1  # location of labels column in the clean df\n",
    "    labels_ = df_x_nan.iloc[:, label_column_loc_:label_column_loc_ + 1]  # keep pure labels\n",
    "    features_ = df_x_nan.drop(df_x_nan.columns[label_column_loc_], axis=1)  # keeping the features only\n",
    "\n",
    "    return features_, labels_ #return features and labels in the X,y order that scikit takes the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitModels(object):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # # Train a SVM classification model\n",
    "\n",
    "    def ridge_clf(self, cv_folds=5):\n",
    "        model_ridge_clf = RidgeClassifierCV(alphas=np.arange(0.1, 1000, 0.1), \\\n",
    "                                            cv=KFold(cv_folds), normalize=True).fit(self.X_train,\n",
    "                                                                                    self.y_train.values.ravel())\n",
    "        # check if class_weight should be used as 'balanced'\n",
    "\n",
    "        return model_ridge_clf\n",
    "\n",
    "    def svm_clf(self, kernel_choice):\n",
    "        param_grid = dict(kernel=[str(kernel_choice)],\n",
    "                          C=[1, 5, 10, 25, 50, 100],\n",
    "                          gamma=[0.0001, 0.001, 0.01, 0.02, 0.05, 0.01])\n",
    "        svc = SVC(class_weight='balanced')\n",
    "        clf = GridSearchCV(svc, param_grid)\n",
    "        clf.fit(self.X_train, np.asanyarray(self.y_train).reshape(self.y_train.shape[0]))\n",
    "\n",
    "        return clf\n",
    "\n",
    "    def gradient_boost_clf(self, learning_rate=0.25):\n",
    "        # this needs to be written properly- but this is somewhat optimised#\n",
    "        GBR = GradientBoostingClassifier(n_estimators=3000, learning_rate=learning_rate,\n",
    "                                         max_depth=4, max_features='sqrt',\n",
    "                                         min_samples_leaf=15, min_samples_split=10)\n",
    "\n",
    "        gb_boost_clf = GBR.fit(self.X_train, self.y_train)\n",
    "\n",
    "        return gb_boost_clf\n",
    "\n",
    "    def gp_clf(self):\n",
    "        kernel = 1.0 * RBF([1.0])  # isotropic\n",
    "        gpc_rbf_isotropic = GaussianProcessClassifier(kernel=kernel).fit(self.X_train, self.y_train)\n",
    "        # hyperparameters are optimised by default\n",
    "        return gpc_rbf_isotropic\n",
    "\n",
    "    def random_forest_clf(self, no_est=100):\n",
    "        rfc = RandomForestClassifier(n_estimators=no_est, max_depth=4, n_jobs=-1, warm_start=True)\n",
    "        rfc.fit(X_train, y_train)\n",
    "\n",
    "        return rfc\n",
    "\n",
    "    def run_cv(self, clf_class, **kwargs):\n",
    "        # Construct a kfolds object\n",
    "        kf = KFold(len(self.y_train), n_folds=10, shuffle=True)\n",
    "        y_pred = self.y_train.copy()\n",
    "\n",
    "        # Iterate through folds\n",
    "        for train_index, test_index in kf:\n",
    "            X_train_local, X_test_local = self.X_train[train_index], self.X_train[test_index]\n",
    "            y_train_local = self.y_train[train_index]\n",
    "            # Initialize a classifier with key word arguments\n",
    "            clf = clf_class(**kwargs)\n",
    "            clf.fit(self.X_train, self.y_train)\n",
    "            y_pred[test_index] = clf.predict(X_test_local)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker = 'test_SYNT_2states'\n",
    "\n",
    "\n",
    "data_dir = os.getenv('FINANCE_DATA')\n",
    "features_path='/home/ak/Data/features_models/features/'\n",
    "labels_path= '/home/ak/Data/features_models/labels'\n",
    "\n",
    "ticker_labels_path = os.path.join(labels_path,ticker+'/NON_DIRECTIONAL')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, ticker)):\n",
    "    os.makedirs(os.path.join(data_dir, ticker))\n",
    "    \n",
    "if not os.path.exists(ticker_labels_path):\n",
    "    os.makedirs(ticker_labels_path)\n",
    "\n",
    "    ####paths####\n",
    "main_path = '/home/ak/Data/features_models/'\n",
    "\n",
    "models_path=os.path.join(main_path,'models')\n",
    "ticker_models_path = os.path.join(models_path, ticker)\n",
    "# hmm_models_path = os.path.join(models_path,'hmm_models')\n",
    "# features_ticker_path = os.path.join(features_path, ticker)\n",
    "# predictions_path = os.path.join(main_path, 'predictions')\n",
    "if not os.path.exists(ticker_models_path):\n",
    "    os.makedirs(ticker_models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_states = 2\n",
    "sigmas = [0.05, 0.002] # fast and slow\n",
    "# Duration is measured in seconds for now (to be revised). lambda units are seconds^{-1}\n",
    "# so here we consider\n",
    "\n",
    "lambdas = [1./35., 1./10.]\n",
    "weights = [0.1, 0.6]\n",
    "\n",
    "obs_model = ExpIndMixDiracGauss(no_states)\n",
    "obs_model.set_up_initials(priors={'sigmas': sigmas, 'lambdas': lambdas, 'weights': weights})\n",
    "\n",
    "hmm_ = hmm_engine(obs_model, no_states)\n",
    "\n",
    "# set up some priors\n",
    "tpm = np.array([[0.4, 0.6], [0.7, 0.3]])\n",
    "pi = np.array([0.4, 0.6])\n",
    "hmm_.set_up_initials(priors={'tpm': tpm, 'pi': pi})\n",
    "\n",
    "no_dates = 3\n",
    "start_date = pd.datetime(2017, 6, 1)\n",
    "dummy_dates = [start_date + BDay(i) for i in range(no_dates)]\n",
    "\n",
    "no_points = 5000\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# silly hack, add 1 millisecond so that the initial timestamp is printed with milliseconds and does not\n",
    "# break the parsing of Timestamps when loading\n",
    "\n",
    "morning_start = dt.time(8, 0, 0, 1)\n",
    "\n",
    "initial_price = 100\n",
    "\n",
    "for dd in dummy_dates:\n",
    "    random_states = hmm_.sample_states(rng=rng, length=no_points)\n",
    "    observation_points = obs_model.sample_data(no_points, rng=rng, state=random_states)\n",
    "    # The first duration is always zero\n",
    "    observation_points[0, 0] = 0.\n",
    "\n",
    "    file_path = os.path.join(data_dir, ticker)\n",
    "    file_name = '.'.join([dd.strftime('%Y%m%d'), 'csv'])\n",
    "\n",
    "    data_to_save = pd.DataFrame({'states': random_states,\n",
    "                                 'Duration': observation_points[:, 0],\n",
    "                                 'ReturnTradedPrice': observation_points[:, 1],\n",
    "                                 })\n",
    "    data_to_save['TradedTime'] = pd.Series()\n",
    "\n",
    "    # Now calculate the Traded prices and traded times in reverse order as to what would happen\n",
    "    # with real data.\n",
    "    # data_to_save.loc[0, 'TradedTime'] = dt.datetime.combine(dd.date(), morning_start)\n",
    "    data_to_save['TradedTime'] = data_to_save['Duration'].cumsum().apply(lambda dur:\n",
    "                                                                         (dt.datetime.combine(dd.date(), morning_start)+\\\n",
    "                                                                                     dt.timedelta(seconds=dur)).time())\n",
    "\n",
    "    data_to_save['TradedPrice'] = initial_price * (1. + data_to_save['ReturnTradedPrice']).cumprod()\n",
    "    data_to_save.to_csv(os.path.join(file_path, file_name), index=False)\n",
    "\n",
    "print \"ok\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_hidden_states = no_states\n",
    "\n",
    "init_params = {\n",
    "    \"obs_model_params\": {\n",
    "                                'obs_model_name': 'ExpIndMixDiracGauss',\n",
    "                                'em_init_method': InitialisationMethod.cluster\n",
    "\n",
    "    },\n",
    "    \"hidden_model_params\": {\n",
    "                                'no_hidden_states': n_hidden_states,\n",
    "                                'pi':pi,\n",
    "                                'tpm': tpm,\n",
    "                                'em_init_method': InitialisationMethod.uniform\n",
    "    },\n",
    "    \"update_tag\": 'tpsml'\n",
    "}\n",
    "\n",
    "\n",
    "data = load_data(ticker, which_trading_hours=TradingHours.all_trading_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trd_hours_filter = TradingHours.all_trading_day\n",
    "hmm_calibration_engine = hmm_calibration(no_parallel_procs=None,\n",
    "                                         init_params=init_params)\n",
    "\n",
    "\n",
    "trained_hmms = hmm_calibration_engine.hmm_fit_func(ticker, data, trd_hours_filter,\n",
    "                                                   force_recalc=False)\n",
    "\n",
    "\n",
    "for date, date_hmm in trained_hmms.iteritems():\n",
    "    feature_engine = hmm_features(date_hmm)\n",
    "    features = feature_engine.generate_features(data[date])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uncomment below:  for saving hmm models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###saving trained model hmms###\n",
    "# seq_model = \"_\".join((str(ticker),str(n_hidden_states),'state',\"trained\",\"hmm\",\"models\", \".pickle\"))\n",
    "# print(\"saving the model:\", seq_model)\n",
    "# pickle.dump(init_params, open(os.path.join(models_path,seq_model), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170601', '20170602', '20170605']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dates = trained_hmms.keys() #dates of the trained hmm models\n",
    "models_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "windows =[2, 5, 10, 25, 100]\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rolling_window': 10, 'labelling_method': <LabellingChoice.price_move_in_window: 'PrMov'>, 'updown_threshold': 0.05, 'threshold_method': <ThresholdMethod.arbitrary: 'arbitrary'>}\n"
     ]
    }
   ],
   "source": [
    "window =10\n",
    "threshold =0.05\n",
    "\n",
    "\n",
    "labelling_method_params = [{\n",
    "\n",
    "    'labelling_method': LabellingChoice.price_move_in_window,\n",
    "    'rolling_window': window,\n",
    "    # Uncomment below if you want to check a price move only above a certain level\n",
    "    'updown_threshold': threshold, #this is multiplied by 100\n",
    "    'threshold_method': ThresholdMethod.arbitrary,\n",
    "}]\n",
    "\n",
    "for label_init in labelling_method_params:\n",
    "    print label_init\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "    labeller.label_training_data(data)\n",
    "\n",
    "keys_ = data.keys()\n",
    "\n",
    "for key_, _ in enumerate(keys_):\n",
    "    data[keys_[key_]].to_csv(ticker_labels_path+'/'+str(keys_[key_])+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Labels: Locations we need ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'SYNT_2states'\n",
    "# ticker = 'SYNT_4states'\n",
    "\n",
    "features_path = os.path.join(main_path, 'features')\n",
    "ticker_labels_path = os.path.join(labels_path, ticker)\n",
    "# ticker_models_path = os.path.join(models_path, ticker)\n",
    "# ticker_predictions_path = os.path.join(predictions_path, ticker)\n",
    "\n",
    "ticker_features_path = os.path.join(features_path, ticker)\n",
    "\n",
    "###\n",
    "\n",
    "# list of files    \n",
    "labels_list = os.listdir(ticker_labels_path)\n",
    "\n",
    "# features_list = os.listdir(ticker_features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Labels###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_directional =os.path.join(ticker_labels_path, labels_list[0])\n",
    "# no=1 #which file to load- this needs to correspond to a date\n",
    "def simple_labels(dates_folder,no=1 ):\n",
    "    label_dates=os.listdir(dates_folder)\n",
    "    file_name= os.path.join(non_directional,label_dates[no])\n",
    "    labels = pd.read_csv(file_name).drop(columns=['ReturnTradedPrice','Duration','states','TradedTime','TradedPrice','ticker'], axis=1).iloc[:,0]\n",
    "    return labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('saving the classifiers:', '20170601_label_PrMov__window_10__thres_arbitrary__5.0_clfs_.pickle')\n",
      "('saving the classifiers:', '20170602_label_PrMov__window_10__thres_arbitrary__5.0_clfs_.pickle')\n",
      "('saving the classifiers:', '20170605_label_PrMov__window_10__thres_arbitrary__5.0_clfs_.pickle')\n"
     ]
    }
   ],
   "source": [
    "data_dic = load_data(ticker, which_trading_hours=TradingHours.all_trading_day)\n",
    "## clf fitting##\n",
    "for date, date_hmm in trained_hmms.iteritems():\n",
    "    feature_engine = hmm_features(date_hmm)\n",
    "    features_load = feature_engine.generate_features(data_dic[date])\n",
    "    labels_load= pd.read_csv(os.path.join(non_directional,str(date)+'.csv'))\n",
    "    features, labels_clean = remove_nans(features_load, labels_load)\n",
    "    x_std = sc.fit_transform(features.values.astype(np.float)) #fit & transform the features\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "        x_std, labels_clean, test_size=0.05, random_state=1, stratify=labels_clean) #probably can get rid of this\n",
    "    models_cls = FitModels(X_train, y_train)\n",
    "    best_clfs = {'SVC': models_cls.svm_clf(kernel_choice=\"rbf\")\n",
    "                 #'RIDGE_clf': models_cls.ridge_clf(),\n",
    "                 #'GBOOST': models_cls.gradient_boost_clf(),\n",
    "                 #'GP_clf': models_cls.gp_clf(),\n",
    "                 #'RF_clf': models_cls.random_forest_clf(),\n",
    "                 }\n",
    "    # This is sequence for the name of the best classifiers.\n",
    "    seq_clf = \"_\".join((str(date),labels_clean.columns.values[0],\"clfs\", \".pickle\"))\n",
    "    print(\"saving the classifiers:\",seq_clf)\n",
    "    pickle.dump(best_clfs, open(os.path.join(ticker_models_path,seq_clf), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_PrMov__window_10__thres_arbitrary__5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4740 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_PrMov__window_10__thres_arbitrary__5.0\n",
       "582                                            1.0\n",
       "4759                                           0.0\n",
       "2147                                           0.0\n",
       "933                                            1.0\n",
       "1069                                           1.0\n",
       "1716                                           1.0\n",
       "1710                                           0.0\n",
       "3175                                           1.0\n",
       "4058                                           1.0\n",
       "4850                                           1.0\n",
       "1876                                           1.0\n",
       "4360                                           0.0\n",
       "873                                            0.0\n",
       "3455                                           0.0\n",
       "2610                                           1.0\n",
       "2824                                           0.0\n",
       "2564                                           0.0\n",
       "658                                            1.0\n",
       "3699                                           1.0\n",
       "1559                                           0.0\n",
       "3225                                           1.0\n",
       "4527                                           1.0\n",
       "4207                                           1.0\n",
       "561                                            0.0\n",
       "1023                                           1.0\n",
       "1791                                           1.0\n",
       "1227                                           1.0\n",
       "3819                                           1.0\n",
       "2121                                           1.0\n",
       "832                                            1.0\n",
       "...                                            ...\n",
       "3786                                           0.0\n",
       "1541                                           1.0\n",
       "1951                                           1.0\n",
       "1287                                           0.0\n",
       "2753                                           1.0\n",
       "3329                                           1.0\n",
       "690                                            1.0\n",
       "3081                                           1.0\n",
       "2103                                           1.0\n",
       "3962                                           1.0\n",
       "4330                                           1.0\n",
       "2624                                           0.0\n",
       "2303                                           1.0\n",
       "1736                                           1.0\n",
       "4385                                           0.0\n",
       "3463                                           1.0\n",
       "3530                                           0.0\n",
       "829                                            1.0\n",
       "3624                                           1.0\n",
       "915                                            0.0\n",
       "4483                                           1.0\n",
       "4573                                           0.0\n",
       "3117                                           1.0\n",
       "1497                                           0.0\n",
       "3768                                           1.0\n",
       "922                                            1.0\n",
       "4517                                           0.0\n",
       "1987                                           1.0\n",
       "4198                                           0.0\n",
       "1402                                           1.0\n",
       "\n",
       "[4740 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
