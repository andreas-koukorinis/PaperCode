{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from hsmm_core.data_utils import TradingHours, DataLoader\n",
    "from hsmm_core.labelling import DataLabellingSimple\n",
    "from hsmm_core.consts import ThresholdMethod, LabellingChoice\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import BDay\n",
    "from hsmm_core.utils import mc_limiting_distribution, states_from_limit_dist\n",
    "from hsmm_core.observation_models import ExpIndMixDiracGauss\n",
    "from hsmm_core.feature_spaces import hmm_features\n",
    "from hsmm_core.hsmm_runner import HmmCalibration\n",
    "\n",
    "from hsmm_core.hmm import hmm_impl\n",
    "\n",
    "from hsmm_core.data_utils import DataLoader, TradingHours\n",
    "from hsmm_core.labelling import DataLabellingSimple\n",
    "from hsmm_core.consts import ThresholdMethod, LabellingChoice\n",
    "import pickle\n",
    "from hsmm_core.consts import InitialisationMethod\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,  GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "sc = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'SYNT_2states' #testing a new synthetic ticker\n",
    "\n",
    "\n",
    "ticker = 'VOD.L'\n",
    "\n",
    "data_dir = os.getenv('FINANCE_DATA') #main directory\n",
    "features_path = os.path.join(os.path.expanduser(\"~\"), 'FinData/features_models/features/') #where features are saved\n",
    "labels_path = os.path.join(os.path.expanduser(\"~\"), 'FinData/features_models/labels') #where labels are saved\n",
    "ticker_labels_path = os.path.join(labels_path, ticker + '/NON_DIRECTIONAL')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, ticker)):\n",
    "    os.makedirs(os.path.join(data_dir, ticker))\n",
    "\n",
    "if not os.path.exists(ticker_labels_path):\n",
    "    os.makedirs(ticker_labels_path)\n",
    "\n",
    "labels_list = os.listdir(ticker_labels_path)\n",
    "\n",
    "# ####paths####\n",
    "main_path = os.path.join(os.path.expanduser(\"~\"), 'Data/features_models/')\n",
    "\n",
    "models_path = os.path.join(main_path, 'models')\n",
    "ticker_models_path = os.path.join(models_path, ticker)\n",
    "\n",
    "hmm_models_path = os.path.join(models_path,'hmm_models') #only if we store the hmm models\n",
    "if not os.path.exists(ticker_models_path):\n",
    "    os.makedirs(ticker_models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ak/FinData'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.expanduser(\"~\"), 'FinData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SMIN.L',\n",
       " 'CEY.L',\n",
       " 'RR.L',\n",
       " 'RTO.L',\n",
       " 'TSCO.L',\n",
       " 'ULVR.L',\n",
       " 'CPI.L',\n",
       " 'LAND.L',\n",
       " 'WPP.L',\n",
       " 'UU.L',\n",
       " 'MKS.L',\n",
       " 'BLT.L',\n",
       " 'AV.L',\n",
       " 'VOD.L',\n",
       " 'RDSa.L',\n",
       " 'III.L',\n",
       " 'RDSb.L',\n",
       " 'ECM.L',\n",
       " 'PSON.L',\n",
       " 'REL.L',\n",
       " 'IEER.L',\n",
       " 'BARC.L',\n",
       " 'GKN.L',\n",
       " 'NG.L',\n",
       " 'RB.L',\n",
       " 'RSA.L',\n",
       " 'ITV.L',\n",
       " 'AAL.L',\n",
       " 'IOG.L',\n",
       " 'SDR.L',\n",
       " 'STAN.L',\n",
       " 'MAB.L',\n",
       " 'LGEN.L',\n",
       " 'RBS.L',\n",
       " 'LLOY.L',\n",
       " 'CPG.L',\n",
       " 'HSBA.L',\n",
       " 'EGS.L',\n",
       " 'AZN.L',\n",
       " 'SGE.L',\n",
       " 'DMGOa.L',\n",
       " 'APF.L',\n",
       " 'PRU.L',\n",
       " 'CNA.L',\n",
       " 'SHP.L',\n",
       " 'DGE.L',\n",
       " 'BATS.L',\n",
       " 'KGF.L',\n",
       " 'CCL.L',\n",
       " 'SPT.L']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir_list= os.listdir(data_dir)\n",
    "\n",
    "user_dir=os.listdir(os.path.join(os.path.expanduser(\"~\"), 'FinData'))\n",
    "ftse_list= [s for s in user_dir if s.endswith('.L')]\n",
    "tmp ='/home/ak/tmp/'\n",
    "ftse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "ticker = ftse_list[0]\n",
    "\n",
    "# sd = '20170116'\n",
    "# ed = '20170120'\n",
    "\n",
    "\n",
    "trading_hours_filter = TradingHours.only_mkt_hours\n",
    "\n",
    "data_loader = DataLoader(trading_hours_filter, ccy_bar= 1000)\n",
    "\n",
    "data = data_loader.load_trades_data(ticker)#, start_date=sd, end_date=ed)\n",
    "\n",
    "\n",
    "labelling_method_params = [\n",
    "# {\n",
    "#     'labelling_method': LabellingChoice.ep_in_window,\n",
    "#     'rolling_window': 10,\n",
    "#     'threshold_method': ThresholdMethod.historical_vol_ma,\n",
    "#     'threshold_vol_window': 5,\n",
    "#     'updown_thrshd_vol_pct': 10.,\n",
    "#     'trading_hours_filter': trading_hours_filter,\n",
    "# },\n",
    "{\n",
    "    'labelling_method': LabellingChoice.price_move_in_window,\n",
    "    'rolling_window': 2,\n",
    "    # Uncomment below if you want to check a price move only above a certain level\n",
    "    # 'updown_threshold': 0.1\n",
    "    # 'threshold_method': ThresholdMethod.arbitrary,\n",
    "}]\n",
    "\n",
    "for label_init in labelling_method_params:\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "    the_label = labeller.get_label_name()\n",
    "    labeller.label_training_data(data)\n",
    "\n",
    "print \"ok\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rolling_window': 25, 'labelling_method': 'PrMov', 'updown_threshold': 0.1, 'threshold_method': 'arbitrary'}\n"
     ]
    }
   ],
   "source": [
    "window = 25\n",
    "threshold = 0.1\n",
    "\n",
    "labelling_method_params = [{\n",
    "\n",
    "    'labelling_method': LabellingChoice.price_move_in_window,\n",
    "    'rolling_window': window,\n",
    "    # Uncomment below if you want to check a price move only above a certain level\n",
    "    'updown_threshold': threshold,  # this is multiplied by 100\n",
    "    'threshold_method': ThresholdMethod.arbitrary,\n",
    "}]\n",
    "\n",
    "for label_init in labelling_method_params:\n",
    "    print label_init\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "    labeller.label_training_data(data)\n",
    "#\n",
    "#     # # TODO IS THIS WHAT YOU WANTED TO DO ? SAVE THE DATA WITH LABELS OR JUST THE LABELS ?\n",
    "for date, date_data in data.iteritems():\n",
    "    date_data.to_csv(os.path.join(tmp, str(date)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170731',\n",
       " '20170831',\n",
       " '20170830',\n",
       " '20170727',\n",
       " '20170726',\n",
       " '20170721',\n",
       " '20170720',\n",
       " '20170929',\n",
       " '20170928',\n",
       " '20170725',\n",
       " '20170724',\n",
       " '20170925',\n",
       " '20170927',\n",
       " '20170926',\n",
       " '20170921',\n",
       " '20170920',\n",
       " '20170922',\n",
       " '20170808',\n",
       " '20170809',\n",
       " '20170807',\n",
       " '20170804',\n",
       " '20170802',\n",
       " '20170803',\n",
       " '20170801',\n",
       " '20170728',\n",
       " '20170717',\n",
       " '20170714',\n",
       " '20170712',\n",
       " '20170713',\n",
       " '20170710',\n",
       " '20170711',\n",
       " '20170718',\n",
       " '20170719',\n",
       " '20170811',\n",
       " '20170810',\n",
       " '20170815',\n",
       " '20170814',\n",
       " '20170817',\n",
       " '20170816',\n",
       " '20170818',\n",
       " '20170703',\n",
       " '20170705',\n",
       " '20170704',\n",
       " '20170707',\n",
       " '20170706',\n",
       " '20180328',\n",
       " '20180329',\n",
       " '20180326',\n",
       " '20180327',\n",
       " '20180320',\n",
       " '20180321',\n",
       " '20180322',\n",
       " '20180323',\n",
       " '20180419',\n",
       " '20180410',\n",
       " '20180411',\n",
       " '20180420',\n",
       " '20180302',\n",
       " '20180418',\n",
       " '20180301',\n",
       " '20180306',\n",
       " '20180307',\n",
       " '20180305',\n",
       " '20180412',\n",
       " '20180413',\n",
       " '20180308',\n",
       " '20180309',\n",
       " '20180416',\n",
       " '20180417',\n",
       " '20170829',\n",
       " '20170914',\n",
       " '20170915',\n",
       " '20170911',\n",
       " '20170912',\n",
       " '20170913',\n",
       " '20170918',\n",
       " '20170919',\n",
       " '20180315',\n",
       " '20180314',\n",
       " '20180316',\n",
       " '20180409',\n",
       " '20180313',\n",
       " '20180312',\n",
       " '20180405',\n",
       " '20180404',\n",
       " '20180406',\n",
       " '20180319',\n",
       " '20180403',\n",
       " '20170907',\n",
       " '20170906',\n",
       " '20170905',\n",
       " '20170904',\n",
       " '20170901',\n",
       " '20170821',\n",
       " '20170822',\n",
       " '20170823',\n",
       " '20170824',\n",
       " '20170825',\n",
       " '20170908']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    labelling_method_params = [{\n",
    "    \n",
    "            'labelling_method': LabellingChoice.price_move_in_window,\n",
    "            'rolling_window': window,\n",
    "            # Uncomment below if you want to check a price move only above a certain level\n",
    "            'updown_threshold': threshold,  # this is multiplied by 100\n",
    "            'threshold_method': ThresholdMethod.arbitrary,\n",
    "        }]\n",
    "    \n",
    "        for label_init in labelling_method_params:\n",
    "            print label_init\n",
    "            labeller = DataLabellingSimple(label_init)\n",
    "            labeller.label_training_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys=data.keys()\n",
    "# data_vol_clock[rel_data_keys[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get dates as a list \n",
    "data_files=os.listdir(os.path.join(data_dir, ticker))\n",
    "\n",
    "synt_dates=[os.path.splitext(x)[0] for x in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_dates.sort()\n",
    "start_date=synt_dates[0]\n",
    "end_date =synt_dates[-1]\n",
    "start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in data set is 1054, number of points with large price change 246\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 970, number of points with large price change 242\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 799, number of points with large price change 231\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1067, number of points with large price change 331\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 893, number of points with large price change 251\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1506, number of points with large price change 391\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 998, number of points with large price change 257\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 983, number of points with large price change 312\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1294, number of points with large price change 549\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1058, number of points with large price change 261\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1437, number of points with large price change 386\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1781, number of points with large price change 527\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 942, number of points with large price change 454\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1330, number of points with large price change 440\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 937, number of points with large price change 312\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 789, number of points with large price change 272\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 3591, number of points with large price change 1435\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 752, number of points with large price change 215\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1120, number of points with large price change 309\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 701, number of points with large price change 226\n",
      "Number of points in data set is 1099, number of points with large price change 268\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1012, number of points with large price change 301\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1356, number of points with large price change 467\n",
      "Number of points in data set is 1260, number of points with large price change 326\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1425, number of points with large price change 390\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1205, number of points with large price change 330\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 934, number of points with large price change 242\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1127, number of points with large price change 311\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 923, number of points with large price change 264\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1346, number of points with large price change 438\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1319, number of points with large price change 391\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1163, number of points with large price change 349\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 900, number of points with large price change 253\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1133, number of points with large price change 285\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1033, number of points with large price change 289\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 985, number of points with large price change 276\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 810, number of points with large price change 228\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1116, number of points with large price change 371\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1066, number of points with large price change 325\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 850, number of points with large price change 258\n",
      "Number of points in data set is 1080, number of points with large price change 287\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 987, number of points with large price change 257\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 830, number of points with large price change 207\n",
      "Number of points in data set is 1149, number of points with large price change 372\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1579, number of points with large price change 309\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 3571, number of points with large price change 1284\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 2554, number of points with large price change 912\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 3215, number of points with large price change 1222\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 2701, number of points with large price change 958\n",
      "Number of points in data set is 2574, number of points with large price change 964\n",
      "Number of points in data set is 1387, number of points with large price change 571\n",
      "Number of points in data set is 2168, number of points with large price change 870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in data set is 10622, number of points with large price change 5674\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1735, number of points with large price change 772\n",
      "Number of points in data set is 2109, number of points with large price change 587\n",
      "Number of points in data set is 1683, number of points with large price change 619\n",
      "Number of points in data set is 2151, number of points with large price change 810\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1843, number of points with large price change 830\n",
      "Number of points in data set is 1993, number of points with large price change 765\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1752, number of points with large price change 745\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1519, number of points with large price change 749\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1324, number of points with large price change 609\n",
      "Number of points in data set is 1337, number of points with large price change 578\n",
      "Number of points in data set is 1062, number of points with large price change 399\n",
      "Number of points in data set is 1375, number of points with large price change 503\n",
      "Number of points in data set is 2079, number of points with large price change 957\n",
      "Number of points in data set is 1686, number of points with large price change 808\n",
      "Number of points in data set is 1598, number of points with large price change 472\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1831, number of points with large price change 596\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 957, number of points with large price change 250\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1301, number of points with large price change 369\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1925, number of points with large price change 448\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 733, number of points with large price change 230\n",
      "Number of points in data set is 963, number of points with large price change 331\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 812, number of points with large price change 239\n",
      "Number of points in data set is 935, number of points with large price change 273\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1050, number of points with large price change 352\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1817, number of points with large price change 720\n",
      "Number of points in data set is 1432, number of points with large price change 570\n",
      "Number of points in data set is 1883, number of points with large price change 734\n",
      "Number of points in data set is 1301, number of points with large price change 516\n",
      "Number of points in data set is 1544, number of points with large price change 682\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1166, number of points with large price change 508\n",
      "Number of points in data set is 1690, number of points with large price change 601\n",
      "Number of points in data set is 2788, number of points with large price change 1227\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1537, number of points with large price change 579\n",
      "Number of points in data set is 1676, number of points with large price change 686\n",
      "Number of points in data set is 2199, number of points with large price change 794\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1497, number of points with large price change 420\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 973, number of points with large price change 260\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 819, number of points with large price change 236\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 451, number of points with large price change 174\n",
      "Number of points in data set is 1031, number of points with large price change 263\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 922, number of points with large price change 225\n",
      "Number of points in data set is 810, number of points with large price change 280\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 977, number of points with large price change 263\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1108, number of points with large price change 283\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 851, number of points with large price change 241\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n",
      "Number of points in data set is 1088, number of points with large price change 307\n",
      "Clustering of data produces highly unbalanced subsets; fall back to random intialisation.\n"
     ]
    }
   ],
   "source": [
    "data_loader_init = {\n",
    "        'trading_hours_filter': TradingHours.only_mkt_hours\n",
    "    }\n",
    "\n",
    "no_states=2\n",
    "\n",
    "hmm_init = {\n",
    "    'obs_model_name': 'CensoredExpIndMixDiracGauss',\n",
    "    'em_obs_init_method': InitialisationMethod.cluster,\n",
    "    'em_hidden_init_method': InitialisationMethod.uniform,\n",
    "    'no_hidden_states': no_states,\n",
    "    'update_tag': 'tpsml'\n",
    "}\n",
    "\n",
    "data_loader = DataLoader(**data_loader_init)\n",
    "# keep the hash of the data loader to uniquely identify how the data was loaded ( perhaps a dollar clock was\n",
    "# used), as this affects the calibration of the hmm\n",
    "data_loader_hash = data_loader.data_loader_hash()\n",
    "\n",
    "data = data_loader.load_trades_data(ticker)#, start_date=start_date, end_date=end_date)\n",
    "##calibrate the hmm models\n",
    "hmm_calibration_engine = HmmCalibration(init_params=hmm_init)\n",
    "hmm_calibration_engine.run_calibration_all_data(ticker, data, data_loader_hash,\n",
    "                                                force_recalc=False, use_multiprocessing=False,\n",
    "                                                n_processes=2)\n",
    "\n",
    "# Create the hmm feature engine and for every change the hmm model in the features engine\n",
    "features_engine = hmm_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method hmm_features.em_features of <hsmm_core.feature_spaces.hmm_features object at 0x7fb507e22490>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_engine.em_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp='/home/ak/tmp/'\n",
    "import pickle\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181223\n"
     ]
    }
   ],
   "source": [
    "now=dt.datetime.now()\n",
    "print(now.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170731\n",
      "SMIN.L_20170831_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170830_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170929_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170928_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170925_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170927_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170926_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170921_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170920_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170922_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170808_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170809_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170807_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170804_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170802_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170803_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170801_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170811_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170810_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170815_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170814_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170817_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170816_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20170818_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180328_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180329_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180326_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180327_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180320_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180321_2_states_features_date_20181223_.pickle\n",
      "SMIN.L_20180322_2_states_features_date_20181223_.pickle\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1f1866a42be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlist_fwd_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfwd_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfwd_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_fwd_dates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfeatures_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfwd_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mfeatures_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwd_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"states\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"features_date\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/virtualenvs/DataAnalysis/local/lib/python2.7/site-packages/sgm_hsmm-LOCAL-py2.7.egg/hsmm_core/feature_spaces.pyc\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(self, obs_data)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_feature_calculations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mfischer_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_fischer_score_information_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mfischer_score_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfischer_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         fischer_score_df.columns = [\"fischer_score_d{0}\".format(param) \\\n",
      "\u001b[0;32m/home/ak/virtualenvs/DataAnalysis/local/lib/python2.7/site-packages/sgm_hsmm-LOCAL-py2.7.egg/hsmm_core/feature_spaces.pyc\u001b[0m in \u001b[0;36mcalculate_fischer_score_information_matrix\u001b[0;34m(self, obs_data)\u001b[0m\n\u001b[1;32m    193\u001b[0m                         np.sum(grad_logalpha[t, :, l1] * \\\n\u001b[1;32m    194\u001b[0m                                grad_logalpha[t, :, l2] * filtering[t, :]) + \\\n\u001b[0;32m--> 195\u001b[0;31m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradsq_logalpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mgradsq_loglikelihood\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/virtualenvs/DataAnalysis/local/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m     return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 1882\u001b[0;31m                          out=out, **kwargs)\n\u001b[0m\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/virtualenvs/DataAnalysis/local/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for date, date_data in data.iteritems():\n",
    "    print(date)\n",
    "    stored_hmm, _ = hmm_calibration_engine.get_calibrated_hmm(ticker, date, data_loader_hash)\n",
    "    stored_hmm_file = \"_\".join(\n",
    "                (str(ticker),\"model_date_:\", str(date), str(no_states), \"states\", \"stored_hmm\", now.strftime('%Y%m%d'), \".pickle\"))\n",
    "    pickle.dump(stored_hmm, open(os.path.join(tmp,stored_hmm_file), 'wb')) #storing the hmm model\n",
    "    features_engine.hmm = stored_hmm\n",
    "    list_fwd_dates=fwd_dates(dates_list=list(data.keys()), key_date=date)\n",
    "    for fwd_date in list_fwd_dates:\n",
    "        features_load = features_engine.generate_features(data[fwd_date])\n",
    "        features_file = \"_\".join((str(ticker),str(fwd_date),str(no_states),\"states\",\"features_date\",now.strftime('%Y%m%d'),\".pickle\"))\n",
    "        print(features_file)\n",
    "        pickle.dump(features_load, open(os.path.join(tmp, features_file), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fwd_dates(dates_list, key_date):\n",
    "    # returns a list of dates that are forward from the key_date\n",
    "    fwd_dates_list = [i for i in dates_list if i > key_date]\n",
    "    return fwd_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TradedTime</th>\n",
       "      <th>TradedPrice</th>\n",
       "      <th>ReturnTradedPrice</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:00:36.274658</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08:02:22.947225</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>244.0</td>\n",
       "      <td>106.672567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08:02:23.047689</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.100464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08:02:26.937219</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.889530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08:03:07.726214</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>482.0</td>\n",
       "      <td>40.788995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08:03:07.970289</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.244075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08:03:07.970300</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08:04:12.873657</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>310.0</td>\n",
       "      <td>64.903357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08:04:12.873669</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08:04:12.873681</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08:04:12.884178</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.010497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08:04:12.884190</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08:05:25.956320</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>208.0</td>\n",
       "      <td>73.072130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08:05:52.265999</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>192.0</td>\n",
       "      <td>26.309679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08:05:52.268990</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08:05:52.269026</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08:08:22.995934</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>150.726908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08:08:23.005884</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.009950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08:08:24.996017</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.990133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08:10:04.742898</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>758.0</td>\n",
       "      <td>99.746881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08:10:04.792708</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.049810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08:10:04.792720</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08:10:04.992971</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.200251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08:10:18.012358</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>357.0</td>\n",
       "      <td>13.019387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08:10:47.048349</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.035991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08:13:08.036219</td>\n",
       "      <td>15.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>241.0</td>\n",
       "      <td>140.987870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08:14:23.025292</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>294.0</td>\n",
       "      <td>74.989073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08:14:23.025304</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08:14:23.051445</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.026141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08:14:23.065347</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.013902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>15:29:23.214573</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.509846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>15:29:24.014246</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.799673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>15:29:24.014283</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>698.0</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>15:29:24.019295</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.005012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>15:29:24.029085</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.009790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>15:29:24.719604</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.690519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>15:29:25.153924</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.434320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>15:29:27.893999</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>459.0</td>\n",
       "      <td>2.740075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>15:29:28.334552</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>0.440553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>15:29:30.538646</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.204094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>15:29:30.538655</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>15:29:35.219110</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.680455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>15:29:45.328209</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>442.0</td>\n",
       "      <td>10.109099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>15:29:47.228631</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.900422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>15:29:48.332825</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.104194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>15:29:50.118403</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.785578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>15:29:55.067067</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>4.948664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>15:29:55.338156</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0.271089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>15:30:00.627581</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.289425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>15:31:12.533085</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71.905504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>15:31:52.472258</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.939173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>15:32:07.481599</td>\n",
       "      <td>15.890000</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.009341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>15:32:38.834205</td>\n",
       "      <td>15.870000</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.352606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>15:35:19.583254</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>167404.0</td>\n",
       "      <td>160.749049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>15:38:47.387658</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>207.804404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>15:39:43.748289</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>56.360631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>15:45:35.902799</td>\n",
       "      <td>15.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>352.154510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>15:51:10.726874</td>\n",
       "      <td>15.803661</td>\n",
       "      <td>-0.003559</td>\n",
       "      <td>754.0</td>\n",
       "      <td>334.824075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>16:01:59.842085</td>\n",
       "      <td>15.716007</td>\n",
       "      <td>-0.005562</td>\n",
       "      <td>784.0</td>\n",
       "      <td>649.115211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>16:02:29.426200</td>\n",
       "      <td>15.748393</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>4734.0</td>\n",
       "      <td>29.584115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TradedTime  TradedPrice  ReturnTradedPrice    Volume    Duration\n",
       "0     08:00:36.274658    15.620000           0.000000     100.0    0.000000\n",
       "1     08:02:22.947225    15.630000           0.000640     244.0  106.672567\n",
       "2     08:02:23.047689    15.630000           0.000000      98.0    0.100464\n",
       "3     08:02:26.937219    15.630000           0.000000      39.0    3.889530\n",
       "4     08:03:07.726214    15.620000          -0.000640     482.0   40.788995\n",
       "5     08:03:07.970289    15.620000           0.000000     238.0    0.244075\n",
       "6     08:03:07.970300    15.620000           0.000000      52.0    0.000011\n",
       "7     08:04:12.873657    15.620000           0.000000     310.0   64.903357\n",
       "8     08:04:12.873669    15.620000           0.000000     160.0    0.000012\n",
       "9     08:04:12.873681    15.620000           0.000000     176.0    0.000012\n",
       "10    08:04:12.884178    15.620000           0.000000     260.0    0.010497\n",
       "11    08:04:12.884190    15.620000           0.000000      26.0    0.000012\n",
       "12    08:05:25.956320    15.630000           0.000640     208.0   73.072130\n",
       "13    08:05:52.265999    15.620000          -0.000640     192.0   26.309679\n",
       "14    08:05:52.268990    15.620000           0.000000     270.0    0.002991\n",
       "15    08:05:52.269026    15.620000           0.000000     422.0    0.000036\n",
       "16    08:08:22.995934    15.620000           0.000000    1048.0  150.726908\n",
       "17    08:08:23.005884    15.620000           0.000000     100.0    0.009950\n",
       "18    08:08:24.996017    15.620000           0.000000     298.0    1.990133\n",
       "19    08:10:04.742898    15.610000          -0.000640     758.0   99.746881\n",
       "20    08:10:04.792708    15.610000           0.000000     500.0    0.049810\n",
       "21    08:10:04.792720    15.610000           0.000000     418.0    0.000012\n",
       "22    08:10:04.992971    15.610000           0.000000     136.0    0.200251\n",
       "23    08:10:18.012358    15.610000           0.000000     357.0   13.019387\n",
       "24    08:10:47.048349    15.610000           0.000000      53.0   29.035991\n",
       "25    08:13:08.036219    15.610000           0.000000     241.0  140.987870\n",
       "26    08:14:23.025292    15.620000           0.000640     294.0   74.989073\n",
       "27    08:14:23.025304    15.620000           0.000000     294.0    0.000012\n",
       "28    08:14:23.051445    15.620000           0.000000     680.0    0.026141\n",
       "29    08:14:23.065347    15.620000           0.000000     187.0    0.013902\n",
       "...               ...          ...                ...       ...         ...\n",
       "1058  15:29:23.214573    15.890000           0.000630     120.0    0.509846\n",
       "1059  15:29:24.014246    15.880000          -0.000630     389.0    0.799673\n",
       "1060  15:29:24.014283    15.880000           0.000000     698.0    0.000037\n",
       "1061  15:29:24.019295    15.880000           0.000000     449.0    0.005012\n",
       "1062  15:29:24.029085    15.880000           0.000000     100.0    0.009790\n",
       "1063  15:29:24.719604    15.880000           0.000000     500.0    0.690519\n",
       "1064  15:29:25.153924    15.880000           0.000000     100.0    0.434320\n",
       "1065  15:29:27.893999    15.880000           0.000000     459.0    2.740075\n",
       "1066  15:29:28.334552    15.880000           0.000000    1068.0    0.440553\n",
       "1067  15:29:30.538646    15.880000           0.000000     173.0    2.204094\n",
       "1068  15:29:30.538655    15.880000           0.000000     197.0    0.000009\n",
       "1069  15:29:35.219110    15.880000           0.000000     120.0    4.680455\n",
       "1070  15:29:45.328209    15.880000           0.000000     442.0   10.109099\n",
       "1071  15:29:47.228631    15.880000           0.000000     120.0    1.900422\n",
       "1072  15:29:48.332825    15.890000           0.000630     443.0    1.104194\n",
       "1073  15:29:50.118403    15.880000          -0.000630     156.0    1.785578\n",
       "1074  15:29:55.067067    15.890000           0.000630    1736.0    4.948664\n",
       "1075  15:29:55.338156    15.890000           0.000000     550.0    0.271089\n",
       "1076  15:30:00.627581    15.890000           0.000000      70.0    5.289425\n",
       "1077  15:31:12.533085    15.870000          -0.001259      18.0   71.905504\n",
       "1078  15:31:52.472258    15.870000           0.000000      15.0   39.939173\n",
       "1079  15:32:07.481599    15.890000           0.001259     110.0   15.009341\n",
       "1080  15:32:38.834205    15.870000          -0.001259      43.0   31.352606\n",
       "1081  15:35:19.583254    15.860000          -0.000630  167404.0  160.749049\n",
       "1082  15:38:47.387658    15.860000           0.000000    1169.0  207.804404\n",
       "1083  15:39:43.748289    15.860000           0.000000    1002.0   56.360631\n",
       "1084  15:45:35.902799    15.860000           0.000000      34.0  352.154510\n",
       "1085  15:51:10.726874    15.803661          -0.003559     754.0  334.824075\n",
       "1086  16:01:59.842085    15.716007          -0.005562     784.0  649.115211\n",
       "1087  16:02:29.426200    15.748393           0.002059    4734.0   29.584115\n",
       "\n",
       "[1088 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(data.keys())\n",
    "# for date, date_data in data.iteritems():\n",
    "#     print len(fwd_dates(dates_list=list(data.keys()), key_date=date))\n",
    "date_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= features_load\n",
    "file_name= os.path.join(tmp,'data_tmp.pickle')\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "     data_read = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     # This is sequence for the name of the best classifiers.\n",
    "    #     seq_clf = \"_\".join((\"synt_model\",  str(date), labels_clean.columns.values[0], \"clfs\", \".pickle\"))\n",
    "    #     print(\"saving the classifiers:\", seq_clf)\n",
    "    #     pickle.dump(best_clfs, open(os.path.join(ticker_models_path, seq_clf), 'wb'))\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is sequence for the name of the best classifiers.\n",
    "    #     seq_clf = \"_\".join((\"synt_model\",  str(date), labels_clean.columns.values[0], \"clfs\", \".pickle\"))\n",
    "    #     print(\"saving the classifiers:\", seq_clf)\n",
    "    #     pickle.dump(best_clfs, open(os.path.join(ticker_models_path, seq_clf), 'wb'))\n",
    "    #a bit co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels and store the labels with the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 25\n",
    "threshold = 0.1\n",
    "\n",
    "labelling_method_params = [{\n",
    "\n",
    "    'labelling_method': LabellingChoice.price_move_in_window,\n",
    "    'rolling_window': window,\n",
    "    # Uncomment below if you want to check a price move only above a certain level\n",
    "    'updown_threshold': threshold,  # this is multiplied by 100\n",
    "    'threshold_method': ThresholdMethod.arbitrary,\n",
    "}]\n",
    "\n",
    "for label_init in labelling_method_params:\n",
    "    print label_init\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "    labeller.label_training_data(data)\n",
    "\n",
    "# SAVE THE DATA WITH LABELS \n",
    "for date, date_data in data.iteritems():\n",
    "    date_data.to_csv(os.path.join(ticker_labels_path, str(date)+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_keys=data.keys()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# oos_data = fwd_dates(_dates_list=dates, _key_date=dates[-2])]\n",
    "\n",
    "#data_for_features = dates_for_features[i],\n",
    "for index, date in enumerate(synt_data_dates):\n",
    "    seq = (synt_data_dates[index], \"csv\"); # This is sequence of strings.\n",
    "#     print str(\".\".join( seq ))\n",
    "    input_date_data = pd.read_csv(os.path.join(ticker_dir, str(\".\".join(seq))))\n",
    "#     features_oos=features_engine.generate_features(input_date_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create features for out of sample predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
