{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "from hsmm_core.hmm import hmm_engine\n",
    "from hsmm_core.observation_models import ExpIndMixDiracGauss\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.feature_spaces import hmm_features\n",
    "from hsmm_core.hmm import hmm_calibration\n",
    "from hsmm_core.data_utils import load_data, TradingHours\n",
    "from hsmm_core.labelling import DataLabellingSimple\n",
    "from hsmm_core.consts import ThresholdMethod, LabellingChoice\n",
    "import pickle\n",
    "from hsmm_core.consts import InitialisationMethod\n",
    "import datetime as dt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(features_tuple, labels, idx=1):\n",
    "    # not the cleanest but useful\n",
    "    # function to clean up nans as I seem to use it a lot, so better to have one function\n",
    "    # combines the features and labels and removes rows with nans across so we dont lose the ordering\n",
    "    # returns features and labels\n",
    "    features_df = pd.concat([features_tuple[0], features_tuple[1], features_tuple[2], \\\n",
    "                             features_tuple[3]], axis=1, sort=False)\n",
    "    labels_only = labels.drop(columns=['ReturnTradedPrice', 'Duration', 'states', 'TradedTime',\n",
    "                                       'TradedPrice', 'ticker'], axis=1)\n",
    "    df_concat = pd.concat([features_df, labels_only.iloc[:, 0:idx]], axis=1, sort='False')\n",
    "    # only using 1st set of labels- but we can re-write this a bit\n",
    "    df_x_nan = df_concat.dropna()  # dropping all nans\n",
    "    label_column_loc_ = df_x_nan.shape[1] - 1  # location of labels column in the clean df\n",
    "    labels_ = df_x_nan.iloc[:, label_column_loc_:label_column_loc_ + 1]  # keep pure labels\n",
    "    features_ = df_x_nan.drop(df_x_nan.columns[label_column_loc_], axis=1)  # keeping the features only\n",
    "\n",
    "    return features_, labels_ #return features and labels in the X,y order that scikit takes the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticker = 'test_SYNT_2states'\n",
    "\n",
    "\n",
    "data_dir = os.getenv('FINANCE_DATA')\n",
    "features_path='/home/ak/Data/features_models/features/'\n",
    "labels_path= '/home/ak/Data/features_models/labels'\n",
    "\n",
    "ticker_labels_path = os.path.join(labels_path,ticker+'/NON_DIRECTIONAL')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, ticker)):\n",
    "    os.makedirs(os.path.join(data_dir, ticker))\n",
    "    \n",
    "if not os.path.exists(ticker_labels_path):\n",
    "    os.makedirs(ticker_labels_path)\n",
    "\n",
    "    ####paths####\n",
    "main_path = '/home/ak/Data/features_models/'\n",
    "\n",
    "# models_path=os.path.join(main_path,'models')\n",
    "# hmm_models_path = os.path.join(models_path,'hmm_models')\n",
    "# features_ticker_path = os.path.join(features_path, ticker)\n",
    "# predictions_path = os.path.join(main_path, 'predictions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_states = 2\n",
    "sigmas = [0.05, 0.002] # fast and slow\n",
    "# Duration is measured in seconds for now (to be revised). lambda units are seconds^{-1}\n",
    "# so here we consider\n",
    "\n",
    "lambdas = [1./35., 1./10.]\n",
    "weights = [0.1, 0.6]\n",
    "\n",
    "obs_model = ExpIndMixDiracGauss(no_states)\n",
    "obs_model.set_up_initials(priors={'sigmas': sigmas, 'lambdas': lambdas, 'weights': weights})\n",
    "\n",
    "hmm_ = hmm_engine(obs_model, no_states)\n",
    "\n",
    "# set up some priors\n",
    "tpm = np.array([[0.4, 0.6], [0.7, 0.3]])\n",
    "pi = np.array([0.4, 0.6])\n",
    "hmm_.set_up_initials(priors={'tpm': tpm, 'pi': pi})\n",
    "\n",
    "no_dates = 3\n",
    "start_date = pd.datetime(2017, 6, 1)\n",
    "dummy_dates = [start_date + BDay(i) for i in range(no_dates)]\n",
    "\n",
    "no_points = 5000\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# silly hack, add 1 millisecond so that the initial timestamp is printed with milliseconds and does not\n",
    "# break the parsing of Timestamps when loading\n",
    "\n",
    "morning_start = dt.time(8, 0, 0, 1)\n",
    "\n",
    "initial_price = 100\n",
    "\n",
    "for dd in dummy_dates:\n",
    "    random_states = hmm_.sample_states(rng=rng, length=no_points)\n",
    "    observation_points = obs_model.sample_data(no_points, rng=rng, state=random_states)\n",
    "    # The first duration is always zero\n",
    "    observation_points[0, 0] = 0.\n",
    "\n",
    "    file_path = os.path.join(data_dir, ticker)\n",
    "    file_name = '.'.join([dd.strftime('%Y%m%d'), 'csv'])\n",
    "\n",
    "    data_to_save = pd.DataFrame({'states': random_states,\n",
    "                                 'Duration': observation_points[:, 0],\n",
    "                                 'ReturnTradedPrice': observation_points[:, 1],\n",
    "                                 })\n",
    "    data_to_save['TradedTime'] = pd.Series()\n",
    "\n",
    "    # Now calculate the Traded prices and traded times in reverse order as to what would happen\n",
    "    # with real data.\n",
    "    # data_to_save.loc[0, 'TradedTime'] = dt.datetime.combine(dd.date(), morning_start)\n",
    "    data_to_save['TradedTime'] = data_to_save['Duration'].cumsum().apply(lambda dur:\n",
    "                                                                         (dt.datetime.combine(dd.date(), morning_start)+\\\n",
    "                                                                                     dt.timedelta(seconds=dur)).time())\n",
    "\n",
    "    data_to_save['TradedPrice'] = initial_price * (1. + data_to_save['ReturnTradedPrice']).cumprod()\n",
    "    data_to_save.to_csv(os.path.join(file_path, file_name), index=False)\n",
    "\n",
    "print \"ok\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_hidden_states = no_states\n",
    "\n",
    "init_params = {\n",
    "    \"obs_model_params\": {\n",
    "                                'obs_model_name': 'ExpIndMixDiracGauss',\n",
    "                                'em_init_method': InitialisationMethod.cluster\n",
    "\n",
    "    },\n",
    "    \"hidden_model_params\": {\n",
    "                                'no_hidden_states': n_hidden_states,\n",
    "                                'pi':pi,\n",
    "                                'tpm': tpm,\n",
    "                                'em_init_method': InitialisationMethod.uniform\n",
    "    },\n",
    "    \"update_tag\": 'tpsml'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trd_hours_filter = TradingHours.all_trading_day\n",
    "hmm_calibration_engine = hmm_calibration(no_parallel_procs=None,\n",
    "                                         init_params=init_params)\n",
    "\n",
    "\n",
    "trained_hmms = hmm_calibration_engine.hmm_fit_func(ticker, data, trd_hours_filter,\n",
    "                                                   force_recalc=False)\n",
    "\n",
    "\n",
    "for date, date_hmm in trained_hmms.iteritems():\n",
    "    feature_engine = hmm_features(date_hmm)\n",
    "    features = feature_engine.generate_features(data[date])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving hmm models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###saving trained model hmms###\n",
    "# seq_model = \"_\".join((str(ticker),str(n_hidden_states),'state',\"trained\",\"hmm\",\"models\", \".pickle\"))\n",
    "# print(\"saving the model:\", seq_model)\n",
    "# pickle.dump(init_params, open(os.path.join(models_path,seq_model), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170601', '20170602', '20170605']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dates = trained_hmms.keys() #dates of the trained hmm models\n",
    "models_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "windows =[2, 5, 10, 25, 100]\n",
    "thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rolling_window': 10, 'labelling_method': <LabellingChoice.price_move_in_window: 'PrMov'>, 'updown_threshold': 0.05, 'threshold_method': <ThresholdMethod.arbitrary: 'arbitrary'>}\n"
     ]
    }
   ],
   "source": [
    "window =10\n",
    "threshold =0.05\n",
    "\n",
    "\n",
    "labelling_method_params = [{\n",
    "\n",
    "    'labelling_method': LabellingChoice.price_move_in_window,\n",
    "    'rolling_window': window,\n",
    "    # Uncomment below if you want to check a price move only above a certain level\n",
    "    'updown_threshold': threshold, #this is multiplied by 100\n",
    "    'threshold_method': ThresholdMethod.arbitrary,\n",
    "}]\n",
    "\n",
    "for label_init in labelling_method_params:\n",
    "    print label_init\n",
    "    labeller = DataLabellingSimple(label_init)\n",
    "    labeller.label_training_data(data)\n",
    "\n",
    "keys_ = data.keys()\n",
    "\n",
    "for key_, _ in enumerate(keys_):\n",
    "    data[keys_[key_]].to_csv(ticker_labels_path+'/'+str(keys_[key_])+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Labels: Locations we need ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'SYNT_2states'\n",
    "# ticker = 'SYNT_4states'\n",
    "\n",
    "features_path = os.path.join(main_path, 'features')\n",
    "ticker_labels_path = os.path.join(labels_path, ticker)\n",
    "# ticker_models_path = os.path.join(models_path, ticker)\n",
    "# ticker_predictions_path = os.path.join(predictions_path, ticker)\n",
    "\n",
    "ticker_features_path = os.path.join(features_path, ticker)\n",
    "\n",
    "###\n",
    "\n",
    "# list of files    \n",
    "labels_list = os.listdir(ticker_labels_path)\n",
    "\n",
    "# features_list = os.listdir(ticker_features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Labels###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_directional =os.path.join(ticker_labels_path, labels_list[0])\n",
    "# no=1 #which file to load- this needs to correspond to a date\n",
    "def simple_labels(dates_folder,no=1 ):\n",
    "    label_dates=os.listdir(dates_folder)\n",
    "    file_name= os.path.join(non_directional,label_dates[no])\n",
    "    labels = pd.read_csv(file_name).drop(columns=['ReturnTradedPrice','Duration','states','TradedTime','TradedPrice','ticker'], axis=1).iloc[:,0]\n",
    "    return labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "5       1.0\n",
       "6       1.0\n",
       "7       1.0\n",
       "8       1.0\n",
       "9       1.0\n",
       "10      1.0\n",
       "11      0.0\n",
       "12      0.0\n",
       "13      0.0\n",
       "14      0.0\n",
       "15      0.0\n",
       "16      0.0\n",
       "17      0.0\n",
       "18      0.0\n",
       "19      0.0\n",
       "20      0.0\n",
       "21      0.0\n",
       "22      0.0\n",
       "23      0.0\n",
       "24      0.0\n",
       "25      0.0\n",
       "26      1.0\n",
       "27      1.0\n",
       "28      1.0\n",
       "29      1.0\n",
       "       ... \n",
       "4961    1.0\n",
       "4962    1.0\n",
       "4963    0.0\n",
       "4964    1.0\n",
       "4965    1.0\n",
       "4966    1.0\n",
       "4967    1.0\n",
       "4968    1.0\n",
       "4969    1.0\n",
       "4970    0.0\n",
       "4971    0.0\n",
       "4972    0.0\n",
       "4973    1.0\n",
       "4974    1.0\n",
       "4975    0.0\n",
       "4976    0.0\n",
       "4977    1.0\n",
       "4978    1.0\n",
       "4979    0.0\n",
       "4980    0.0\n",
       "4981    0.0\n",
       "4982    0.0\n",
       "4983    0.0\n",
       "4984    1.0\n",
       "4985    1.0\n",
       "4986    1.0\n",
       "4987    1.0\n",
       "4988    1.0\n",
       "4989    1.0\n",
       "4990    1.0\n",
       "Name: label_PrMov__window_10__thres_arbitrary__5.0, Length: 4991, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the dates only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = load_data(ticker, which_trading_hours=TradingHours.all_trading_day)\n",
    "## clf fitting##\n",
    "for date, date_hmm in trained_hmms.iteritems():\n",
    "    feature_engine = hmm_features(date_hmm)\n",
    "    features_load = feature_engine.generate_features(data_dic[date])\n",
    "    simple_labels(non_directional, no=1)\n",
    "#     labels_load = data_cls.ticker_labels_csv(date=date)\n",
    "#     features, labels_clean = remove_nans(features_load, labels_load)\n",
    "#     x_std = sc.fit_transform(features.values.astype(np.float)) #fit & transform the features\n",
    "#     X_train, X_test, y_train, y_test = train_test_split( \\\n",
    "#         x_std, labels_clean, test_size=0.05, random_state=1, stratify=labels_clean) #probably can get rid of this\n",
    "#     models_cls = FitModels(X_train, y_train)\n",
    "#     best_clfs = {'SVC': models_cls.svm_clf(kernel_choice=\"rbf\"),\n",
    "#                  'RIDGE_clf': models_cls.ridge_clf(),\n",
    "#                  'GBOOST': models_cls.gradient_boost_clf(),\n",
    "#                  'GP_clf': models_cls.gp_clf(),\n",
    "#                  'RF_clf': models_cls.random_forest_clf(),\n",
    "#                  }\n",
    "#     # This is sequence for the name of the best classifiers.\n",
    "#     seq_clf = \"_\".join((str(date),labels_clean.columns.values[0],\"clfs\", \".pickle\"))\n",
    "#     print(\"saving the classifiers:\",seq_clf)\n",
    "#     pickle.dump(best_clfs, open(os.path.join(ticker_models_path,seq_clf), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
