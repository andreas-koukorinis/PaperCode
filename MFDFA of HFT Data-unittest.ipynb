{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "###\n",
    "import pystan\n",
    "from scipy.stats import pearsonr, zscore\n",
    "from MFDFA import fgn\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sb.set()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/directory/tothe/handshakefile/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ak/Documents/Research/PaperCode'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stylised_facts.stylised_facts_data_utilities.createLOB as createLOB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import visual tools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "\n",
    "#plt.rcParams['font.family'] = 'DejaVu Sans Mono'\n",
    "#plt.rcParams['font.size'] = 9.5\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "#plt.rcParams['figure.figsize'] = 10,7\n",
    "blue, green, red, purple, gold, teal = sns.color_palette('colorblind', 6)\n",
    "\n",
    "# import util libs\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 777\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_axes(title, figsize=(16, 6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    # define the axis for the first plot\n",
    "    left, width = 0.1, 0.22\n",
    "    bottom, height = 0.1, 0.7\n",
    "    bottom_h = height + 0.15\n",
    "    left_h = left + width + 0.02\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom_h, width, 0.1]\n",
    "    rect_histy = [left_h, bottom, 0.05, height]\n",
    "\n",
    "    ax_scatter = plt.axes(rect_scatter)\n",
    "    ax_histx = plt.axes(rect_histx)\n",
    "    ax_histy = plt.axes(rect_histy)\n",
    "\n",
    "    # define the axis for the zoomed-in plot\n",
    "    left = width + left + 0.2\n",
    "    left_h = left + width + 0.02\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom_h, width, 0.1]\n",
    "    rect_histy = [left_h, bottom, 0.05, height]\n",
    "\n",
    "    ax_scatter_zoom = plt.axes(rect_scatter)\n",
    "    ax_histx_zoom = plt.axes(rect_histx)\n",
    "    ax_histy_zoom = plt.axes(rect_histy)\n",
    "\n",
    "    # define the axis for the colorbar\n",
    "    left, width = width + left + 0.13, 0.01\n",
    "\n",
    "    rect_colorbar = [left, bottom, width, height]\n",
    "    ax_colorbar = plt.axes(rect_colorbar)\n",
    "\n",
    "    return ((ax_scatter, ax_histy, ax_histx),\n",
    "            (ax_scatter_zoom, ax_histy_zoom, ax_histx_zoom),\n",
    "            ax_colorbar)\n",
    "\n",
    "\n",
    "def plot_distribution(axes, X, y, hist_nbins=50, title=\"\",\n",
    "                      x0_label=\"\", x1_label=\"\"):\n",
    "    ax, hist_X1, hist_X0 = axes\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x0_label)\n",
    "    ax.set_ylabel(x1_label)\n",
    "\n",
    "    # The scatter plot\n",
    "    colors = cmap(y)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.5, marker='o', s=5, lw=0, c=colors)\n",
    "\n",
    "    # Removing the top and the right spine for aesthetics\n",
    "    # make nice axis layout\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "\n",
    "    # Histogram for axis X1 (feature 5)\n",
    "    hist_X1.set_ylim(ax.get_ylim())\n",
    "    hist_X1.hist(X[:, 1], bins=hist_nbins, orientation='horizontal',\n",
    "                 color='grey', ec='grey')\n",
    "    hist_X1.axis('off')\n",
    "\n",
    "    # Histogram for axis X0 (feature 0)\n",
    "    hist_X0.set_xlim(ax.get_xlim())\n",
    "    hist_X0.hist(X[:, 0], bins=hist_nbins, orientation='vertical',\n",
    "                 color='grey', ec='grey')\n",
    "    hist_X0.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(item_idx):\n",
    "    title, X = distributions[item_idx]\n",
    "    ax_zoom_out, ax_zoom_in, ax_colorbar = create_axes(title)\n",
    "    axarr = (ax_zoom_out, ax_zoom_in)\n",
    "    plot_distribution(axarr[0], X, y, hist_nbins=200,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Full data\")\n",
    "\n",
    "    # zoom-in\n",
    "    zoom_in_percentile_range = (0, 99)\n",
    "    cutoffs_X0 = np.percentile(X[:, 0], zoom_in_percentile_range)\n",
    "    cutoffs_X1 = np.percentile(X[:, 1], zoom_in_percentile_range)\n",
    "\n",
    "    non_outliers_mask = (\n",
    "        np.all(X > [cutoffs_X0[0], cutoffs_X1[0]], axis=1) &\n",
    "        np.all(X < [cutoffs_X0[1], cutoffs_X1[1]], axis=1))\n",
    "    plot_distribution(axarr[1], X[non_outliers_mask], y[non_outliers_mask],\n",
    "                      hist_nbins=50,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Zoom-in\")\n",
    "\n",
    "    norm = mpl.colors.Normalize(y_full.min(), y_full.max())\n",
    "    mpl.colorbar.ColorbarBase(ax_colorbar, cmap=cmap,\n",
    "                              norm=norm, orientation='vertical',\n",
    "                              label='Color mapping for values of y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def select_sample_data(ref, sub, price_col, date):\n",
    "#     '''\n",
    "#     select a sample of data based on date, assumes datetimeindex\n",
    "    \n",
    "#     # args\n",
    "#         ref: pd.DataFrame containing all ticks\n",
    "#         sub: subordinated pd.DataFrame of prices\n",
    "#         price_col: str(), price column\n",
    "#         date: str(), date to select\n",
    "#     # returns\n",
    "#         xdf: ref pd.Series\n",
    "#         xtdf: subordinated pd.Series\n",
    "#     '''\n",
    "#     xdf = ref[price_col].loc[ref[str(date)]\n",
    "#     xtdf = sub[price_col].loc[date]\n",
    "#     return xdf, xtdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder= '/media/ak/My Passport/Experiment Data/ActivityClockData/'\n",
    "folderList = os.listdir(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/My Passport/Experiment Data/ActivityClockData/ClocksData_FB1_Comdty_20180416_.pkl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxFile = 1\n",
    "fileLoc = \"\".join((folder, folderList[idxFile]))\n",
    "fileLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string='FB1_Comdty-20180417.csv'\n",
    "\"_\".join((string.split('-')[0],string.split('-')[1].split('.')[0],'.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stylised_facts.stylised_facts_data_utilities import mdfda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "''' Locations'''\n",
    "cwd= os.getcwd()\n",
    "extHD = '/media/ak/My Passport/'\n",
    "extHdData = \"\".join((extHD, 'Data'))\n",
    "extHdExpData = \"\".join((extHD, 'Experiment Data')) #['features', 'labels', 'metrics', 'models']\n",
    "extHdFutures = \"\".join((extHD, 'Barket Data/raw bloomberg data')) #futures\n",
    "bmrg_folders=[s for s in os.listdir(extHdFutures) if ('Comdty') in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(extHdExpData)\n",
    "cleanLOBFolder = \"/\".join((extHdExpData,'CleanLOBData'))\n",
    "symbols =sorted(os.listdir(cleanLOBFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolIdx = 0\n",
    "symbolCleanSymbolFolder = \"/\".join((cleanLOBFolder, symbols[symbolIdx]))\n",
    "symbolCleanFilesList = os.listdir(symbolCleanSymbolFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest =pd.read_csv(\"/\".join((symbolCleanSymbolFolder,symbolCleanFilesList[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestCopy = dfTest.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGrouped = dfTestCopy.groupby('TradeTime')['BidSize', 'AskSize', 'TradeSize']\n",
    "dfGroupedSum = dfGrouped.sum()\n",
    "#this needs to be a function I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMergedtEST =dfTestCopy.merge(dfGroupedSum, on='TradeTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestCase = dfMergedtEST.drop(columns=['Unnamed: 0','type_x','type_y','AskQuoteId','BidQuoteId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(extHdFutures)\n",
    "bmrg_folders=[s for s in os.listdir(extHdFutures) if ('Comdty') in s]\n",
    "# bmrg_trades=sorted([s for s in os.listdir(dataOnlyDrive) if s.endswith('y_trades')])\n",
    "# bmrg_quotes=sorted([s for s in os.listdir(dataOnlyDrive) if s.endswith('y_quotes')])\n",
    "# bmrg_tickers=sorted([bmrg_trades[idx].split('_t')[0] for idx,_ in enumerate(bmrg_trades)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=createLOB.rawLOBFIle(futuresFolder=extHdFutures, symbolsFolder=bmrg_folders, symbolID=1,fileID=15)\n",
    "# test.shape\n",
    "# testLOB= dfTestCopy\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOB =createLOB.createLOB(test)\n",
    "LOB.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = createLOB.calcLOB(createLOB.formatLOB(LOB))\n",
    "dfraw.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activityClocks = createLOB.Clocks(dfraw, 'MicroPrice', 'TradeVolume','DollarVolume',1,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_bars(df, volume_column, m):\n",
    "    '''\n",
    "    compute volume bars\n",
    "\n",
    "    # args\n",
    "        df: pd.DataFrame()\n",
    "        volume_column: name for volume data\n",
    "        m: int(), threshold value for volume\n",
    "    # returns\n",
    "        idx: list of indices\n",
    "    '''\n",
    "    t = df[volume_column]\n",
    "    ts = 0\n",
    "    idx = []\n",
    "    for i, x in enumerate(tqdm(t)):\n",
    "        ts += x\n",
    "        if ts >= m:\n",
    "            idx.append(i)\n",
    "            ts = 0\n",
    "            continue\n",
    "    return idx\n",
    "\n",
    "def volume_bar_df(df, volume_column, m):\n",
    "    idx = volume_bars(df, volume_column, m)\n",
    "    return df.iloc[idx].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_M =1 \n",
    "print(f'volume threshold: {volume_M:,}')\n",
    "v_bar_df = volume_bar_df(dfraw, 'TradeVolume', volume_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVolDf= createLOB.calcLOB(activityClocks.volume_bar_df())\n",
    "dfTickDf= createLOB.calcLOB(activityClocks.tick_bar_df())\n",
    "dfDVDF = createLOB.calcLOB(activityClocks.dollar_bar_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={}\n",
    "dict['VolumeClockDf']=activityClocks.volume_bar_df()\n",
    "dict['TickClockDf']=activityClocks.tick_bar_df()\n",
    "dict['DollarVolumeClockDf']=activityClocks.tick_bar_df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCreatedLOB['DollarVolumeTraded'] = np.array(df.TradePrice)*np.array(df.TradeVolume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickDf.MicroPrice.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drvolume = createLOB.calcLOB(createLOB.formatLOB(clocks.volume_bar_df()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drvolume.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickdf = createLOB.calcLOB(createLOB.formatLOB(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tickdf.MicroPricePctChange.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbolID=1\n",
    "# futuresFolder= extHdFutures\n",
    "# symbolsFolder=bmrg_folders\n",
    "# listDatesFiles = os.listdir(\"/\".join((futuresFolder, symbolsFolder[symbolID])))\n",
    "# symbol=symbolsFolder[symbolID].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbolIDX, _ in enumerate(symbolsFolder):\n",
    "#     noFiles = len(os.listdir())\n",
    "#     print(symbolsFolder[symbolIDX], symbolIDX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# testLOB =(createLOB.createLOB(rawLOBFile = test))\n",
    "# cleanLOB =createLOB.formatLOB(testLOB)\n",
    "# cleanLOBDate = str(pd.to_datetime(cleanLOB.QuoteTime[0]).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stylised_facts.stylised_facts_data_utilities import createLOB as createLOB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mad = activityClocks.mad_outlier(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~mad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanLOBDateFileName = \"_\".join(('LOB',str(symbol),cleanLOBDate+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanLOBDateFileName\n",
    "# cleanLOBFileLoc = \"/\".join((cleanLOBFolder,symbol ,cleanLOBDateFileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanLOB.to_csv(cleanLOBFileLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanLOB.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanLOB['TimeStamp']=pd.to_datetime(cleanLOB.TradeTime).dt.time\n",
    "# cleanLOB['milliSeconds'] = [(((x.hour * 60 + x.minute) * 60 + x.second) * 1000) for x in cleanLOB['TimeStamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listDatesFiles = (\"/\".join((futuresFolder, symbolsFolder[symbolID])))\n",
    "# rawLOBFile = pd.read_csv(\"/\".join((futuresFolder, symbolsFolder[symbolID], listDatesFiles[symbolID])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB =testLOB.loc[~mad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfLOB['TradedDollarVolume'] =dfLOB.TradeSize*dfLOB.TradePrice\n",
    "# cleanLOB['TradedDollarVolume'] =cleanLOB.TradeSize*dfLOB.TradePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Bars ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ticks = testLOB.shape[0]\n",
    "volume_ratio = (testLOB.TradeSize.sum()/n_ticks).round()\n",
    "dollar_ratio = (testLOB.DollarVolumeTraded.sum()/n_ticks).round()\n",
    "print(f'num ticks: {n_ticks:,}')\n",
    "print(f'volume ratio: {volume_ratio}')\n",
    "print(f'dollar ratio: {dollar_ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFDFA import MFDFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_final= np.array(np.max(clocks.tick_bar_df().shape[0], clocks.volume_bar_df().shape[0], clocks.dollar_bar_df().shape[0]))\n",
    "delta_t=1 #tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The time array of the trajectory\n",
    "time = np.arange(0, t_final, delta_t)\n",
    "# y = np.asarray(clocks.tick_bar_df().MicroPricePctChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the stochastic trajectory over time\n",
    "plt.plot( y_tick, label = r'Trajectory of MicroPrice Pct Change')\n",
    "plt.plot(y_dv, color='r')\n",
    "\n",
    "plt.xlabel(r'time $t$')\n",
    "plt.ylabel(r'$y(t)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a band of lags, which usually ranges from \n",
    "# very small segments of data, to very long ones, as\n",
    "lag = np.logspace(0.7, 4, 60).astype(int)\n",
    "# Notice these must be ints, since these will segment\n",
    "# the data into chucks of lag size\n",
    "\n",
    "# Select the power q\n",
    "q = 9\n",
    "\n",
    "# The order of the polynomial fitting\n",
    "order = 2\n",
    "\n",
    "# Obtain the (MF)DFA as\n",
    "lag, dfa = MFDFA(y, lag = lag, q = q, order = order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag, dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To uncover the Hurst index, lets get some log-log plots\n",
    "plt.loglog(lag, dfa, 'o', label='fOU: MFDFA q=2')\n",
    "\n",
    "# And now we need to fit the line to find the slope. We will\n",
    "# fit the first points, since the results are more accurate \n",
    "# there. Don't forget that if you are seeing in log-log\n",
    "# scales, you need to fit the logs of the results\n",
    "np.polyfit(np.log(lag[:15]), np.log(dfa[:15]),1)[0]\n",
    "plt.show()\n",
    "# Now what you should obtain is: slope = H + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take three examples, with H=0.3, H=0.5, H=0.7\n",
    "# The total integration time, as before\n",
    "t_final = 500\n",
    "\n",
    "# The desired timestep of integration\n",
    "delta_t = 0.001\n",
    "\n",
    "# time array of the process\n",
    "time = np.linspace(0, t_final, t_final * int(1 / delta_t))\n",
    "\n",
    "# Generate three fractional Gaussian noises dB \n",
    "H_anti = 0.3       # Anti-presistent noise\n",
    "H_regu = 0.5       # Regular noise\n",
    "H_posi = 0.7       # Positively correlated noise\n",
    "\n",
    "# Generate the noises (with the appropriate normalisation)\n",
    "dB_anti = (t_final ** H_anti) * fgn(N = time.size, H = H_anti)\n",
    "dB_regu = (t_final ** H_regu) * fgn(N = time.size, H = H_regu)\n",
    "dB_posi = (t_final ** H_posi) * fgn(N = time.size, H = H_posi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's plot the noises, and the associated motions\n",
    "\n",
    "# fig, ax = plt.subplots(2,3, figsize=(12,4));\n",
    "\n",
    "# ax[0,0].plot(time, dB_anti)\n",
    "# ax[0,1].plot(time, dB_regu)\n",
    "# ax[0,2].plot(time, dB_posi)\n",
    "\n",
    "# # their motions are given by the integral of the noise,\n",
    "# # i.e., the cumsum of the processew \n",
    "\n",
    "# ax[1,0].plot(time, np.cumsum(dB_anti))\n",
    "# ax[1,1].plot(time, np.cumsum(dB_regu))\n",
    "# ax[1,2].plot(time, np.cumsum(dB_posi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def require(fname):\n",
    "    if not os.path.exists(fname):\n",
    "        from urllib import urlretrieve\n",
    "        print ('Downloading %s.')%fname\n",
    "        urlretrieve('http://bsp.brain.riken.jp/~juricap/mdfa/%s'%fname,fname)\n",
    "    if fname.endswith('.zip'):\n",
    "        import zipfile\n",
    "        try:\n",
    "            zipfile.ZipFile(fname).extractall()\n",
    "        except Exception as exc:\n",
    "            print( exc)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14,8)\n",
    "from scipy.io import loadmat\n",
    "from numpy import cumsum, polyfit, polyval, mean, sqrt\n",
    "import matplotlib.pyplot as plt \n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW1=np.cumsum(y-np.mean(y));\n",
    "A = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ma.array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A*y)\n",
    "plt.plot(RW1,'r',lw=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import cumsum\n",
    "def plot_trends(X,scale,m=1,label='',title=''):\n",
    "    t = np.arange(X.shape[0])\n",
    "    plt.plot(t,X,lw=2.0)\n",
    "    for i0 in range(0,X.shape[0]-scale+1,scale):\n",
    "        i1 = i0+scale\n",
    "        t0 = t[i0:i1]\n",
    "        C = polyfit(t0,X[i0:i1],m)\n",
    "        fit = polyval(C,t0);\n",
    "        RMS = np.sqrt(((X[i0:i1]-fit)**2).mean())\n",
    "        plt.plot(t0,fit,color='r',linestyle='--')\n",
    "        plt.plot(t0,fit-RMS,'r')\n",
    "        plt.plot(t0,fit+RMS,'r')\n",
    "    plt.ylabel(label,ha='center')\n",
    "#     if title: plt.text(100,500,title,fontsize=12) \n",
    "\n",
    "scale = 1000\n",
    "RW = cumsum(y-y.mean())\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.title('A Linear detrending')\n",
    "plot_trends(RW1,scale,1,label='Multifractal signal\\namplitude',\n",
    "            title='A Linear detrending')\n",
    "plt.legend(['Noise like time-series','Local trend','+/- 1 local RMS'], prop={'size': 6}, loc='upper right')\n",
    "plt.subplot(312)\n",
    "plt.title('B Quadratic detrending')\n",
    "plot_trends(RW1,scale,2,label='MicroPrice Change\\namplitude',\n",
    "            title='B Quadratic detrending')\n",
    "plt.subplot(313)\n",
    "plt.title('C Cubig detrending')\n",
    "plot_trends(RW1,scale,3,label='MicroPrice Change\\namplitude',\n",
    "            title='C Cubic detrending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trends(RW1,scale,1,label='Multifractal signal\\namplitude',\n",
    "            title='A Linear detrending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trends(X,scale,m=1):\n",
    "    t = np.arange(X.shape[0])\n",
    "    segments = np.arange(0,X.shape[0]-scale+1,scale)\n",
    "    RMS = []\n",
    "    for i0 in segments:\n",
    "        i1 = i0+scale\n",
    "        t0 = t[i0:i1]\n",
    "        C = polyfit(t0,X[i0:i1],m)\n",
    "        fit = polyval(C,t0)\n",
    "        RMS.append( sqrt(((X[i0:i1]-fit)**2).mean()) )\n",
    "    return np.array(RMS)\n",
    "\n",
    "RW = cumsum(y-y.mean())\n",
    "scales = 2**np.arange(4,11)\n",
    "#[16,32,64,128,256,512,1024];\n",
    "m = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stylised_facts.stylised_facts_data_utilities import mdfda as mdfda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =np.arange(9000)\n",
    "# mdfda.rw(X,4,3)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scstep = 8\n",
    "t0 = time.clock()\n",
    "scales = np.floor(2.0**np.arange(4,10.1,1.0/scstep)).astype('i4')\n",
    "RW = mdfda.rwalk(y.ravel())\n",
    "\n",
    "RMS = mdfda.compRMS(RW,scales,1)\n",
    "dtslow = time.clock() - t0\n",
    "print ('Took %0.3fs'%dtslow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qstep = 4\n",
    "# qs = np.arange(-5,5.01,1.0/qstep)\n",
    "# Fq = mdfda.compFq(RMS,qs)\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(scales[::scstep//2],Fq[::scstep//2,::qstep],'.-',lw=0.1)\n",
    "# plt.gca().set_xscale('log')\n",
    "# gca().set_yscale('log')\n",
    "# Hq = zeros(len(qs),'f8')\n",
    "# for qi,q in enumerate(qs):\n",
    "#     C = polyfit(log2(scales),log2(Fq[:,qi]),1)\n",
    "#     Hq[qi] = C[0]\n",
    "#     if abs(q - int(q)) > 0.1: continue\n",
    "#     loglog(scales,2**polyval(C,log2(scales)),lw=0.5,label='q=%d [H=%0.2f]'%(q,Hq[qi]))\n",
    "# margins(0,0)\n",
    "# legend(loc='lower right')\n",
    "# plt.xticks(scales[::scstep],scales[::scstep]);\n",
    "# plt.yticks([0.1,1.0,10.0],[0.1,1.0,10.0])\n",
    "# plt.xlabel('scale')\n",
    "# plt.ylabel('Fq')\n",
    "\n",
    "# plt.subplot(122)\n",
    "# tq = Hq*qs - 1\n",
    "# hq = diff(tq)/(qs[1]-qs[0])\n",
    "# Dq = (qs[:-1]*hq) - tq[:-1]\n",
    "# plot(hq,Dq,'.-')\n",
    "# xlabel('hq'); ylabel('Dq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Clock ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_bars(df, volume_column, m):\n",
    "    '''\n",
    "    compute volume bars\n",
    "\n",
    "    # args\n",
    "        df: pd.DataFrame()\n",
    "        volume_column: name for volume data\n",
    "        m: int(), threshold value for volume\n",
    "    # returns\n",
    "        idx: list of indices\n",
    "    '''\n",
    "    t = df[volume_column]\n",
    "    ts = 0\n",
    "    idx = []\n",
    "    for i, x in enumerate(tqdm(t)):\n",
    "        ts += x\n",
    "        if ts >= m:\n",
    "            idx.append(i)\n",
    "            ts = 0\n",
    "            continue\n",
    "    return idx\n",
    "\n",
    "def volume_bar_df(df, volume_column, m):\n",
    "    idx = volume_bars(df, volume_column, m)\n",
    "    return df.iloc[idx].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_M =5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'volume threshold: {volume_M:,}')\n",
    "v_bar_df = volume_bar_df(dfLOB, 'TradeSize', volume_M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bar_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clocks.volume_bar_df().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cprint\n",
    "from cprint import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB.MicroPrice.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLOB.TradedTime.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= dfLOB.MicroPricePctChange.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit =powerlaw.Fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit.alpha)\n",
    "print(fit.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= x\n",
    "fit = powerlaw.Fit(data, discrete=True, xmax=None)\n",
    "FigCCDFmax = fit.plot_ccdf(color='b', label=r\"Empirical, no $x_{max}$\")\n",
    "fit.power_law.plot_ccdf(color='b', linestyle='--', ax=FigCCDFmax, label=r\"Fit, no $x_{max}$\")\n",
    "fit = powerlaw.Fit(data, discrete=True, xmax=1000)\n",
    "fit.plot_ccdf(color='r', label=r\"Empirical, $x_{max}=1000$\")\n",
    "fit.power_law.plot_ccdf(color='r', linestyle='--', ax=FigCCDFmax, label=r\"Fit, $x_{max}=1000$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit = powerlaw.Fit(data, discrete=True)\n",
    "# ####\n",
    "# fit.distribution_compare('power_law', 'lognormal')\n",
    "# fig = fit.plot_ccdf(linewidth=3, label='Empirical Data')\n",
    "# fit.power_law.plot_ccdf(ax=fig, color='r', linestyle='--', label='Power law fit')\n",
    "# fit.lognormal.plot_ccdf(ax=fig, color='g', linestyle='--', label='Lognormal fit')\n",
    "# ####\n",
    "# fig.set_ylabel(u\"p(X≥x)\")\n",
    "# fig.set_xlabel(\"Frequency\")\n",
    "# handles, labels = fig.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absMPchange = np.abs(v_bar_df.MicroPricePctChange).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(np.abs(v_bar_df.MicroPricePctChange)/v_bar_df.Duration).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_bar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[~np.isfinite(x)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1000000*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=x.drop(x.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity =x[x<1]\n",
    "activity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the stochastic trajectory over time\n",
    "plt.plot(x, label = r'MicroPrice Pct Change/Duration')\n",
    "\n",
    "plt.xlabel(r'time $t$')\n",
    "plt.ylabel(r'$y(t)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activity.hist(bins=50, label='activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = np.sign(dfLOB.TradePrice -dfLOB.TradePrice.shift(1) )\n",
    "ticks_adj = ticks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_adj = ticks.replace(to_replace=0, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_adj.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate autocorrelation for n lags \n",
    "fig, ax1 = plt.subplots(figsize=(16,9))\n",
    "for i in np.arange( 1, 1000 ):\n",
    "    ax1.bar( i, ticks_adj.autocorr( lag = i ), color = 'blue' )\n",
    "ax1.set_title( 'Autocorrelation of tick test data by lag' )\n",
    "ax1.set_ylabel( 'Autocorrelation' )\n",
    "ax1.set_xlabel( 'Lag' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate our signal: collect trades - we'll use tick count\n",
    "\n",
    "# determine our window size\n",
    "tick_window = 20\n",
    "\n",
    "# Calc EMA directly (alpha = 2 / span +1)\n",
    "ema = ticks_adj.ewm( span=tick_window ).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import r_\n",
    "def trends(X,scale,m=1):\n",
    "    t = np.arange(X.shape[0])\n",
    "    segments = np.arange(0,X.shape[0]-scale+1,scale)\n",
    "    RMS = []\n",
    "    for i0 in segments:\n",
    "        i1 = i0+scale\n",
    "        t0 = t[i0:i1]\n",
    "        C = polyfit(t0,X[i0:i1],m)\n",
    "        fit = polyval(C,t0)\n",
    "        RMS.append( sqrt(((X[i0:i1]-fit)**2).mean()) )\n",
    "    return np.array(RMS)\n",
    "\n",
    "RW = cumsum(ema-ema.mean())\n",
    "scales = 2**np.arange(4,11)\n",
    "#[16,32,64,128,256,512,1024];\n",
    "m = 1\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "RMS = {}\n",
    "for si, scale in enumerate(scales):\n",
    "    plt.subplot(len(scales),1,len(scales)-si)\n",
    "    t = np.arange(0,RW.shape[0]+1,scale)\n",
    "    RMS[scale] = trends(RW,scale,m)\n",
    "    plt.step(t,r_[RMS[scale],RMS[scale][-1]],where='post')\n",
    "    plt.plot(xlim(),r_[1,1]*RMS[scale].mean(),'r',lw=2.0)\n",
    "    plt.text(8100,RMS[scale].mean(),'Scale = %d'%scale)\n",
    "    if scale < 128:\n",
    "        yticks([0,5,10,20])\n",
    "    else:\n",
    "        yticks([0,10,20,40])\n",
    "\n",
    "plt.xlabel('Sample index')\n",
    "plt.subplot(len(scales),1,len(scales)//2+1)\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to it in real time as in the simulation...\n",
    "sim_ema = pd.Series( index=ticks_adj.index )\n",
    "\n",
    "# define our accumulator for the average\n",
    "accum = 0\n",
    "alpha = 2 / ( tick_window + 1 )\n",
    "# loop\n",
    "for index, value in ticks_adj.items():\n",
    "    if pd.isna( value ):\n",
    "        continue\n",
    "    if accum == 0:\n",
    "        accum = value\n",
    "    else:\n",
    "        accum = ( alpha * value ) + ( 1 - alpha ) * accum\n",
    "    sim_ema.loc[ index ] = accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ema.plot(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.concat([sim_ema, ema], axis=1)\n",
    "values.columns = ['sim_ema', 'ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(values.sim_ema - values.ema).head(200).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW1=np.cumsum(ema-np.mean(ema));\n",
    "A = 10.0\n",
    "t_final= len(ema)\n",
    "delta_t=1 #tick\n",
    "# The time array of the trajectory\n",
    "time = np.arange(0, t_final, delta_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=ema\n",
    "scale = 1000\n",
    "RW = cumsum(y-y.mean())\n",
    "plt.figure(figsize=(9, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(311)\n",
    "plt.title('A Linear detrending')\n",
    "plot_trends(RW1,scale,1,label='Multifractal signal\\namplitude',\n",
    "            title='A Linear detrending')\n",
    "plt.legend(['Noise like time-series','Local trend','+/- 1 local RMS'], prop={'size': 6}, loc='upper right')\n",
    "plt.subplot(312)\n",
    "plt.title('B Quadratic detrending')\n",
    "plot_trends(RW1,scale,2,label='MicroPrice Change\\namplitude',\n",
    "            title='B Quadratic detrending')\n",
    "plt.subplot(313)\n",
    "plt.title('C Cubic detrending')\n",
    "plot_trends(RW1,scale,3,label='MicroPrice Change\\namplitude',\n",
    "            title='C Cubic detrending')\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
