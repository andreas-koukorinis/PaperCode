{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aknotebooks.classification.convenience_functions.mkl_base as mkl_base\n",
    "from aknotebooks.classification.convenience_functions.mkl_base import hardDrivesLoc, dataOnlyDrive, folderList, symbols, \\\n",
    "    dataList, symbolFeaturesLocation, selection,checkDir\n",
    "from aknotebooks.classification.convenience_functions.fit_mkl import featureCreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MKLpy\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.preprocessing import kernel_normalization\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics.pairwise import rbf_kernel as RBF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLT.L',\n",
       " 'CNA.L',\n",
       " 'PRU.L',\n",
       " 'BATS.L',\n",
       " 'CEY.L',\n",
       " 'APF.L',\n",
       " 'AZN.L',\n",
       " 'CCL.L',\n",
       " 'CPG.L',\n",
       " 'BARC.L',\n",
       " 'AV.L',\n",
       " 'AAL.L']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbolIdx = 2  # pick one of the symbols\n",
    "\n",
    "# do a join to get the location\n",
    "# symbolLocation = \"/\".join((finalLocation, symbols[symbolIdx]))\n",
    "# # get the features now\n",
    "\n",
    "selectionLoc = os.path.join(hardDrivesLoc, selection)\n",
    "\n",
    "# ''' location of WorkDrive'''\n",
    "# dataList = [s for s in os.listdir(selectionLoc) if s.startswith('Dat')]\n",
    "# path = 'MKL_Experiments'\n",
    "MKLExpPath = os.path.join(os.path.join(hardDrivesLoc, selection, dataList[1]), 'MKL_Experiments')\n",
    "MKLSymbolPath = os.path.join(MKLExpPath, symbols[symbolIdx])\n",
    "MKLSymbolKernelsPath = \"/\".join((MKLSymbolPath, 'Kernels'))\n",
    "\n",
    "SymbolCommonPaths = mkl_base.open_pickle_file(MKLSymbolPath, 'LocDictsListCorrect.pkl')\n",
    "uniqueTrainingKeys = np.unique([i[1] for i in SymbolCommonPaths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    " kernelDates = [file.split(\"_\")[0] for file in os.listdir('/media/ak/WorkDrive/Data/MKL_Experiments/PRU.L/Kernels/')\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20170131'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernelDates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('20170120', '20170131'), ('20170117', '20170131')]\n"
     ]
    }
   ],
   "source": [
    "keys=list(SymbolCommonPaths.keys())\n",
    "type(keys)\n",
    "# for idx, key in enumerate(keys):\n",
    "#     print(idx)\n",
    "#     print(key)\n",
    "#     kernelFileName = \"/\".join((MKLSymbolKernelsPath, \"\".join((key[0], \"_Kernels.pkl\"))))\n",
    "#     checkDir(kernelFileName)\n",
    "#     print(kernelFileName)\n",
    "#     print(SymbolCommonPaths[key])\n",
    "i=kernelDates[0]\n",
    "result=[]\n",
    "for j in keys:\n",
    "    if i in j:\n",
    "        result.append(j)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20170117/PRU.L_3_states_features_date:_20180406_now:_20181229_.pickle', '/media/ak/DataOnly/FinDataReal/Labels/PRU.L/NON_DIRECTIONAL/20180406.csv']\n",
      "The directory exists\n"
     ]
    }
   ],
   "source": [
    "print(SymbolCommonPaths[keys[920]])\n",
    "kernelFileName = \"/\".join((MKLSymbolKernelsPath, \"\".join((i, \"_Kernels.pkl\"))))\n",
    "checkDir(kernelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ak/DataOnly/FinDataReal/PRU.L/MODEL_BASED/20170117/PRU.L_3_states_features_date:_20170131_now:_20181229_.pickle',\n",
       " '/media/ak/DataOnly/FinDataReal/Labels/PRU.L/NON_DIRECTIONAL/20170131.csv']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SymbolCommonPaths[result[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1ae13ab570fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeaturesTupleFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSymbolCommonPaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabelsIdxDirFileLoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSymbolCommonPaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabelsDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsIdxDirFileLoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/resrPyth3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/resrPyth3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 413\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/resrPyth3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "featuresTupleFile=pkl.load(open(SymbolCommonPaths[result[1]][0], \"rb\"),encoding='latin1')\n",
    "labelsIdxDirFileLoc = pd.read_csv(SymbolCommonPaths[result[1]][1])\n",
    "labelsDf = pd.read_csv(labelsIdxDirFileLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labelsDf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-9839219d6a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m''' pop the labels out'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelsDf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_PrMov__window_5__thres_arbitrary__0.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m'''dataframe of Features and Labels - X and Y'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfXY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'False'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfXY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfXY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labelsDf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "''' pop the labels out'''\n",
    "labels = labelsDf['label_PrMov__window_5__thres_arbitrary__0.1']\n",
    "'''dataframe of Features and Labels - X and Y'''\n",
    "dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "''' drop the labels from the features'''\n",
    "dfX = dfXY.drop(columns=[labelName])\n",
    "arrX = np.array(dfX)\n",
    "''' feature normalisation'''\n",
    "# feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "X = normalization(rescale_01(arrX))\n",
    "y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "''' returns features, labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1], \\\n",
    "                            featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "testKernes =pkl.load(open(kernelFileName, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2661, 2661)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(testKernes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainingKey =1 \n",
    "    keyDate = list(SymbolCommonPaths)[trainingKey]\n",
    "    \n",
    "    \n",
    "\n",
    "    for trainingKey, keyDate in enumerate(list(SymbolCommonPaths)):\n",
    "\n",
    "        print(trainingKey, keyDate[1])\n",
    "        Xtr, ytr = featureCreation(idxKey=trainingKey,\n",
    "                                   locDict=SymbolCommonPaths)  # need to refactor this to read from the mkl_base\n",
    "        if Xtr.shape[0] == ytr.shape[0]:\n",
    "            print(list(SymbolCommonPaths.keys())[trainingKey][0])\n",
    "            kernelFileName = \"/\".join((MKLSymbolKernelsPath, \"\".join((keyDate[0], \"_Kernels.pkl\"))))\n",
    "            loadPickleKernels = pkl.load(open(kernelFileName, \"rb\"))\n",
    "            print('doing the kernels bit')\n",
    "            KLsimple = loadPickleKernels[0]\n",
    "            KLrbf = loadPickleKernels[1]\n",
    "            clf = AverageMKL().fit(KLsimple, ytr)  # a wrapper for averaging kernels\n",
    "            clfEasy = EasyMKL(lam=0.1).fit(KLsimple, ytr)#combining kernels with the EasyMKL algorithm\n",
    "            clfRBF = EasyMKL(lam=0.1).fit(KLrbf, ytr)\n",
    "            print('------')\n",
    "            print('finished MKL Fitting- Now will test Predictions')\n",
    "            print('Average Kernel Testing')\n",
    "            y_pred = clf.predict(KLsimple)  # predictions\n",
    "            y_score = clf.decision_function(KLsimple)  # rank\n",
    "            accuracy = accuracy_score(ytr, y_pred)\n",
    "            fprAverage, tprAverage, thresholdsAverage = roc_curve(ytr.ravel(), y_score.ravel())\n",
    "            roc_auc = auc(fprAverage, tprAverage)\n",
    "            print('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "        else:\n",
    "            print('Shapes dont match.')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingKey =1 \n",
    "keyDate = list(SymbolCommonPaths)[trainingKey]\n",
    "print(trainingKey, keyDate[1])\n",
    "Xtr, ytr = featureCreation(idxKey=trainingKey,\n",
    "                                   locDict=SymbolCommonPaths)  # need to refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape[0] == ytr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(SymbolCommonPaths.keys())[trainingKey][0])\n",
    "kernelFileName = \"/\".join((MKLSymbolKernelsPath, \"\".join((keyDate[1], \"_Kernels.pkl\"))))\n",
    "loadPickleKernels = pkl.load(open(kernelFileName, \"rb\"))\n",
    "print('doing the kernels bit')\n",
    "KLsimple = loadPickleKernels[0]\n",
    "KLrbf = loadPickleKernels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AverageMKL().fit(KLsimple, ytr)  # a wrapper for averaging kernels\n",
    "clfEasy = EasyMKL(lam=0.1).fit(KLsimple, ytr)#combining kernels with the EasyMKL algorithm\n",
    "            \n",
    "clfRBF = EasyMKL(lam=0.1).fit(KLrbf, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
