{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/DataAnalysis/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ak/Envs/DataAnalysis/local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hsmm_core.consts import *\n",
    "n_hidden_states = 2\n",
    "# Set what the model should understand as zero price change, here wee use 1bp\n",
    "zero_pc_threshold = 1e-4\n",
    "\n",
    "use_random_tpm_pi = True\n",
    "\n",
    "init_params = {\n",
    "    \"obs_model_params\": {\n",
    "                                'epsilon': zero_pc_threshold,\n",
    "                                'obs_model_name': 'ExpUniGauss',\n",
    "                                'init_params': {'epsilon': zero_pc_threshold},\n",
    "                                'em_initialization_method': 'cluster'\n",
    "\n",
    "    },\n",
    "    \"hidden_model_params\": {\n",
    "                                'no_hidden_states': n_hidden_states,\n",
    "                                # 'pi':startprob,\n",
    "                                # 'tpm': transmat\n",
    "                                'em_initialization_method': initialization_method.uniform\n",
    "    },\n",
    "    \"update_tag\": 'tpsml'\n",
    "}\n",
    "\n",
    "\n",
    "prediction_params = {\n",
    "    'labelling_method':  dl_choices.control_chart,\n",
    "    'feature_generation': feature_generation.one_model_to_one_fset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dic, data_sampling_tag = load_data_from_directory(ticker, resample=None,\n",
    "                                                       file_name=['20140421.csv', '20140424.csv', '20140428.csv'], \n",
    "                                                       columns=['Duration', 'ReturnTradedPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hs_prediction_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-85fc7173fc26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m prediction_eng = hs_prediction_engine(hmm_init_params=init_params, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                       \u001b[0mprediction_innit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                       no_parallel_procs=None)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_eng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_sampling_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hs_prediction_engine' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_eng = hs_prediction_engine(hmm_init_params=init_params, \n",
    "                                      prediction_innit_params=prediction_params,\n",
    "                                      no_parallel_procs=None)\n",
    "                                      \n",
    "features = prediction_eng.train_model_data(ticker, data_dic, data_sampling_tag, hidden_states=n_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f8ae83a7551c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-da2fdd0c1573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'20140424'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features['20140424']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fischer_score,inf_matrix, gamma, ksi =features['20140421']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit=data_dic['20140421'].dropna()\n",
    "data_test = data_dic['20140428'].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/DataAnalysis/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/ak/Envs/DataAnalysis/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data_fit['Diff_15']= data_fit['MidPrice'].diff(-15)\n",
    "data_test['Diff_15']=data_test['MidPrice'].diff(-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'TradedTime', 'Duration', 'LogDuration', 'Volume',\n",
       "       'LogVolume', 'ReturnTradedPrice', 'MidPrice',\n",
       "       'VolumeAdjustedMidPrice', 'ReturnMidPrice',\n",
       "       'ReturnVolumeAdjustedMidPrice', 'BidAskSpread', 'SizeImbalance',\n",
       "       'NoOfTrades', 'rtp_rollingmean', 'quantiles_labelling', 'Diff_15',\n",
       "       'Price_Labels_15'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def price_labels(df):\n",
    "    if df['Diff_15'] >0:\n",
    "        return 1\n",
    "    if df['Diff_15']<=0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/DataAnalysis/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "price_labels_15=data_fit.apply(price_labels, axis=1)\n",
    "data_fit['Price_Labels_15']=price_labels_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/DataAnalysis/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "price_labels_15_test=data_test.apply(price_labels, axis=1)\n",
    "data_test['Price_Labels_15']=price_labels_15_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print np.mean(data_fit['Diff_15'])\n",
    "print np.mean(data_test['Price_Labels_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_labels_15_test.value_counts()\n",
    "#data_test =data_dic['20140424'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23744, 18)\n",
      "(51309, 18)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(data_fit)\n",
    "print np.shape(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels =data_fit['Price_Labels_15']\n",
    "test_labels =data_test['Price_Labels_15']\n",
    "price_labels_clf =pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23744\n",
      "51309\n"
     ]
    }
   ],
   "source": [
    "print len(train_labels)\n",
    "print len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(price_labels_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_features_fit =data_fit[['Duration','ReturnMidPrice']]\n",
    "normal_features_fit_1 =data_fit[['Duration','ReturnMidPrice']].loc[data_fit['Price_Labels_15']==1]\n",
    "normal_features_fit_0 =data_fit[['Duration','ReturnMidPrice']].loc[data_fit['Price_Labels_15']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.scatter(normal_features_fit_0['Duration'], normal_features_fit_0['ReturnMidPrice'])\n",
    "plt.show()\n",
    "plt.scatter(normal_features_fit_1['Duration'], normal_features_fit_1['ReturnMidPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_all=pd.concat([fischer_score, gamma, ksi],axis=1).dropna()\n",
    "df_features=pd.concat([fischer_score, gamma, ksi],axis=1)\n",
    "df_ksi =pd.DataFrame(ksi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df_fit= data_fit['MidPrice']\n",
    "price_df_test= data_test['MidPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to np array\n",
    "price_time_series = np.array(price_df_fit)\n",
    "mean_array_string = '6,10,26,27,37,41,47,49,53,57,58,64,67'\n",
    "means_list = [int(mean) for mean in mean_array_string.split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EWMA Calculation \n",
    "mean_to_ewma_dict = OrderedDict()\n",
    "for mean in means_list:\n",
    "    mean_to_ewma_dict[mean] = np.round(pd.ewma(price_time_series, span=mean), 3)\n",
    "    \n",
    "mean_to_ewma_df = pd.DataFrame(mean_to_ewma_dict)\n",
    "mean_to_ewma_df = mean_to_ewma_df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spread / Acceleration Calculation\n",
    "length = len(mean_to_ewma_dict)\n",
    "spread_dict = OrderedDict()\n",
    "for i in xrange(0, length):\n",
    "    for j in xrange(i + 1, length):\n",
    "        spread = mean_to_ewma_dict[means_list[i]] - mean_to_ewma_dict[means_list[j]]\n",
    "        spread_key = ''.join([mean_array_string[i], '_', mean_array_string[j]])\n",
    "        spread_dict[spread_key] = spread\n",
    "        spread_ma = np.round(pd.rolling_mean(spread, window=10), 3)\n",
    "        spread_ma = np.nan_to_num(spread_ma)\n",
    "        spread_key = ''.join([mean_array_string[i], '_', mean_array_string[j], '_MA'])\n",
    "        spread_dict[spread_key] = spread_ma\n",
    "        \n",
    "mean_combinations_to_ewma_df = pd.DataFrame(spread_dict)\n",
    "mean_combinations_to_ewma_df = mean_combinations_to_ewma_df.fillna(value=0)\n",
    "ewma_input_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "y= train_labels\n",
    "y_minus = (y==-1).astype(int)\n",
    "y_zeros = (y==0).astype(int)\n",
    "y_plus = (y==1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print \"X feature Length\", len(X)\n",
    "print \"y Label Length\", len(y)\n",
    "print \"y-minus Label Length\", len(y_minus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test=X.reset_index(drop=True).loc[y==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_minus = (y==-1).astype(int)\n",
    "y_zeros = (y==0).astype(int)\n",
    "y_plus = (y==1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price_labels_15 = data_fit['Price_Labels_15']\n",
    "#y_price_labels_2 =data_fit['Price_Labels_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_price_labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff= len(df_features_all) -len(y_price_labels_15)\n",
    "X= df_features_all.iloc[diff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y_price_labels_15, test_size=0.25, random_state=0) #change the lable here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(X_train)\n",
    "print len(X_test)\n",
    "print len(y_train)\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_features_am= df_features_all.as_matrix()\n",
    "sc= StandardScaler()\n",
    "#df_features_std= sc.fit_transform(df_features_am)\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('\\nEigenvalues \\n%s' % eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=8)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pca.fit(X_train_std)\n",
    "print(pca.explained_variance_ratio_)\n",
    "var_exp= pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a scree plot\n",
    "pve = pca.explained_variance_ratio_\n",
    "pve.shape\n",
    "plt.plot(range(len(pve)), pve)\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.ylabel(\"Proportion of Variance Explained\")\n",
    "plt.xlabel(\"Principal Component Number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "               for i in range(len(eigen_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eigen_pairs.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "               eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_pca[:, 1], X_train_pca[:, 3])\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train_std, y_train)\n",
    "lr_pca= lr.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std_compact=X_test_std[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test_std_compact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "y_pred_2= lr.predict(X_test_std_compact)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Misclassified samples: %d' % (y_test != y_pred_2).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf= SVC(kernel='rbf',C=10, gamma=0.1) \n",
    "svc_rbf.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_svc= svc_rbf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =y_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(svc_rbf.predict(X_test_std), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
