{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mkl_data_processing as mkldp\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import sys\n",
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "import jsonpickle\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy import generators\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from MKLpy.model_selection import cross_val_score\n",
    "from MKLpy.multiclass import OneVsRestMKLClassifier, OneVsOneMKLClassifier\n",
    "\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, \\\n",
    "    KOMD  # KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "\n",
    "from fileutils import new_feature_utils as nfu\n",
    "from fileutils.new_feature_utils import CreateMarketFeatures\n",
    "import multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileutils import DataLoader as DataLoader\n",
    "from fileutils import paths\n",
    "from fileutils import new_feature_utils as nfu\n",
    "from fileutils.new_feature_utils import CreateMarketFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_filepath(pickle_file):\n",
    "    pickle_to_file = pickle.load(open(pickle_file, \"rb\"), encoding='latin1')\n",
    "\n",
    "    return pickle_to_file\n",
    "\n",
    "\n",
    "def forward_Dates(list_of_keys, current_date):\n",
    "    \"\"\"\n",
    "    return all the forward looking dates for each idxKey we use for training\n",
    "\n",
    "    :param list_of_keys: dates i have model dates for out of sample\n",
    "    :param current_date: current model date\n",
    "    :return: forward dates for applying the fitted model\n",
    "    \"\"\"\n",
    "    lookAheadKeys = sorted(i for i in list_of_keys if i > current_date)\n",
    "    return lookAheadKeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = mkldp.paths('main')\n",
    "\n",
    "symbols = sorted(os.listdir(mkldp.paths('symbols_features')))\n",
    "jointFeatureLocation = os.path.join(mainPath, \"ExperimentCommonLocs/JointLocationsDicts\")\n",
    "commonLocs  = os.path.join(mainPath, \"ExperimentCommonLocs/\")\n",
    "\n",
    "mklOOSPredictionPath = os.path.join(mainPath, \"ExperimentCommonLocs/MKLOOSPredictions\")\n",
    "allFiles = os.listdir(jointFeatureLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LabelsAlternateThree': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateThree',\n",
       " 'LabelsAlternateFour': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateFour',\n",
       " 'LabelsAlternateSeven': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven',\n",
       " 'LabelsAlternateOne': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateOne',\n",
       " 'LabelsAlternateSix': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSix',\n",
       " 'LabelsAlternateTwo': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateTwo',\n",
       " 'LabelsAlternateFive': '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateFive'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAlternateLocs = {f:os.path.join(commonLocs, f) for f in os.listdir(os.path.join(mainPath, \"ExperimentCommonLocs/\")) if str(\"LabelsAlternate\") in f }\n",
    "labelsAlternateLocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alternate_labels_nos = {1:\"LabelsAlternateOne\", 2:\"LabelsAlternateTwo\", 3:\"LabelsAlternateThree\", \n",
    "                        4:\"LabelsAlternateFour\", 5:\"LabelsAlternateFive\", 6:\"LabelsAlternateSix\", \n",
    "                        7:\"LabelsAlternateSeven\"}  # we have 7 alternative data types\n",
    "\n",
    "fittedModelsPath = os.path.join(mainPath, \"ExperimentCommonLocs/FittedModels\")\n",
    "oosPredictionsPath = os.path.join(mainPath, \"ExperimentCommonLocs/OOSPredictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 1  # to be serialised\n",
    "\n",
    "labelsLocation = labelsAlternateLocs[alternate_labels_nos[label_idx]]\n",
    "\n",
    "labelsFiles = sorted(os.listdir(labelsLocation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APF.L\n"
     ]
    }
   ],
   "source": [
    "symbol_idx = 1  # pick a symbol\n",
    "symbol = sorted(symbols)[symbol_idx]  # to be serialised so read all the symbols\n",
    "print(symbol)\n",
    "\n",
    "symbolData = DataLoader(mainPath, symbol)  # initiate a path where all the data should be\n",
    "pickled_models = [f for f in os.listdir(fittedModelsPath) if str(symbol) in f]  # list of all the pickled models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateOne\n"
     ]
    }
   ],
   "source": [
    "print(labelsLocation)\n",
    "files = os.listdir(jointFeatureLocation)\n",
    "fileIdx =2\n",
    "pickle_path = os.path.join( jointFeatureLocation, [f for f in os.listdir(jointFeatureLocation) if str(symbol) in f][fileIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ak/DataOnly/ExperimentCommonLocs/JointLocationsDicts/APF.L_hmm_date:_20170731_feature_date_20170929_label_id:_2_ProcessedData.pkl\n"
     ]
    }
   ],
   "source": [
    "print(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ak/DataOnly/ExperimentCommonLocs/JointLocationsDicts/APF.L_hmm_date:_20170731_feature_date_20170929_label_id:_2_ProcessedData.pkl\n"
     ]
    }
   ],
   "source": [
    "print(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "Datekeys =list(open_pickle_filepath(pickle_path).keys())\n",
    "print(len(Datekeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol:-----> RR.L\n"
     ]
    }
   ],
   "source": [
    "file = files[4]\n",
    "select_file_path = os.path.join(jointFeatureLocation, file)  # formulate the path\n",
    "print('Symbol:----->', file.split(\"_\")[0])\n",
    "symbol = file.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_hmm_date = select_file_path.split(\"_\")[3]  # pull out the hmm_date - strip it out\n",
    "\n",
    "select_feature_label_date = select_file_path.split(\"_\")[6]  # pull out the label_feature_date\n",
    "\n",
    "select_label_idx = select_file_path.split(\"_\")[9]  # pull out the label _idx\n",
    "\n",
    "unpickled_select_file = open_pickle_filepath(select_file_path)  # unplickle the select file\n",
    "\n",
    "hmm_keys = sorted(list(unpickled_select_file.keys()))  # hmm keys for the select file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hmm_date_key in hmm_keys:  # pick and hmm date\n",
    "    feature_label_keys = sorted(\n",
    "        unpickled_select_file[hmm_date_key].keys())  # each key here unlocks a feature and label set\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### 20170703 ########################\n",
      "['20170704', '20170705', '20170706', '20170707', '20170710', '20170711', '20170712', '20170713', '20170714', '20170717', '20170718', '20170719', '20170720', '20170721', '20170724', '20170725', '20170726', '20170727', '20170728', '20170731', '20170801', '20170802', '20170803', '20170804', '20170807', '20170808', '20170809', '20170810', '20170811', '20170814', '20170815', '20170816', '20170817', '20170818', '20170821', '20170822', '20170823', '20170824', '20170825', '20170829', '20170830', '20170831', '20170901', '20170904', '20170905', '20170906', '20170907', '20170908', '20170911', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170926', '20170927', '20170928', '20170929', '20180301', '20180302', '20180305', '20180306', '20180307', '20180308', '20180309', '20180312', '20180313', '20180314', '20180315', '20180316', '20180319', '20180320', '20180321', '20180322', '20180323', '20180326', '20180327', '20180328', '20180329', '20180403', '20180404', '20180405', '20180406', '20180409', '20180410', '20180411', '20180412', '20180413', '20180416', '20180417', '20180418', '20180419', '20180420']\n",
      "#######################################\n",
      "ok-----> 20170704\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven/RR.L/20170704.csv does not exist: '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven/RR.L/20170704.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-a13e98075827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if label file exists I can traing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ok----->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_label_date\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# if you got to this point we have data so we can mov eon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_file_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# open labels file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_pickle_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_file_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# opens features file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/anaconda3/envs/mmd-kernels/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/anaconda3/envs/mmd-kernels/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/anaconda3/envs/mmd-kernels/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/anaconda3/envs/mmd-kernels/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ak/anaconda3/envs/mmd-kernels/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven/RR.L/20170704.csv does not exist: '/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven/RR.L/20170704.csv'"
     ]
    }
   ],
   "source": [
    "for hmm_date_key in hmm_keys:  # pick and hmm date\n",
    "    print('###################', hmm_date_key, '########################')\n",
    "    feature_label_keys = sorted(\n",
    "        unpickled_select_file[hmm_date_key].keys())  # each key here unlocks a feature and label set    \n",
    "    print(feature_label_keys)\n",
    "    print('#######################################')\n",
    "\n",
    "    for feature_label_date in feature_label_keys:  # make a list of all the feature dates\n",
    "        features_file_path = unpickled_select_file[hmm_date_key][feature_label_date][\n",
    "            0]  # this is the feature path\n",
    "        labels_file_path = unpickled_select_file[hmm_date_key][feature_label_date][1]  # this is the labels path\n",
    "\n",
    "        if os.path.isfile(features_file_path):  # if label file exists I can traing\n",
    "            print('ok----->', feature_label_date)  # if you got to this point we have data so we can mov eon\n",
    "            labels = pd.read_csv(labels_file_path)  # open labels file\n",
    "            label_name = str(labels.columns[labels.columns.str.contains(pat='label')].values[0])\n",
    "            features = open_pickle_filepath(features_file_path)  # opens features file\n",
    "            hmm_features = nfu.hmm_features_df(features)  # get the hmm features out, so unpack the tuples!\n",
    "            print('loaded features and labels ')\n",
    "        else:\n",
    "            print('PROBLEM----->in one of of your locations')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/ak/DataOnly/ExperimentCommonLocs/LabelsAlternateSeven/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
