{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from memory_profiler import profile\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/MultiKernelLearning')\n",
    "import jsonpickle\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy import generators\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL\n",
    "from sklearn.svm import SVC\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import new_alternate_single_svm as nalsvm\n",
    "from mkl_data_processing import storage_location, cross_validation_results_location, evaluate_predictions, oos_results_location, return_cross_val_symbol_path, model_dates_list\n",
    "from MKLpy.multiclass import OneVsRestMKLClassifier, OneVsOneMKLClassifier\n",
    "from mkl_model_cross_validation import load_pickled_in_filename\n",
    "# evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# MKL algorithms\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, \\\n",
    "    KOMD  # KOMD is not a MKL algorithm but a simple kernel machine like the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelsAlternateFour\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# pick the symbols you want to try out of sample\n",
    "# pick the model dates- this is important as you need to calculate the out of sample \"forward\" dates\n",
    "# pick label\n",
    "alternate_label = 'LabelsAlternateFour'\n",
    "# index of label - this can be redundant\n",
    "alternate_label_idx = list(nalsvm.labels_pickle_files).index(alternate_label)\n",
    "print(alternate_label)\n",
    "# clean data location\n",
    "# oos_results_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL.L',\n",
       " 'BATS.L',\n",
       " 'CCL.L',\n",
       " 'CPG.L',\n",
       " 'CV_Results',\n",
       " 'DMGOa.L',\n",
       " 'ECM.L',\n",
       " 'GKN.L',\n",
       " 'OOS_Results',\n",
       " 'PRU.L',\n",
       " 'PSON.L',\n",
       " 'RB.L',\n",
       " 'RDSa.L',\n",
       " 'RDSb.L',\n",
       " 'RSA.L',\n",
       " 'RTO.L',\n",
       " 'SDR.L',\n",
       " 'SHP.L',\n",
       " 'SMIN.L',\n",
       " 'STAN.L']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/ak/My Passport/Data/FinDataReal/JointLocationsAlternateDataClean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL.L',\n",
       " 'BATS.L',\n",
       " 'ECM.L',\n",
       " 'GKN.L',\n",
       " 'PSON.L',\n",
       " 'RDSa.L',\n",
       " 'RDSb.L',\n",
       " 'RSA.L',\n",
       " 'RTO.L',\n",
       " 'SHP.L',\n",
       " 'STAN.L']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/ak/My Passport/Data/FinDataReal/JointLocationsAlternateDataClean/CV_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSA.L\n",
      "/media/ak/My Passport/Data/FinDataReal/JointLocationsAlternateDataClean/CV_Results/RSA.L\n",
      "0\n",
      "---------------> Doing Model Date: 20170706\n",
      "first bit done\n",
      "done with kernel\n",
      "['20170707', '20170712', '20170717', '20170718', '20170719', '20170720', '20170721', '20170724', '20170727', '20170801', '20170802', '20170803', '20170804', '20170808', '20170809', '20170814', '20170816', '20170817', '20170818', '20170822', '20170823', '20170824', '20170830', '20170901', '20170904', '20170905', '20170908', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170929', '20180301', '20180302', '20180404', '20180412', '20180420']\n",
      "done\n",
      "the combination weights are:\n",
      "(-1 vs all):  tensor([0.0072, 0.0739, 0.9189])\n",
      "43\n",
      "20170707\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.865\n",
      "Acc: 86.54%\n",
      "Precision: 0.75\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.80\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.086\n",
      "Acc: 8.64%\n",
      "Precision: 0.71\n",
      "Recall: 0.09\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.09\n",
      "Hamming Loss Value: 0.91\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n",
      "Accuracy score: 0.435\n",
      "Acc: 43.48%\n",
      "Precision: 0.67\n",
      "Recall: 0.43\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.43\n",
      "Hamming Loss Value: 0.57\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.292\n",
      "Acc: 29.18%\n",
      "Precision: 0.72\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.204\n",
      "Acc: 20.37%\n",
      "Precision: 0.76\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.615\n",
      "Acc: 61.55%\n",
      "Precision: 0.78\n",
      "Recall: 0.62\n",
      "F1 score weighted: 0.69\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.62\n",
      "Hamming Loss Value: 0.38\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.318\n",
      "Acc: 31.82%\n",
      "Precision: 0.79\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.601\n",
      "Acc: 60.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.523\n",
      "Acc: 52.35%\n",
      "Precision: 0.51\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.242\n",
      "Acc: 24.15%\n",
      "Precision: 0.68\n",
      "Recall: 0.24\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.24\n",
      "Hamming Loss Value: 0.76\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.448\n",
      "Acc: 44.78%\n",
      "Precision: 0.80\n",
      "Recall: 0.45\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.45\n",
      "Hamming Loss Value: 0.55\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.567\n",
      "Acc: 56.68%\n",
      "Precision: 0.79\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.471\n",
      "Acc: 47.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.178\n",
      "Acc: 17.76%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.26\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.544\n",
      "Acc: 54.39%\n",
      "Precision: 0.79\n",
      "Recall: 0.54\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.54\n",
      "Hamming Loss Value: 0.46\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.48%\n",
      "Precision: 0.72\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.474\n",
      "Acc: 47.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.317\n",
      "Acc: 31.73%\n",
      "Precision: 0.73\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.390\n",
      "Acc: 39.03%\n",
      "Precision: 0.80\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.201\n",
      "Acc: 20.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.22\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.297\n",
      "Acc: 29.74%\n",
      "Precision: 0.74\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.120\n",
      "Acc: 12.05%\n",
      "Precision: 0.47\n",
      "Recall: 0.12\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.12\n",
      "Hamming Loss Value: 0.88\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n",
      "Accuracy score: 0.348\n",
      "Acc: 34.76%\n",
      "Precision: 0.66\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.212\n",
      "Acc: 21.16%\n",
      "Precision: 0.83\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.375\n",
      "Acc: 37.54%\n",
      "Precision: 0.42\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.253\n",
      "Acc: 25.30%\n",
      "Precision: 0.50\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.509\n",
      "Acc: 50.86%\n",
      "Precision: 0.42\n",
      "Recall: 0.51\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.51\n",
      "Hamming Loss Value: 0.49\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.386\n",
      "Acc: 38.59%\n",
      "Precision: 0.38\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.312\n",
      "Acc: 31.23%\n",
      "Precision: 0.74\n",
      "Recall: 0.31\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.31\n",
      "Hamming Loss Value: 0.69\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.127\n",
      "Acc: 12.74%\n",
      "Precision: 0.03\n",
      "Recall: 0.13\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.13\n",
      "Hamming Loss Value: 0.87\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.218\n",
      "Acc: 21.77%\n",
      "Precision: 0.59\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.23\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.584\n",
      "Acc: 58.36%\n",
      "Precision: 0.55\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.455\n",
      "Acc: 45.51%\n",
      "Precision: 0.69\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "(0 vs all):  tensor([0.0081, 0.0822, 0.9096])\n",
      "43\n",
      "20170707\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.865\n",
      "Acc: 86.54%\n",
      "Precision: 0.75\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.80\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.086\n",
      "Acc: 8.64%\n",
      "Precision: 0.71\n",
      "Recall: 0.09\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.09\n",
      "Hamming Loss Value: 0.91\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.435\n",
      "Acc: 43.48%\n",
      "Precision: 0.67\n",
      "Recall: 0.43\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.43\n",
      "Hamming Loss Value: 0.57\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.292\n",
      "Acc: 29.18%\n",
      "Precision: 0.72\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.204\n",
      "Acc: 20.37%\n",
      "Precision: 0.76\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.615\n",
      "Acc: 61.55%\n",
      "Precision: 0.78\n",
      "Recall: 0.62\n",
      "F1 score weighted: 0.69\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.62\n",
      "Hamming Loss Value: 0.38\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.318\n",
      "Acc: 31.82%\n",
      "Precision: 0.79\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.601\n",
      "Acc: 60.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.523\n",
      "Acc: 52.35%\n",
      "Precision: 0.51\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.242\n",
      "Acc: 24.15%\n",
      "Precision: 0.68\n",
      "Recall: 0.24\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.24\n",
      "Hamming Loss Value: 0.76\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.448\n",
      "Acc: 44.78%\n",
      "Precision: 0.80\n",
      "Recall: 0.45\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.45\n",
      "Hamming Loss Value: 0.55\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.567\n",
      "Acc: 56.68%\n",
      "Precision: 0.79\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.471\n",
      "Acc: 47.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.178\n",
      "Acc: 17.76%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.26\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.544\n",
      "Acc: 54.39%\n",
      "Precision: 0.79\n",
      "Recall: 0.54\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.54\n",
      "Hamming Loss Value: 0.46\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.48%\n",
      "Precision: 0.72\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.474\n",
      "Acc: 47.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 31.73%\n",
      "Precision: 0.73\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.390\n",
      "Acc: 39.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.80\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.201\n",
      "Acc: 20.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.22\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.297\n",
      "Acc: 29.74%\n",
      "Precision: 0.74\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.120\n",
      "Acc: 12.05%\n",
      "Precision: 0.47\n",
      "Recall: 0.12\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.12\n",
      "Hamming Loss Value: 0.88\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.348\n",
      "Acc: 34.76%\n",
      "Precision: 0.66\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n",
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.212\n",
      "Acc: 21.16%\n",
      "Precision: 0.83\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.375\n",
      "Acc: 37.54%\n",
      "Precision: 0.42\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.253\n",
      "Acc: 25.30%\n",
      "Precision: 0.50\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.509\n",
      "Acc: 50.86%\n",
      "Precision: 0.42\n",
      "Recall: 0.51\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.51\n",
      "Hamming Loss Value: 0.49\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.386\n",
      "Acc: 38.59%\n",
      "Precision: 0.38\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.312\n",
      "Acc: 31.23%\n",
      "Precision: 0.74\n",
      "Recall: 0.31\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.31\n",
      "Hamming Loss Value: 0.69\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.127\n",
      "Acc: 12.74%\n",
      "Precision: 0.03\n",
      "Recall: 0.13\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.13\n",
      "Hamming Loss Value: 0.87\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.218\n",
      "Acc: 21.77%\n",
      "Precision: 0.59\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.23\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.584\n",
      "Acc: 58.36%\n",
      "Precision: 0.55\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.455\n",
      "Acc: 45.51%\n",
      "Precision: 0.69\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "(1 vs all):  tensor([0.0081, 0.0820, 0.9099])\n",
      "43\n",
      "20170707\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.865\n",
      "Acc: 86.54%\n",
      "Precision: 0.75\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.80\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acc: 8.64%\n",
      "Precision: 0.71\n",
      "Recall: 0.09\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.09\n",
      "Hamming Loss Value: 0.91\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.435\n",
      "Acc: 43.48%\n",
      "Precision: 0.67\n",
      "Recall: 0.43\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.43\n",
      "Hamming Loss Value: 0.57\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.292\n",
      "Acc: 29.18%\n",
      "Precision: 0.72\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.204\n",
      "Acc: 20.37%\n",
      "Precision: 0.76\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 61.55%\n",
      "Precision: 0.78\n",
      "Recall: 0.62\n",
      "F1 score weighted: 0.69\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.62\n",
      "Hamming Loss Value: 0.38\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 31.82%\n",
      "Precision: 0.79\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.601\n",
      "Acc: 60.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.523\n",
      "Acc: 52.35%\n",
      "Precision: 0.51\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.242\n",
      "Acc: 24.15%\n",
      "Precision: 0.68\n",
      "Recall: 0.24\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.24\n",
      "Hamming Loss Value: 0.76\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.448\n",
      "Acc: 44.78%\n",
      "Precision: 0.80\n",
      "Recall: 0.45\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.45\n",
      "Hamming Loss Value: 0.55\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.567\n",
      "Acc: 56.68%\n",
      "Precision: 0.79\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.471\n",
      "Acc: 47.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.178\n",
      "Acc: 17.76%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.26\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.544\n",
      "Acc: 54.39%\n",
      "Precision: 0.79\n",
      "Recall: 0.54\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.54\n",
      "Hamming Loss Value: 0.46\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.48%\n",
      "Precision: 0.72\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.474\n",
      "Acc: 47.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 31.73%\n",
      "Precision: 0.73\n",
      "Recall: 0.32\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.32\n",
      "Hamming Loss Value: 0.68\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.390\n",
      "Acc: 39.03%\n",
      "Precision: 0.80\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.201\n",
      "Acc: 20.14%\n",
      "Precision: 0.73\n",
      "Recall: 0.20\n",
      "F1 score weighted: 0.22\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.20\n",
      "Hamming Loss Value: 0.80\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.297\n",
      "Acc: 29.74%\n",
      "Precision: 0.74\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.120\n",
      "Acc: 12.05%\n",
      "Precision: 0.47\n",
      "Recall: 0.12\n",
      "F1 score weighted: 0.06\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.12\n",
      "Hamming Loss Value: 0.88\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.348\n",
      "Acc: 34.76%\n",
      "Precision: 0.66\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n",
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.212\n",
      "Acc: 21.16%\n",
      "Precision: 0.83\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.375\n",
      "Acc: 37.54%\n",
      "Precision: 0.42\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.253\n",
      "Acc: 25.30%\n",
      "Precision: 0.50\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.509\n",
      "Acc: 50.86%\n",
      "Precision: 0.42\n",
      "Recall: 0.51\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.51\n",
      "Hamming Loss Value: 0.49\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.386\n",
      "Acc: 38.59%\n",
      "Precision: 0.38\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.312\n",
      "Acc: 31.23%\n",
      "Precision: 0.74\n",
      "Recall: 0.31\n",
      "F1 score weighted: 0.41\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.31\n",
      "Hamming Loss Value: 0.69\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.127\n",
      "Acc: 12.74%\n",
      "Precision: 0.03\n",
      "Recall: 0.13\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.14\n",
      "F1 score micro: 0.13\n",
      "Hamming Loss Value: 0.87\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.218\n",
      "Acc: 21.77%\n",
      "Precision: 0.59\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.23\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.584\n",
      "Acc: 58.36%\n",
      "Precision: 0.55\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.455\n",
      "Acc: 45.51%\n",
      "Precision: 0.69\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "it took 0.24524545669555664 seconds!\n",
      "1\n",
      "---------------> Doing Model Date: 20170707\n",
      "first bit done\n",
      "done with kernel\n",
      "['20170712', '20170717', '20170718', '20170719', '20170720', '20170721', '20170724', '20170727', '20170801', '20170802', '20170803', '20170804', '20170808', '20170809', '20170814', '20170816', '20170817', '20170818', '20170822', '20170823', '20170824', '20170830', '20170901', '20170904', '20170905', '20170908', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170929', '20180301', '20180302', '20180404', '20180412', '20180420']\n",
      "done\n",
      "the combination weights are:\n",
      "(-1 vs all):  tensor([0.0078, 0.0796, 0.9125])\n",
      "42\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.642\n",
      "Acc: 64.23%\n",
      "Precision: 0.67\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.352\n",
      "Acc: 35.24%\n",
      "Precision: 0.77\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.657\n",
      "Acc: 65.73%\n",
      "Precision: 0.80\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 59.58%\n",
      "Precision: 0.79\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 25.17%\n",
      "Precision: 0.75\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.416\n",
      "Acc: 41.60%\n",
      "Precision: 0.73\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.259\n",
      "Acc: 25.85%\n",
      "Precision: 0.45\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.24\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.249\n",
      "Acc: 24.95%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.472\n",
      "Acc: 47.18%\n",
      "Precision: 0.81\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.329\n",
      "Acc: 32.88%\n",
      "Precision: 0.75\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.233\n",
      "Acc: 23.33%\n",
      "Precision: 0.67\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.276\n",
      "Acc: 27.63%\n",
      "Precision: 0.83\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.374\n",
      "Acc: 37.37%\n",
      "Precision: 0.77\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.210\n",
      "Acc: 21.02%\n",
      "Precision: 0.70\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.137\n",
      "Acc: 13.69%\n",
      "Precision: 0.82\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 57.02%\n",
      "Precision: 0.74\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 51.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.69\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.335\n",
      "Acc: 33.52%\n",
      "Precision: 0.50\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n",
      "Accuracy score: 0.338\n",
      "Acc: 33.81%\n",
      "Precision: 0.66\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.361\n",
      "Acc: 36.11%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.496\n",
      "Acc: 49.56%\n",
      "Precision: 0.42\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.499\n",
      "Acc: 49.91%\n",
      "Precision: 0.58\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.281\n",
      "Acc: 28.11%\n",
      "Precision: 0.37\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.261\n",
      "Acc: 26.05%\n",
      "Precision: 0.33\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.21\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.516\n",
      "Acc: 51.59%\n",
      "Precision: 0.77\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.286\n",
      "Acc: 28.57%\n",
      "Precision: 0.59\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.568\n",
      "Acc: 56.82%\n",
      "Precision: 0.64\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.190\n",
      "Acc: 18.99%\n",
      "Precision: 0.56\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.113\n",
      "Acc: 11.32%\n",
      "Precision: 0.66\n",
      "Recall: 0.11\n",
      "F1 score weighted: 0.08\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.11\n",
      "Hamming Loss Value: 0.89\n",
      "(0 vs all):  tensor([0.0080, 0.0812, 0.9108])\n",
      "42\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.642\n",
      "Acc: 64.23%\n",
      "Precision: 0.67\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.352\n",
      "Acc: 35.24%\n",
      "Precision: 0.77\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.657\n",
      "Acc: 65.73%\n",
      "Precision: 0.80\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 59.58%\n",
      "Precision: 0.79\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.252\n",
      "Acc: 25.17%\n",
      "Precision: 0.75\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.416\n",
      "Acc: 41.60%\n",
      "Precision: 0.73\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.259\n",
      "Acc: 25.85%\n",
      "Precision: 0.45\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.24\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.249\n",
      "Acc: 24.95%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.472\n",
      "Acc: 47.18%\n",
      "Precision: 0.81\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.329\n",
      "Acc: 32.88%\n",
      "Precision: 0.75\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.233\n",
      "Acc: 23.33%\n",
      "Precision: 0.67\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.276\n",
      "Acc: 27.63%\n",
      "Precision: 0.83\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.374\n",
      "Acc: 37.37%\n",
      "Precision: 0.77\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.210\n",
      "Acc: 21.02%\n",
      "Precision: 0.70\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.137\n",
      "Acc: 13.69%\n",
      "Precision: 0.82\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.570\n",
      "Acc: 57.02%\n",
      "Precision: 0.74\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 51.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.69\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.335\n",
      "Acc: 33.52%\n",
      "Precision: 0.50\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n",
      "Accuracy score: 0.338\n",
      "Acc: 33.81%\n",
      "Precision: 0.66\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.361\n",
      "Acc: 36.11%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.496\n",
      "Acc: 49.56%\n",
      "Precision: 0.42\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.499\n",
      "Acc: 49.91%\n",
      "Precision: 0.58\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.281\n",
      "Acc: 28.11%\n",
      "Precision: 0.37\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.261\n",
      "Acc: 26.05%\n",
      "Precision: 0.33\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.21\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.516\n",
      "Acc: 51.59%\n",
      "Precision: 0.77\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.286\n",
      "Acc: 28.57%\n",
      "Precision: 0.59\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.568\n",
      "Acc: 56.82%\n",
      "Precision: 0.64\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.190\n",
      "Acc: 18.99%\n",
      "Precision: 0.56\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.113\n",
      "Acc: 11.32%\n",
      "Precision: 0.66\n",
      "Recall: 0.11\n",
      "F1 score weighted: 0.08\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.11\n",
      "Hamming Loss Value: 0.89\n",
      "(1 vs all):  tensor([0.0084, 0.0848, 0.9067])\n",
      "42\n",
      "20170712\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.809\n",
      "Acc: 80.93%\n",
      "Precision: 0.65\n",
      "Recall: 0.81\n",
      "F1 score weighted: 0.72\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.81\n",
      "Hamming Loss Value: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.642\n",
      "Acc: 64.23%\n",
      "Precision: 0.67\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.352\n",
      "Acc: 35.24%\n",
      "Precision: 0.77\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.657\n",
      "Acc: 65.73%\n",
      "Precision: 0.80\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.596\n",
      "Acc: 59.58%\n",
      "Precision: 0.79\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "20170724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 25.17%\n",
      "Precision: 0.75\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.416\n",
      "Acc: 41.60%\n",
      "Precision: 0.73\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.51\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.259\n",
      "Acc: 25.85%\n",
      "Precision: 0.45\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.24\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.249\n",
      "Acc: 24.95%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.472\n",
      "Acc: 47.18%\n",
      "Precision: 0.81\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.329\n",
      "Acc: 32.88%\n",
      "Precision: 0.75\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.233\n",
      "Acc: 23.33%\n",
      "Precision: 0.67\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.276\n",
      "Acc: 27.63%\n",
      "Precision: 0.83\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.17\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.374\n",
      "Acc: 37.37%\n",
      "Precision: 0.77\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.210\n",
      "Acc: 21.02%\n",
      "Precision: 0.70\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.137\n",
      "Acc: 13.69%\n",
      "Precision: 0.82\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.570\n",
      "Acc: 57.02%\n",
      "Precision: 0.74\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.78\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 51.97%\n",
      "Precision: 0.73\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.69\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.335\n",
      "Acc: 33.52%\n",
      "Precision: 0.50\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.39\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n",
      "Accuracy score: 0.338\n",
      "Acc: 33.81%\n",
      "Precision: 0.66\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.361\n",
      "Acc: 36.11%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.496\n",
      "Acc: 49.56%\n",
      "Precision: 0.42\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.499\n",
      "Acc: 49.91%\n",
      "Precision: 0.58\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.53\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.281\n",
      "Acc: 28.11%\n",
      "Precision: 0.37\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.25\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.261\n",
      "Acc: 26.05%\n",
      "Precision: 0.33\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.21\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.516\n",
      "Acc: 51.59%\n",
      "Precision: 0.77\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.286\n",
      "Acc: 28.57%\n",
      "Precision: 0.59\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.568\n",
      "Acc: 56.82%\n",
      "Precision: 0.64\n",
      "Recall: 0.57\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.57\n",
      "Hamming Loss Value: 0.43\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.190\n",
      "Acc: 18.99%\n",
      "Precision: 0.56\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.15\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.113\n",
      "Acc: 11.32%\n",
      "Precision: 0.66\n",
      "Recall: 0.11\n",
      "F1 score weighted: 0.08\n",
      "F1 score macro: 0.12\n",
      "F1 score micro: 0.11\n",
      "Hamming Loss Value: 0.89\n",
      "it took 0.2721233367919922 seconds!\n",
      "2\n",
      "---------------> Doing Model Date: 20170712\n",
      "first bit done\n",
      "done with kernel\n",
      "['20170717', '20170718', '20170719', '20170720', '20170721', '20170724', '20170727', '20170801', '20170802', '20170803', '20170804', '20170808', '20170809', '20170814', '20170816', '20170817', '20170818', '20170822', '20170823', '20170824', '20170830', '20170901', '20170904', '20170905', '20170908', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170929', '20180301', '20180302', '20180404', '20180412', '20180420']\n",
      "done\n",
      "the combination weights are:\n",
      "(-1 vs all):  tensor([0.0071, 0.0730, 0.9199])\n",
      "41\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.48%\n",
      "Precision: 0.75\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.377\n",
      "Acc: 37.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.53%\n",
      "Precision: 0.70\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.282\n",
      "Acc: 28.20%\n",
      "Precision: 0.50\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.69\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.19\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.658\n",
      "Acc: 65.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n",
      "Accuracy score: 0.194\n",
      "Acc: 19.42%\n",
      "Precision: 0.80\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.588\n",
      "Acc: 58.82%\n",
      "Precision: 0.78\n",
      "Recall: 0.59\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.59\n",
      "Hamming Loss Value: 0.41\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.561\n",
      "Acc: 56.07%\n",
      "Precision: 0.62\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.492\n",
      "Acc: 49.17%\n",
      "Precision: 0.37\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.473\n",
      "Acc: 47.30%\n",
      "Precision: 0.59\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.32%\n",
      "Precision: 0.41\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.26%\n",
      "Precision: 0.75\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.421\n",
      "Acc: 42.05%\n",
      "Precision: 0.61\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n",
      "Accuracy score: 0.637\n",
      "Acc: 63.69%\n",
      "Precision: 0.64\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "(0 vs all):  tensor([0.0064, 0.0664, 0.9272])\n",
      "41\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.48%\n",
      "Precision: 0.75\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.377\n",
      "Acc: 37.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.53%\n",
      "Precision: 0.70\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.282\n",
      "Acc: 28.20%\n",
      "Precision: 0.50\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.69\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.19\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.658\n",
      "Acc: 65.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.194\n",
      "Acc: 19.42%\n",
      "Precision: 0.80\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.588\n",
      "Acc: 58.82%\n",
      "Precision: 0.78\n",
      "Recall: 0.59\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.59\n",
      "Hamming Loss Value: 0.41\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.561\n",
      "Acc: 56.07%\n",
      "Precision: 0.62\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.492\n",
      "Acc: 49.17%\n",
      "Precision: 0.37\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.473\n",
      "Acc: 47.30%\n",
      "Precision: 0.59\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.32%\n",
      "Precision: 0.41\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.26%\n",
      "Precision: 0.75\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.421\n",
      "Acc: 42.05%\n",
      "Precision: 0.61\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n",
      "Accuracy score: 0.637\n",
      "Acc: 63.69%\n",
      "Precision: 0.64\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "(1 vs all):  tensor([0.0052, 0.0558, 0.9390])\n",
      "41\n",
      "20170717\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.48%\n",
      "Precision: 0.75\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.377\n",
      "Acc: 37.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.365\n",
      "Acc: 36.53%\n",
      "Precision: 0.70\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.282\n",
      "Acc: 28.20%\n",
      "Precision: 0.50\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.181\n",
      "Acc: 18.15%\n",
      "Precision: 0.69\n",
      "Recall: 0.18\n",
      "F1 score weighted: 0.19\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.18\n",
      "Hamming Loss Value: 0.82\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.658\n",
      "Acc: 65.75%\n",
      "Precision: 0.76\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n",
      "Accuracy score: 0.194\n",
      "Acc: 19.42%\n",
      "Precision: 0.80\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.27\n",
      "F1 score macro: 0.15\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.588\n",
      "Acc: 58.82%\n",
      "Precision: 0.78\n",
      "Recall: 0.59\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.59\n",
      "Hamming Loss Value: 0.41\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n",
      "Accuracy score: 0.561\n",
      "Acc: 56.07%\n",
      "Precision: 0.62\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.492\n",
      "Acc: 49.17%\n",
      "Precision: 0.37\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.42\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.473\n",
      "Acc: 47.30%\n",
      "Precision: 0.59\n",
      "Recall: 0.47\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.47\n",
      "Hamming Loss Value: 0.53\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.32%\n",
      "Precision: 0.41\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.283\n",
      "Acc: 28.26%\n",
      "Precision: 0.75\n",
      "Recall: 0.28\n",
      "F1 score weighted: 0.38\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.28\n",
      "Hamming Loss Value: 0.72\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.421\n",
      "Acc: 42.05%\n",
      "Precision: 0.61\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n",
      "Accuracy score: 0.637\n",
      "Acc: 63.69%\n",
      "Precision: 0.64\n",
      "Recall: 0.64\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.36\n",
      "F1 score micro: 0.64\n",
      "Hamming Loss Value: 0.36\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "it took 0.05940556526184082 seconds!\n",
      "3\n",
      "---------------> Doing Model Date: 20170717\n",
      "first bit done\n",
      "done with kernel\n",
      "['20170718', '20170719', '20170720', '20170721', '20170724', '20170727', '20170801', '20170802', '20170803', '20170804', '20170808', '20170809', '20170814', '20170816', '20170817', '20170818', '20170822', '20170823', '20170824', '20170830', '20170901', '20170904', '20170905', '20170908', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170929', '20180301', '20180302', '20180404', '20180412', '20180420']\n",
      "done\n",
      "the combination weights are:\n",
      "(-1 vs all):  tensor([0.0080, 0.0808, 0.9112])\n",
      "40\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.248\n",
      "Acc: 24.83%\n",
      "Precision: 0.74\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.32\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.875\n",
      "Acc: 87.52%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.388\n",
      "Acc: 38.80%\n",
      "Precision: 0.77\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.74\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.359\n",
      "Acc: 35.92%\n",
      "Precision: 0.79\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.489\n",
      "Acc: 48.93%\n",
      "Precision: 0.78\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.829\n",
      "Acc: 82.94%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.350\n",
      "Acc: 35.01%\n",
      "Precision: 0.72\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.498\n",
      "Acc: 49.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.555\n",
      "Acc: 55.55%\n",
      "Precision: 0.51\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.520\n",
      "Acc: 51.99%\n",
      "Precision: 0.60\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.275\n",
      "Acc: 27.49%\n",
      "Precision: 0.81\n",
      "Recall: 0.27\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.27\n",
      "Hamming Loss Value: 0.73\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.584\n",
      "Acc: 58.42%\n",
      "Precision: 0.78\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.66\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923\n",
      "Acc: 92.33%\n",
      "Precision: 0.85\n",
      "Recall: 0.92\n",
      "F1 score weighted: 0.89\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.92\n",
      "Hamming Loss Value: 0.08\n",
      "Accuracy score: 0.340\n",
      "Acc: 34.01%\n",
      "Precision: 0.81\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.853\n",
      "Acc: 85.33%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.526\n",
      "Acc: 52.65%\n",
      "Precision: 0.75\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.93%\n",
      "Precision: 0.71\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n",
      "Accuracy score: 0.079\n",
      "Acc: 7.88%\n",
      "Precision: 0.86\n",
      "Recall: 0.08\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.08\n",
      "Hamming Loss Value: 0.92\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.222\n",
      "Acc: 22.25%\n",
      "Precision: 0.80\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.260\n",
      "Acc: 26.02%\n",
      "Precision: 0.72\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.823\n",
      "Acc: 82.34%\n",
      "Precision: 0.68\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.74\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.422\n",
      "Acc: 42.19%\n",
      "Precision: 0.72\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.290\n",
      "Acc: 28.95%\n",
      "Precision: 0.76\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.833\n",
      "Acc: 83.26%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.465\n",
      "Acc: 46.49%\n",
      "Precision: 0.70\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 39.19%\n",
      "Precision: 0.74\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.362\n",
      "Acc: 36.16%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.545\n",
      "Acc: 54.51%\n",
      "Precision: 0.74\n",
      "Recall: 0.55\n",
      "F1 score weighted: 0.62\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.55\n",
      "Hamming Loss Value: 0.45\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.139\n",
      "Acc: 13.90%\n",
      "Precision: 0.73\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.16\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.380\n",
      "Acc: 37.95%\n",
      "Precision: 0.70\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.419\n",
      "Acc: 41.90%\n",
      "Precision: 0.67\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n",
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.47%\n",
      "Precision: 0.77\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.408\n",
      "Acc: 40.76%\n",
      "Precision: 0.43\n",
      "Recall: 0.41\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.41\n",
      "Hamming Loss Value: 0.59\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.302\n",
      "Acc: 30.17%\n",
      "Precision: 0.57\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.33\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.234\n",
      "Acc: 23.44%\n",
      "Precision: 0.56\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.17\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.387\n",
      "Acc: 38.71%\n",
      "Precision: 0.35\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.213\n",
      "Acc: 21.26%\n",
      "Precision: 0.76\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.437\n",
      "Acc: 43.72%\n",
      "Precision: 0.60\n",
      "Recall: 0.44\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.44\n",
      "Hamming Loss Value: 0.56\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.250\n",
      "Acc: 25.02%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n",
      "Accuracy score: 0.682\n",
      "Acc: 68.18%\n",
      "Precision: 0.54\n",
      "Recall: 0.68\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.68\n",
      "Hamming Loss Value: 0.32\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n",
      "Accuracy score: 0.579\n",
      "Acc: 57.88%\n",
      "Precision: 0.69\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.63\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "(0 vs all):  tensor([0.0080, 0.0807, 0.9114])\n",
      "40\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n",
      "Accuracy score: 0.248\n",
      "Acc: 24.83%\n",
      "Precision: 0.74\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.32\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.52%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.388\n",
      "Acc: 38.80%\n",
      "Precision: 0.77\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.74\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.359\n",
      "Acc: 35.92%\n",
      "Precision: 0.79\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.489\n",
      "Acc: 48.93%\n",
      "Precision: 0.78\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.829\n",
      "Acc: 82.94%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.350\n",
      "Acc: 35.01%\n",
      "Precision: 0.72\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.498\n",
      "Acc: 49.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.555\n",
      "Acc: 55.55%\n",
      "Precision: 0.51\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.520\n",
      "Acc: 51.99%\n",
      "Precision: 0.60\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.275\n",
      "Acc: 27.49%\n",
      "Precision: 0.81\n",
      "Recall: 0.27\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.27\n",
      "Hamming Loss Value: 0.73\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.584\n",
      "Acc: 58.42%\n",
      "Precision: 0.78\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.66\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923\n",
      "Acc: 92.33%\n",
      "Precision: 0.85\n",
      "Recall: 0.92\n",
      "F1 score weighted: 0.89\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.92\n",
      "Hamming Loss Value: 0.08\n",
      "Accuracy score: 0.340\n",
      "Acc: 34.01%\n",
      "Precision: 0.81\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.853\n",
      "Acc: 85.33%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.526\n",
      "Acc: 52.65%\n",
      "Precision: 0.75\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.93%\n",
      "Precision: 0.71\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.079\n",
      "Acc: 7.88%\n",
      "Precision: 0.86\n",
      "Recall: 0.08\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.08\n",
      "Hamming Loss Value: 0.92\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.222\n",
      "Acc: 22.25%\n",
      "Precision: 0.80\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.260\n",
      "Acc: 26.02%\n",
      "Precision: 0.72\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.823\n",
      "Acc: 82.34%\n",
      "Precision: 0.68\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.74\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n",
      "Accuracy score: 0.422\n",
      "Acc: 42.19%\n",
      "Precision: 0.72\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.290\n",
      "Acc: 28.95%\n",
      "Precision: 0.76\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.833\n",
      "Acc: 83.26%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.465\n",
      "Acc: 46.49%\n",
      "Precision: 0.70\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.392\n",
      "Acc: 39.19%\n",
      "Precision: 0.74\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.362\n",
      "Acc: 36.16%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.545\n",
      "Acc: 54.51%\n",
      "Precision: 0.74\n",
      "Recall: 0.55\n",
      "F1 score weighted: 0.62\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.55\n",
      "Hamming Loss Value: 0.45\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.139\n",
      "Acc: 13.90%\n",
      "Precision: 0.73\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.16\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.380\n",
      "Acc: 37.95%\n",
      "Precision: 0.70\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.419\n",
      "Acc: 41.90%\n",
      "Precision: 0.67\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n",
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.47%\n",
      "Precision: 0.77\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "Accuracy score: 0.408\n",
      "Acc: 40.76%\n",
      "Precision: 0.43\n",
      "Recall: 0.41\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.41\n",
      "Hamming Loss Value: 0.59\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n",
      "Accuracy score: 0.302\n",
      "Acc: 30.17%\n",
      "Precision: 0.57\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.33\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.234\n",
      "Acc: 23.44%\n",
      "Precision: 0.56\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.17\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.387\n",
      "Acc: 38.71%\n",
      "Precision: 0.35\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.213\n",
      "Acc: 21.26%\n",
      "Precision: 0.76\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n",
      "Accuracy score: 0.437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acc: 43.72%\n",
      "Precision: 0.60\n",
      "Recall: 0.44\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.44\n",
      "Hamming Loss Value: 0.56\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.250\n",
      "Acc: 25.02%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n",
      "Accuracy score: 0.682\n",
      "Acc: 68.18%\n",
      "Precision: 0.54\n",
      "Recall: 0.68\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.68\n",
      "Hamming Loss Value: 0.32\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted out test dates bit done\n",
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.579\n",
      "Acc: 57.88%\n",
      "Precision: 0.69\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.63\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "(1 vs all):  tensor([0.0082, 0.0832, 0.9085])\n",
      "40\n",
      "20170718\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.852\n",
      "Acc: 85.15%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.248\n",
      "Acc: 24.83%\n",
      "Precision: 0.74\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.32\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.875\n",
      "Acc: 87.52%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.388\n",
      "Acc: 38.80%\n",
      "Precision: 0.77\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.871\n",
      "Acc: 87.07%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.529\n",
      "Acc: 52.91%\n",
      "Precision: 0.74\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.886\n",
      "Acc: 88.59%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.359\n",
      "Acc: 35.92%\n",
      "Precision: 0.79\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.489\n",
      "Acc: 48.93%\n",
      "Precision: 0.78\n",
      "Recall: 0.49\n",
      "F1 score weighted: 0.58\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.49\n",
      "Hamming Loss Value: 0.51\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.829\n",
      "Acc: 82.94%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.350\n",
      "Acc: 35.01%\n",
      "Precision: 0.72\n",
      "Recall: 0.35\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.35\n",
      "Hamming Loss Value: 0.65\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n",
      "Accuracy score: 0.498\n",
      "Acc: 49.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.555\n",
      "Acc: 55.55%\n",
      "Precision: 0.51\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n",
      "Accuracy score: 0.520\n",
      "Acc: 51.99%\n",
      "Precision: 0.60\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.55\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Acc: 88.84%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.84\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n",
      "Accuracy score: 0.275\n",
      "Acc: 27.49%\n",
      "Precision: 0.81\n",
      "Recall: 0.27\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.27\n",
      "Hamming Loss Value: 0.73\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.875\n",
      "Acc: 87.45%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n",
      "Accuracy score: 0.584\n",
      "Acc: 58.42%\n",
      "Precision: 0.78\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.66\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.923\n",
      "Acc: 92.33%\n",
      "Precision: 0.85\n",
      "Recall: 0.92\n",
      "F1 score weighted: 0.89\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.92\n",
      "Hamming Loss Value: 0.08\n",
      "Accuracy score: 0.340\n",
      "Acc: 34.01%\n",
      "Precision: 0.81\n",
      "Recall: 0.34\n",
      "F1 score weighted: 0.46\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.34\n",
      "Hamming Loss Value: 0.66\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.853\n",
      "Acc: 85.33%\n",
      "Precision: 0.73\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.526\n",
      "Acc: 52.65%\n",
      "Precision: 0.75\n",
      "Recall: 0.53\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.53\n",
      "Hamming Loss Value: 0.47\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.826\n",
      "Acc: 82.62%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.93%\n",
      "Precision: 0.71\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.079\n",
      "Acc: 7.88%\n",
      "Precision: 0.86\n",
      "Recall: 0.08\n",
      "F1 score weighted: 0.05\n",
      "F1 score macro: 0.09\n",
      "F1 score micro: 0.08\n",
      "Hamming Loss Value: 0.92\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.883\n",
      "Acc: 88.32%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.222\n",
      "Acc: 22.25%\n",
      "Precision: 0.80\n",
      "Recall: 0.22\n",
      "F1 score weighted: 0.30\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.22\n",
      "Hamming Loss Value: 0.78\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.851\n",
      "Acc: 85.11%\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1 score weighted: 0.78\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.85\n",
      "Hamming Loss Value: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.260\n",
      "Acc: 26.02%\n",
      "Precision: 0.72\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.34\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.823\n",
      "Acc: 82.34%\n",
      "Precision: 0.68\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.74\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n",
      "Accuracy score: 0.422\n",
      "Acc: 42.19%\n",
      "Precision: 0.72\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.878\n",
      "Acc: 87.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.290\n",
      "Acc: 28.95%\n",
      "Precision: 0.76\n",
      "Recall: 0.29\n",
      "F1 score weighted: 0.37\n",
      "F1 score macro: 0.18\n",
      "F1 score micro: 0.29\n",
      "Hamming Loss Value: 0.71\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.833\n",
      "Acc: 83.26%\n",
      "Precision: 0.69\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n",
      "Accuracy score: 0.465\n",
      "Acc: 46.49%\n",
      "Precision: 0.70\n",
      "Recall: 0.46\n",
      "F1 score weighted: 0.54\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.46\n",
      "Hamming Loss Value: 0.54\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.860\n",
      "Acc: 85.97%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n",
      "Accuracy score: 0.392\n",
      "Acc: 39.19%\n",
      "Precision: 0.74\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.886\n",
      "Acc: 88.64%\n",
      "Precision: 0.79\n",
      "Recall: 0.89\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.89\n",
      "Hamming Loss Value: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.362\n",
      "Acc: 36.16%\n",
      "Precision: 0.81\n",
      "Recall: 0.36\n",
      "F1 score weighted: 0.47\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.36\n",
      "Hamming Loss Value: 0.64\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.858\n",
      "Acc: 85.77%\n",
      "Precision: 0.74\n",
      "Recall: 0.86\n",
      "F1 score weighted: 0.79\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.86\n",
      "Hamming Loss Value: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.545\n",
      "Acc: 54.51%\n",
      "Precision: 0.74\n",
      "Recall: 0.55\n",
      "F1 score weighted: 0.62\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.55\n",
      "Hamming Loss Value: 0.45\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.827\n",
      "Acc: 82.65%\n",
      "Precision: 0.68\n",
      "Recall: 0.83\n",
      "F1 score weighted: 0.75\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.83\n",
      "Hamming Loss Value: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.139\n",
      "Acc: 13.90%\n",
      "Precision: 0.73\n",
      "Recall: 0.14\n",
      "F1 score weighted: 0.16\n",
      "F1 score macro: 0.13\n",
      "F1 score micro: 0.14\n",
      "Hamming Loss Value: 0.86\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.380\n",
      "Acc: 37.95%\n",
      "Precision: 0.70\n",
      "Recall: 0.38\n",
      "F1 score weighted: 0.44\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.38\n",
      "Hamming Loss Value: 0.62\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.793\n",
      "Acc: 79.29%\n",
      "Precision: 0.63\n",
      "Recall: 0.79\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.79\n",
      "Hamming Loss Value: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.419\n",
      "Acc: 41.90%\n",
      "Precision: 0.67\n",
      "Recall: 0.42\n",
      "F1 score weighted: 0.49\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.42\n",
      "Hamming Loss Value: 0.58\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.884\n",
      "Acc: 88.43%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.83\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n",
      "Accuracy score: 0.635\n",
      "Acc: 63.47%\n",
      "Precision: 0.77\n",
      "Recall: 0.63\n",
      "F1 score weighted: 0.70\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.63\n",
      "Hamming Loss Value: 0.37\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.559\n",
      "Acc: 55.91%\n",
      "Precision: 0.31\n",
      "Recall: 0.56\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.56\n",
      "Hamming Loss Value: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.408\n",
      "Acc: 40.76%\n",
      "Precision: 0.43\n",
      "Recall: 0.41\n",
      "F1 score weighted: 0.40\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.41\n",
      "Hamming Loss Value: 0.59\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.708\n",
      "Acc: 70.78%\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 score weighted: 0.59\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.71\n",
      "Hamming Loss Value: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.302\n",
      "Acc: 30.17%\n",
      "Precision: 0.57\n",
      "Recall: 0.30\n",
      "F1 score weighted: 0.33\n",
      "F1 score macro: 0.21\n",
      "F1 score micro: 0.30\n",
      "Hamming Loss Value: 0.70\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n",
      "Accuracy score: 0.234\n",
      "Acc: 23.44%\n",
      "Precision: 0.56\n",
      "Recall: 0.23\n",
      "F1 score weighted: 0.17\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.23\n",
      "Hamming Loss Value: 0.77\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.483\n",
      "Acc: 48.26%\n",
      "Precision: 0.23\n",
      "Recall: 0.48\n",
      "F1 score weighted: 0.31\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.48\n",
      "Hamming Loss Value: 0.52\n",
      "Accuracy score: 0.387\n",
      "Acc: 38.71%\n",
      "Precision: 0.35\n",
      "Recall: 0.39\n",
      "F1 score weighted: 0.36\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.39\n",
      "Hamming Loss Value: 0.61\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.213\n",
      "Acc: 21.26%\n",
      "Precision: 0.76\n",
      "Recall: 0.21\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.16\n",
      "F1 score micro: 0.21\n",
      "Hamming Loss Value: 0.79\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.437\n",
      "Acc: 43.72%\n",
      "Precision: 0.60\n",
      "Recall: 0.44\n",
      "F1 score weighted: 0.48\n",
      "F1 score macro: 0.27\n",
      "F1 score micro: 0.44\n",
      "Hamming Loss Value: 0.56\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.777\n",
      "Acc: 77.69%\n",
      "Precision: 0.60\n",
      "Recall: 0.78\n",
      "F1 score weighted: 0.68\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.78\n",
      "Hamming Loss Value: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.250\n",
      "Acc: 25.02%\n",
      "Precision: 0.59\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.19\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.727\n",
      "Acc: 72.70%\n",
      "Precision: 0.53\n",
      "Recall: 0.73\n",
      "F1 score weighted: 0.61\n",
      "F1 score macro: 0.28\n",
      "F1 score micro: 0.73\n",
      "Hamming Loss Value: 0.27\n",
      "Accuracy score: 0.682\n",
      "Acc: 68.18%\n",
      "Precision: 0.54\n",
      "Recall: 0.68\n",
      "F1 score weighted: 0.60\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.68\n",
      "Hamming Loss Value: 0.32\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.817\n",
      "Acc: 81.68%\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 score weighted: 0.73\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.82\n",
      "Hamming Loss Value: 0.18\n",
      "Accuracy score: 0.579\n",
      "Acc: 57.88%\n",
      "Precision: 0.69\n",
      "Recall: 0.58\n",
      "F1 score weighted: 0.63\n",
      "F1 score macro: 0.33\n",
      "F1 score micro: 0.58\n",
      "Hamming Loss Value: 0.42\n",
      "it took 0.24602675437927246 seconds!\n",
      "4\n",
      "---------------> Doing Model Date: 20170718\n",
      "first bit done\n",
      "done with kernel\n",
      "['20170719', '20170720', '20170721', '20170724', '20170727', '20170801', '20170802', '20170803', '20170804', '20170808', '20170809', '20170814', '20170816', '20170817', '20170818', '20170822', '20170823', '20170824', '20170830', '20170901', '20170904', '20170905', '20170908', '20170912', '20170913', '20170914', '20170915', '20170918', '20170919', '20170920', '20170921', '20170922', '20170925', '20170929', '20180301', '20180302', '20180404', '20180412', '20180420']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "the combination weights are:\n",
      "(-1 vs all):  tensor([0.0081, 0.0815, 0.9104])\n",
      "39\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.328\n",
      "Acc: 32.76%\n",
      "Precision: 0.77\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.500\n",
      "Acc: 50.03%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.541376mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.262\n",
      "Acc: 26.20%\n",
      "Precision: 0.54\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1196.998656mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.252\n",
      "Acc: 25.23%\n",
      "Precision: 0.60\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.373\n",
      "Acc: 37.26%\n",
      "Precision: 0.80\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.189\n",
      "Acc: 18.85%\n",
      "Precision: 0.63\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.248\n",
      "Acc: 24.81%\n",
      "Precision: 0.51\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.665\n",
      "Acc: 66.49%\n",
      "Precision: 0.78\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 52.01%\n",
      "Precision: 0.63\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "(0 vs all):  tensor([0.0086, 0.0865, 0.9049])\n",
      "39\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.328\n",
      "Acc: 32.76%\n",
      "Precision: 0.77\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.500\n",
      "Acc: 50.03%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1101.324288mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.262\n",
      "Acc: 26.20%\n",
      "Precision: 0.54\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1196.7488mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.252\n",
      "Acc: 25.23%\n",
      "Precision: 0.60\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.373\n",
      "Acc: 37.26%\n",
      "Precision: 0.80\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.189\n",
      "Acc: 18.85%\n",
      "Precision: 0.63\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.248\n",
      "Acc: 24.81%\n",
      "Precision: 0.51\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.0744320000001mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.665\n",
      "Acc: 66.49%\n",
      "Precision: 0.78\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 52.01%\n",
      "Precision: 0.63\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "(1 vs all):  tensor([0.0082, 0.0833, 0.9085])\n",
      "39\n",
      "20170719\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20170720\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20170721\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20170724\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.877\n",
      "Acc: 87.75%\n",
      "Precision: 0.77\n",
      "Recall: 0.88\n",
      "F1 score weighted: 0.82\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.88\n",
      "Hamming Loss Value: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.328\n",
      "Acc: 32.76%\n",
      "Precision: 0.77\n",
      "Recall: 0.33\n",
      "F1 score weighted: 0.43\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.33\n",
      "Hamming Loss Value: 0.67\n",
      "20170727\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "20170801\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.838\n",
      "Acc: 83.76%\n",
      "Precision: 0.70\n",
      "Recall: 0.84\n",
      "F1 score weighted: 0.76\n",
      "F1 score macro: 0.30\n",
      "F1 score micro: 0.84\n",
      "Hamming Loss Value: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.500\n",
      "Acc: 50.03%\n",
      "Precision: 0.70\n",
      "Recall: 0.50\n",
      "F1 score weighted: 0.57\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.50\n",
      "Hamming Loss Value: 0.50\n",
      "20170802\n",
      "Memory usage at Before garbage collect is 1129.725952mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.655\n",
      "Acc: 65.50%\n",
      "Precision: 0.43\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.52\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.262\n",
      "Acc: 26.20%\n",
      "Precision: 0.54\n",
      "Recall: 0.26\n",
      "F1 score weighted: 0.28\n",
      "F1 score macro: 0.26\n",
      "F1 score micro: 0.26\n",
      "Hamming Loss Value: 0.74\n",
      "20170803\n",
      "Memory usage at Before garbage collect is 1228.742656mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.772\n",
      "Acc: 77.22%\n",
      "Precision: 0.60\n",
      "Recall: 0.77\n",
      "F1 score weighted: 0.67\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.77\n",
      "Hamming Loss Value: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.252\n",
      "Acc: 25.23%\n",
      "Precision: 0.60\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.29\n",
      "F1 score macro: 0.23\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170804\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170808\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170809\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170814\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170816\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170817\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170818\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.900\n",
      "Acc: 89.96%\n",
      "Precision: 0.81\n",
      "Recall: 0.90\n",
      "F1 score weighted: 0.85\n",
      "F1 score macro: 0.32\n",
      "F1 score micro: 0.90\n",
      "Hamming Loss Value: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.373\n",
      "Acc: 37.26%\n",
      "Precision: 0.80\n",
      "Recall: 0.37\n",
      "F1 score weighted: 0.50\n",
      "F1 score macro: 0.22\n",
      "F1 score micro: 0.37\n",
      "Hamming Loss Value: 0.63\n",
      "20170822\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170823\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170824\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170830\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170901\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170904\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170905\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170908\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170912\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170913\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170914\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170915\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.751\n",
      "Acc: 75.08%\n",
      "Precision: 0.56\n",
      "Recall: 0.75\n",
      "F1 score weighted: 0.64\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.75\n",
      "Hamming Loss Value: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.189\n",
      "Acc: 18.85%\n",
      "Precision: 0.63\n",
      "Recall: 0.19\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.20\n",
      "F1 score micro: 0.19\n",
      "Hamming Loss Value: 0.81\n",
      "20170918\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170919\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170920\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170921\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170922\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20170925\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.597\n",
      "Acc: 59.73%\n",
      "Precision: 0.36\n",
      "Recall: 0.60\n",
      "F1 score weighted: 0.45\n",
      "F1 score macro: 0.25\n",
      "F1 score micro: 0.60\n",
      "Hamming Loss Value: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.248\n",
      "Acc: 24.81%\n",
      "Precision: 0.51\n",
      "Recall: 0.25\n",
      "F1 score weighted: 0.20\n",
      "F1 score macro: 0.24\n",
      "F1 score micro: 0.25\n",
      "Hamming Loss Value: 0.75\n",
      "20170929\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "20180301\n",
      "Memory usage at Before garbage collect is 1101.0662399999999mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.870\n",
      "Acc: 86.96%\n",
      "Precision: 0.76\n",
      "Recall: 0.87\n",
      "F1 score weighted: 0.81\n",
      "F1 score macro: 0.31\n",
      "F1 score micro: 0.87\n",
      "Hamming Loss Value: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.665\n",
      "Acc: 66.49%\n",
      "Precision: 0.78\n",
      "Recall: 0.66\n",
      "F1 score weighted: 0.71\n",
      "F1 score macro: 0.35\n",
      "F1 score micro: 0.66\n",
      "Hamming Loss Value: 0.34\n",
      "20180302\n",
      "Memory usage at Before garbage collect is 1129.71776mb.\n",
      "sorted out test dates bit done\n",
      "Accuracy score: 0.756\n",
      "Acc: 75.63%\n",
      "Precision: 0.57\n",
      "Recall: 0.76\n",
      "F1 score weighted: 0.65\n",
      "F1 score macro: 0.29\n",
      "F1 score micro: 0.76\n",
      "Hamming Loss Value: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/mklpyresearch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.520\n",
      "Acc: 52.01%\n",
      "Precision: 0.63\n",
      "Recall: 0.52\n",
      "F1 score weighted: 0.56\n",
      "F1 score macro: 0.34\n",
      "F1 score micro: 0.52\n",
      "Hamming Loss Value: 0.48\n",
      "20180404\n",
      "Memory usage at Before garbage collect is 1129.71776mb.\n",
      "sorted out test dates bit done\n",
      "20180412\n",
      "Memory usage at Before garbage collect is 1129.71776mb.\n",
      "sorted out test dates bit done\n",
      "20180420\n",
      "Memory usage at Before garbage collect is 1129.71776mb.\n",
      "sorted out test dates bit done\n",
      "it took 0.05754351615905762 seconds!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for symbol in ['RSA.L']:\n",
    "    clean_data_location = storage_location(symbol)\n",
    "    print(symbol)\n",
    "    # model dates list\n",
    "    model_dates = model_dates_list(return_cross_val_symbol_path(symbol))\n",
    "    # location of data -->dataDrive, Clean Data Storage, and label.\n",
    "    pkl_file = load_pickled_in_filename(\n",
    "        os.path.join(clean_data_location, os.listdir(clean_data_location)[alternate_label_idx]))\n",
    "    date_keys = list(pkl_file.keys())\n",
    "    # list of out of sample dates\n",
    "    results_dict = defaultdict(dict)\n",
    "    for model_idx, model_date in enumerate(model_dates):\n",
    "        \n",
    "        #dictionaries to store everything\n",
    "        \n",
    "\n",
    "        \n",
    "        print(model_idx)\n",
    "        \n",
    "        forward_dates = nalsvm.forwardDates(date_keys, model_date)\n",
    "\n",
    "        print('---------------> Doing Model Date:', model_date)\n",
    "        try:\n",
    "            mkl_dict = collections.defaultdict(dict)\n",
    "            average_dict = collections.defaultdict(dict)\n",
    "            # put the features in a tensor format\n",
    "            Xtr = normalization(rescale_01(torch.Tensor(pkl_file[model_date][0].values)))  # fitting model\n",
    "            # put the labels in a tensor format\n",
    "            Ytr = torch.Tensor(pkl_file[model_date][1].values)\n",
    "            print('first bit done')\n",
    "            # force garbage collect\n",
    "            nalsvm.gc.collect()\n",
    "            # kernels\n",
    "            KLrbf = generators.RBF_generator(Xtr, gamma=[.001, .01, .1])\n",
    "            # dont need the next bit\n",
    "            print('done with kernel')\n",
    "            print(forward_dates)\n",
    "            # base learner- use c =1 or 10\n",
    "            # the c and lambda values need to be picked up by the cross-val results !\n",
    "            base_learner = SVC(C=1)\n",
    "\n",
    "            clf = EasyMKL(lam=0.2, multiclass_strategy='ova', learner=base_learner).fit(KLrbf, Ytr)\n",
    "            # try ovo as\n",
    "            # well\n",
    "            mkl_avg = AverageMKL().fit(KLrbf, Ytr)\n",
    "            print('done')\n",
    "            print('the combination weights are:')\n",
    "            # this bit may be redundant here and we can put it somewhere else\n",
    "            for sol in clf.solution:\n",
    "                print('(%d vs all): ' % sol, clf.solution[sol].weights) #dont need this loop- can make it redundant in another file\n",
    "                print(len(forward_dates))\n",
    "\n",
    "                for date in forward_dates:\n",
    "                    print(date)\n",
    "                    start = time.time()\n",
    "                    nalsvm.logmemoryusage(\"Before garbage collect\")\n",
    "                    Xte = normalization(rescale_01(torch.Tensor(pkl_file[date][0].values)))\n",
    "                    Yte = torch.Tensor(pkl_file[date][1].values)\n",
    "                    try:\n",
    "                        KLte = generators.RBF_generator(Xte, gamma=[.001, .01, .1])\n",
    "                        print('sorted out test dates bit done')\n",
    "                        nalsvm.gc.collect()\n",
    "                        y_pred = clf.predict(KLte)  # predictions\n",
    "                        y_score = clf.decision_function(KLte)  # rank\n",
    "                        # oos_svc_predictions = defaultdict(dict)\n",
    "                        accuracy = accuracy_score(Yte, y_pred)\n",
    "                        accuracy_file_name = \"_\".join((symbol, model_date, date,alternate_label,'OOSResult.pkl'))\n",
    "                        print('Accuracy score: %.3f' % accuracy)\n",
    "                        mkl_dict[str(date)] = evaluate_predictions(Yte, y_pred)\n",
    "\n",
    "#                         # average kernel as a base line\n",
    "\n",
    "                        y_preds_average = mkl_avg.predict(KLte)  # predict the output class\n",
    "                        y_scores_average = mkl_avg.decision_function(KLte)  # returns the projection on the distance vector\n",
    "                        average_accuracy = accuracy_score(Yte, y_preds_average)\n",
    "                        print ('Accuracy score: %.3f' % average_accuracy)\n",
    "                        average_dict[str(date)] = evaluate_predictions(Yte, y_preds_average)\n",
    "                    except (ValueError, TypeError, EOFError, IndexError):\n",
    "                        continue\n",
    "\n",
    "        except (ValueError, TypeError, EOFError, IndexError):\n",
    "            print('problem in :', )\n",
    "            # at some point for clarity we need to clean these error up.\n",
    "            continue\n",
    "            nalsvm.gc.collect()\n",
    "            print('done too')\n",
    "        results_dict['MKL_Results'][str(model_date)] = mkl_dict\n",
    "        results_dict['AvgKL_Results'][str(model_date)] = average_dict\n",
    "        end = time.time()\n",
    "        print(f'it took {end - start} seconds!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'MKL_Results': {'20170706': defaultdict(dict,\n",
       "                          {'20170707': {'accuracy': 0.87,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.8,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170712': {'accuracy': 0.81,\n",
       "                            'precision': 0.65,\n",
       "                            'recall': 0.81,\n",
       "                            'f1- weighted': 0.72,\n",
       "                            'f1- micro': 0.81,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.19},\n",
       "                           '20170718': {'accuracy': 0.85,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170720': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170721': {'accuracy': 0.89,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170724': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170801': {'accuracy': 0.84,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.84,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.84,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.16},\n",
       "                           '20170802': {'accuracy': 0.66,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170803': {'accuracy': 0.77,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.77,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.77,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.23},\n",
       "                           '20170804': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.84,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170809': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170817': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170818': {'accuracy': 0.9,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.9,\n",
       "                            'f1- weighted': 0.85,\n",
       "                            'f1- micro': 0.9,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.1},\n",
       "                           '20170822': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170823': {'accuracy': 0.85,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170830': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170905': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170908': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170913': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170914': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170915': {'accuracy': 0.75,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.75,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.75,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.25},\n",
       "                           '20170918': {'accuracy': 0.79,\n",
       "                            'precision': 0.63,\n",
       "                            'recall': 0.79,\n",
       "                            'f1- weighted': 0.7,\n",
       "                            'f1- micro': 0.79,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.21},\n",
       "                           '20170919': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170921': {'accuracy': 0.56,\n",
       "                            'precision': 0.31,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.4,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170922': {'accuracy': 0.71,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.71,\n",
       "                            'f1- weighted': 0.59,\n",
       "                            'f1- micro': 0.71,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.29},\n",
       "                           '20170925': {'accuracy': 0.6,\n",
       "                            'precision': 0.36,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20170929': {'accuracy': 0.48,\n",
       "                            'precision': 0.23,\n",
       "                            'recall': 0.48,\n",
       "                            'f1- weighted': 0.31,\n",
       "                            'f1- micro': 0.48,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.52},\n",
       "                           '20180301': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20180302': {'accuracy': 0.76,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.76,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.76,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.24},\n",
       "                           '20180404': {'accuracy': 0.78,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.78,\n",
       "                            'f1- weighted': 0.68,\n",
       "                            'f1- micro': 0.78,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.22},\n",
       "                           '20180412': {'accuracy': 0.73,\n",
       "                            'precision': 0.53,\n",
       "                            'recall': 0.73,\n",
       "                            'f1- weighted': 0.61,\n",
       "                            'f1- micro': 0.73,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.27},\n",
       "                           '20180420': {'accuracy': 0.82,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.82,\n",
       "                            'f1- weighted': 0.73,\n",
       "                            'f1- micro': 0.82,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.18}}),\n",
       "              '20170707': defaultdict(dict,\n",
       "                          {'20170712': {'accuracy': 0.81,\n",
       "                            'precision': 0.65,\n",
       "                            'recall': 0.81,\n",
       "                            'f1- weighted': 0.72,\n",
       "                            'f1- micro': 0.81,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.19},\n",
       "                           '20170718': {'accuracy': 0.85,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170720': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170721': {'accuracy': 0.89,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170724': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170801': {'accuracy': 0.84,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.84,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.84,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.16},\n",
       "                           '20170802': {'accuracy': 0.66,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170803': {'accuracy': 0.77,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.77,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.77,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.23},\n",
       "                           '20170804': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.84,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170809': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170817': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170818': {'accuracy': 0.9,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.9,\n",
       "                            'f1- weighted': 0.85,\n",
       "                            'f1- micro': 0.9,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.1},\n",
       "                           '20170822': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170823': {'accuracy': 0.85,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170830': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170905': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170908': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170913': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170914': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170915': {'accuracy': 0.75,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.75,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.75,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.25},\n",
       "                           '20170918': {'accuracy': 0.79,\n",
       "                            'precision': 0.63,\n",
       "                            'recall': 0.79,\n",
       "                            'f1- weighted': 0.7,\n",
       "                            'f1- micro': 0.79,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.21},\n",
       "                           '20170919': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170921': {'accuracy': 0.56,\n",
       "                            'precision': 0.31,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.4,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170922': {'accuracy': 0.71,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.71,\n",
       "                            'f1- weighted': 0.59,\n",
       "                            'f1- micro': 0.71,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.29},\n",
       "                           '20170925': {'accuracy': 0.6,\n",
       "                            'precision': 0.36,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20170929': {'accuracy': 0.48,\n",
       "                            'precision': 0.23,\n",
       "                            'recall': 0.48,\n",
       "                            'f1- weighted': 0.31,\n",
       "                            'f1- micro': 0.48,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.52},\n",
       "                           '20180301': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20180302': {'accuracy': 0.76,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.76,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.76,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.24},\n",
       "                           '20180404': {'accuracy': 0.78,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.78,\n",
       "                            'f1- weighted': 0.68,\n",
       "                            'f1- micro': 0.78,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.22},\n",
       "                           '20180412': {'accuracy': 0.73,\n",
       "                            'precision': 0.53,\n",
       "                            'recall': 0.73,\n",
       "                            'f1- weighted': 0.61,\n",
       "                            'f1- micro': 0.73,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.27},\n",
       "                           '20180420': {'accuracy': 0.82,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.82,\n",
       "                            'f1- weighted': 0.73,\n",
       "                            'f1- micro': 0.82,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.18}}),\n",
       "              '20170712': defaultdict(dict,\n",
       "                          {'20170718': {'accuracy': 0.85,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170724': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170801': {'accuracy': 0.84,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.84,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.84,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.16},\n",
       "                           '20170802': {'accuracy': 0.66,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170803': {'accuracy': 0.77,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.77,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.77,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.23},\n",
       "                           '20170809': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170818': {'accuracy': 0.9,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.9,\n",
       "                            'f1- weighted': 0.85,\n",
       "                            'f1- micro': 0.9,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.1},\n",
       "                           '20170830': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170915': {'accuracy': 0.75,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.75,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.75,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.25},\n",
       "                           '20170921': {'accuracy': 0.56,\n",
       "                            'precision': 0.31,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.4,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170922': {'accuracy': 0.71,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.71,\n",
       "                            'f1- weighted': 0.59,\n",
       "                            'f1- micro': 0.71,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.29},\n",
       "                           '20170925': {'accuracy': 0.6,\n",
       "                            'precision': 0.36,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20180301': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20180302': {'accuracy': 0.76,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.76,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.76,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.24},\n",
       "                           '20180404': {'accuracy': 0.78,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.78,\n",
       "                            'f1- weighted': 0.68,\n",
       "                            'f1- micro': 0.78,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.22}}),\n",
       "              '20170717': defaultdict(dict,\n",
       "                          {'20170718': {'accuracy': 0.85,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170719': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170720': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170721': {'accuracy': 0.89,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170724': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170727': {'accuracy': 0.83,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170801': {'accuracy': 0.84,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.84,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.84,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.16},\n",
       "                           '20170802': {'accuracy': 0.66,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170803': {'accuracy': 0.77,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.77,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.77,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.23},\n",
       "                           '20170804': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.84,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170809': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20170814': {'accuracy': 0.92,\n",
       "                            'precision': 0.85,\n",
       "                            'recall': 0.92,\n",
       "                            'f1- weighted': 0.89,\n",
       "                            'f1- micro': 0.92,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.08},\n",
       "                           '20170816': {'accuracy': 0.85,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170817': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170818': {'accuracy': 0.9,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.9,\n",
       "                            'f1- weighted': 0.85,\n",
       "                            'f1- micro': 0.9,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.1},\n",
       "                           '20170822': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170823': {'accuracy': 0.85,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.85,\n",
       "                            'f1- weighted': 0.78,\n",
       "                            'f1- micro': 0.85,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.15},\n",
       "                           '20170824': {'accuracy': 0.82,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.82,\n",
       "                            'f1- weighted': 0.74,\n",
       "                            'f1- micro': 0.82,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.18},\n",
       "                           '20170830': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170901': {'accuracy': 0.83,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170905': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170908': {'accuracy': 0.89,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.89,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.89,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.11},\n",
       "                           '20170913': {'accuracy': 0.86,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.86,\n",
       "                            'f1- weighted': 0.79,\n",
       "                            'f1- micro': 0.86,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.14},\n",
       "                           '20170914': {'accuracy': 0.83,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.83,\n",
       "                            'f1- weighted': 0.75,\n",
       "                            'f1- micro': 0.83,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.17},\n",
       "                           '20170915': {'accuracy': 0.75,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.75,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.75,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.25},\n",
       "                           '20170918': {'accuracy': 0.79,\n",
       "                            'precision': 0.63,\n",
       "                            'recall': 0.79,\n",
       "                            'f1- weighted': 0.7,\n",
       "                            'f1- micro': 0.79,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.21},\n",
       "                           '20170919': {'accuracy': 0.88,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.83,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170921': {'accuracy': 0.56,\n",
       "                            'precision': 0.31,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.4,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170922': {'accuracy': 0.71,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.71,\n",
       "                            'f1- weighted': 0.59,\n",
       "                            'f1- micro': 0.71,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.29},\n",
       "                           '20170925': {'accuracy': 0.6,\n",
       "                            'precision': 0.36,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20170929': {'accuracy': 0.48,\n",
       "                            'precision': 0.23,\n",
       "                            'recall': 0.48,\n",
       "                            'f1- weighted': 0.31,\n",
       "                            'f1- micro': 0.48,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.52},\n",
       "                           '20180301': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20180302': {'accuracy': 0.76,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.76,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.76,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.24},\n",
       "                           '20180404': {'accuracy': 0.78,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.78,\n",
       "                            'f1- weighted': 0.68,\n",
       "                            'f1- micro': 0.78,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.22},\n",
       "                           '20180412': {'accuracy': 0.73,\n",
       "                            'precision': 0.53,\n",
       "                            'recall': 0.73,\n",
       "                            'f1- weighted': 0.61,\n",
       "                            'f1- micro': 0.73,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.27},\n",
       "                           '20180420': {'accuracy': 0.82,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.82,\n",
       "                            'f1- weighted': 0.73,\n",
       "                            'f1- micro': 0.82,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.18}}),\n",
       "              '20170718': defaultdict(dict,\n",
       "                          {'20170724': {'accuracy': 0.88,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.88,\n",
       "                            'f1- weighted': 0.82,\n",
       "                            'f1- micro': 0.88,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.12},\n",
       "                           '20170801': {'accuracy': 0.84,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.84,\n",
       "                            'f1- weighted': 0.76,\n",
       "                            'f1- micro': 0.84,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.16},\n",
       "                           '20170802': {'accuracy': 0.66,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170803': {'accuracy': 0.77,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.77,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.77,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.23},\n",
       "                           '20170818': {'accuracy': 0.9,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.9,\n",
       "                            'f1- weighted': 0.85,\n",
       "                            'f1- micro': 0.9,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.1},\n",
       "                           '20170915': {'accuracy': 0.75,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.75,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.75,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.25},\n",
       "                           '20170925': {'accuracy': 0.6,\n",
       "                            'precision': 0.36,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20180301': {'accuracy': 0.87,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.87,\n",
       "                            'f1- weighted': 0.81,\n",
       "                            'f1- micro': 0.87,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.13},\n",
       "                           '20180302': {'accuracy': 0.76,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.76,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.76,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.24}})},\n",
       "             'AvgKL_Results': {'20170706': defaultdict(dict,\n",
       "                          {'20170707': {'accuracy': 0.09,\n",
       "                            'precision': 0.71,\n",
       "                            'recall': 0.09,\n",
       "                            'f1- weighted': 0.06,\n",
       "                            'f1- micro': 0.09,\n",
       "                            'f1- macro': 0.09,\n",
       "                            'Hamming Loss': 0.91},\n",
       "                           '20170712': {'accuracy': 0.43,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.43,\n",
       "                            'f1- weighted': 0.51,\n",
       "                            'f1- micro': 0.43,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.57},\n",
       "                           '20170718': {'accuracy': 0.29,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.29,\n",
       "                            'f1- weighted': 0.37,\n",
       "                            'f1- micro': 0.29,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.71},\n",
       "                           '20170720': {'accuracy': 0.2,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.2,\n",
       "                            'f1- weighted': 0.27,\n",
       "                            'f1- micro': 0.2,\n",
       "                            'f1- macro': 0.16,\n",
       "                            'Hamming Loss': 0.8},\n",
       "                           '20170721': {'accuracy': 0.62,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.62,\n",
       "                            'f1- weighted': 0.69,\n",
       "                            'f1- micro': 0.62,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.38},\n",
       "                           '20170724': {'accuracy': 0.32,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.32,\n",
       "                            'f1- weighted': 0.42,\n",
       "                            'f1- micro': 0.32,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.68},\n",
       "                           '20170801': {'accuracy': 0.6,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20170802': {'accuracy': 0.52,\n",
       "                            'precision': 0.51,\n",
       "                            'recall': 0.52,\n",
       "                            'f1- weighted': 0.51,\n",
       "                            'f1- micro': 0.52,\n",
       "                            'f1- macro': 0.34,\n",
       "                            'Hamming Loss': 0.48},\n",
       "                           '20170803': {'accuracy': 0.24,\n",
       "                            'precision': 0.68,\n",
       "                            'recall': 0.24,\n",
       "                            'f1- weighted': 0.28,\n",
       "                            'f1- micro': 0.24,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.76},\n",
       "                           '20170804': {'accuracy': 0.45,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.45,\n",
       "                            'f1- weighted': 0.55,\n",
       "                            'f1- micro': 0.45,\n",
       "                            'f1- macro': 0.27,\n",
       "                            'Hamming Loss': 0.55},\n",
       "                           '20170809': {'accuracy': 0.57,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.57,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.57,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.43},\n",
       "                           '20170817': {'accuracy': 0.47,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.47,\n",
       "                            'f1- weighted': 0.55,\n",
       "                            'f1- micro': 0.47,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.53},\n",
       "                           '20170818': {'accuracy': 0.18,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.18,\n",
       "                            'f1- weighted': 0.26,\n",
       "                            'f1- micro': 0.18,\n",
       "                            'f1- macro': 0.13,\n",
       "                            'Hamming Loss': 0.82},\n",
       "                           '20170822': {'accuracy': 0.54,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.54,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.54,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.46},\n",
       "                           '20170823': {'accuracy': 0.36,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.36,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.36,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.64},\n",
       "                           '20170830': {'accuracy': 0.47,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.47,\n",
       "                            'f1- weighted': 0.58,\n",
       "                            'f1- micro': 0.47,\n",
       "                            'f1- macro': 0.27,\n",
       "                            'Hamming Loss': 0.53},\n",
       "                           '20170905': {'accuracy': 0.32,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.32,\n",
       "                            'f1- weighted': 0.41,\n",
       "                            'f1- micro': 0.32,\n",
       "                            'f1- macro': 0.2,\n",
       "                            'Hamming Loss': 0.68},\n",
       "                           '20170908': {'accuracy': 0.39,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.39,\n",
       "                            'f1- weighted': 0.5,\n",
       "                            'f1- micro': 0.39,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.61},\n",
       "                           '20170913': {'accuracy': 0.2,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.2,\n",
       "                            'f1- weighted': 0.22,\n",
       "                            'f1- micro': 0.2,\n",
       "                            'f1- macro': 0.19,\n",
       "                            'Hamming Loss': 0.8},\n",
       "                           '20170914': {'accuracy': 0.3,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.3,\n",
       "                            'f1- weighted': 0.36,\n",
       "                            'f1- micro': 0.3,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.7},\n",
       "                           '20170915': {'accuracy': 0.12,\n",
       "                            'precision': 0.47,\n",
       "                            'recall': 0.12,\n",
       "                            'f1- weighted': 0.06,\n",
       "                            'f1- micro': 0.12,\n",
       "                            'f1- macro': 0.14,\n",
       "                            'Hamming Loss': 0.88},\n",
       "                           '20170918': {'accuracy': 0.35,\n",
       "                            'precision': 0.66,\n",
       "                            'recall': 0.35,\n",
       "                            'f1- weighted': 0.42,\n",
       "                            'f1- micro': 0.35,\n",
       "                            'f1- macro': 0.27,\n",
       "                            'Hamming Loss': 0.65},\n",
       "                           '20170919': {'accuracy': 0.21,\n",
       "                            'precision': 0.83,\n",
       "                            'recall': 0.21,\n",
       "                            'f1- weighted': 0.27,\n",
       "                            'f1- micro': 0.21,\n",
       "                            'f1- macro': 0.15,\n",
       "                            'Hamming Loss': 0.79},\n",
       "                           '20170921': {'accuracy': 0.38,\n",
       "                            'precision': 0.42,\n",
       "                            'recall': 0.38,\n",
       "                            'f1- weighted': 0.39,\n",
       "                            'f1- micro': 0.38,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.62},\n",
       "                           '20170922': {'accuracy': 0.25,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.3,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20170925': {'accuracy': 0.51,\n",
       "                            'precision': 0.42,\n",
       "                            'recall': 0.51,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.51,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.49},\n",
       "                           '20170929': {'accuracy': 0.39,\n",
       "                            'precision': 0.38,\n",
       "                            'recall': 0.39,\n",
       "                            'f1- weighted': 0.37,\n",
       "                            'f1- micro': 0.39,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.61},\n",
       "                           '20180301': {'accuracy': 0.31,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.31,\n",
       "                            'f1- weighted': 0.41,\n",
       "                            'f1- micro': 0.31,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.69},\n",
       "                           '20180302': {'accuracy': 0.13,\n",
       "                            'precision': 0.03,\n",
       "                            'recall': 0.13,\n",
       "                            'f1- weighted': 0.05,\n",
       "                            'f1- micro': 0.13,\n",
       "                            'f1- macro': 0.14,\n",
       "                            'Hamming Loss': 0.87},\n",
       "                           '20180404': {'accuracy': 0.22,\n",
       "                            'precision': 0.59,\n",
       "                            'recall': 0.22,\n",
       "                            'f1- weighted': 0.23,\n",
       "                            'f1- micro': 0.22,\n",
       "                            'f1- macro': 0.2,\n",
       "                            'Hamming Loss': 0.78},\n",
       "                           '20180412': {'accuracy': 0.58,\n",
       "                            'precision': 0.55,\n",
       "                            'recall': 0.58,\n",
       "                            'f1- weighted': 0.56,\n",
       "                            'f1- micro': 0.58,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.42},\n",
       "                           '20180420': {'accuracy': 0.46,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.46,\n",
       "                            'f1- weighted': 0.53,\n",
       "                            'f1- micro': 0.46,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.54}}),\n",
       "              '20170707': defaultdict(dict,\n",
       "                          {'20170712': {'accuracy': 0.64,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.64,\n",
       "                            'f1- weighted': 0.65,\n",
       "                            'f1- micro': 0.64,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.36},\n",
       "                           '20170718': {'accuracy': 0.35,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.35,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.35,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.65},\n",
       "                           '20170720': {'accuracy': 0.66,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.71,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.35,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170721': {'accuracy': 0.6,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.6,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.6,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.4},\n",
       "                           '20170724': {'accuracy': 0.25,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.34,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.17,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20170801': {'accuracy': 0.42,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.42,\n",
       "                            'f1- weighted': 0.51,\n",
       "                            'f1- micro': 0.42,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.58},\n",
       "                           '20170802': {'accuracy': 0.26,\n",
       "                            'precision': 0.45,\n",
       "                            'recall': 0.26,\n",
       "                            'f1- weighted': 0.24,\n",
       "                            'f1- micro': 0.26,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.74},\n",
       "                           '20170803': {'accuracy': 0.25,\n",
       "                            'precision': 0.59,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.29,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20170804': {'accuracy': 0.47,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.47,\n",
       "                            'f1- weighted': 0.58,\n",
       "                            'f1- micro': 0.47,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.53},\n",
       "                           '20170809': {'accuracy': 0.33,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.33,\n",
       "                            'f1- weighted': 0.43,\n",
       "                            'f1- micro': 0.33,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.67},\n",
       "                           '20170817': {'accuracy': 0.23,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.23,\n",
       "                            'f1- weighted': 0.29,\n",
       "                            'f1- micro': 0.23,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.77},\n",
       "                           '20170818': {'accuracy': 0.28,\n",
       "                            'precision': 0.83,\n",
       "                            'recall': 0.28,\n",
       "                            'f1- weighted': 0.38,\n",
       "                            'f1- micro': 0.28,\n",
       "                            'f1- macro': 0.17,\n",
       "                            'Hamming Loss': 0.72},\n",
       "                           '20170822': {'accuracy': 0.37,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.37,\n",
       "                            'f1- weighted': 0.48,\n",
       "                            'f1- micro': 0.37,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.63},\n",
       "                           '20170823': {'accuracy': 0.21,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.21,\n",
       "                            'f1- weighted': 0.28,\n",
       "                            'f1- micro': 0.21,\n",
       "                            'f1- macro': 0.16,\n",
       "                            'Hamming Loss': 0.79},\n",
       "                           '20170830': {'accuracy': 0.14,\n",
       "                            'precision': 0.82,\n",
       "                            'recall': 0.14,\n",
       "                            'f1- weighted': 0.15,\n",
       "                            'f1- micro': 0.14,\n",
       "                            'f1- macro': 0.12,\n",
       "                            'Hamming Loss': 0.86},\n",
       "                           '20170905': {'accuracy': 0.57,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.57,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.57,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.43},\n",
       "                           '20170908': {'accuracy': 0.18,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.18,\n",
       "                            'f1- weighted': 0.25,\n",
       "                            'f1- micro': 0.18,\n",
       "                            'f1- macro': 0.15,\n",
       "                            'Hamming Loss': 0.82},\n",
       "                           '20170913': {'accuracy': 0.52,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.52,\n",
       "                            'f1- weighted': 0.6,\n",
       "                            'f1- micro': 0.52,\n",
       "                            'f1- macro': 0.27,\n",
       "                            'Hamming Loss': 0.48},\n",
       "                           '20170914': {'accuracy': 0.53,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.53,\n",
       "                            'f1- weighted': 0.58,\n",
       "                            'f1- micro': 0.53,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.47},\n",
       "                           '20170915': {'accuracy': 0.34,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.34,\n",
       "                            'f1- weighted': 0.39,\n",
       "                            'f1- micro': 0.34,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.66},\n",
       "                           '20170918': {'accuracy': 0.34,\n",
       "                            'precision': 0.66,\n",
       "                            'recall': 0.34,\n",
       "                            'f1- weighted': 0.42,\n",
       "                            'f1- micro': 0.34,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.66},\n",
       "                           '20170919': {'accuracy': 0.36,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.36,\n",
       "                            'f1- weighted': 0.47,\n",
       "                            'f1- micro': 0.36,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.64},\n",
       "                           '20170921': {'accuracy': 0.5,\n",
       "                            'precision': 0.42,\n",
       "                            'recall': 0.5,\n",
       "                            'f1- weighted': 0.42,\n",
       "                            'f1- micro': 0.5,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.5},\n",
       "                           '20170922': {'accuracy': 0.5,\n",
       "                            'precision': 0.58,\n",
       "                            'recall': 0.5,\n",
       "                            'f1- weighted': 0.53,\n",
       "                            'f1- micro': 0.5,\n",
       "                            'f1- macro': 0.36,\n",
       "                            'Hamming Loss': 0.5},\n",
       "                           '20170925': {'accuracy': 0.28,\n",
       "                            'precision': 0.37,\n",
       "                            'recall': 0.28,\n",
       "                            'f1- weighted': 0.25,\n",
       "                            'f1- micro': 0.28,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.72},\n",
       "                           '20170929': {'accuracy': 0.26,\n",
       "                            'precision': 0.33,\n",
       "                            'recall': 0.26,\n",
       "                            'f1- weighted': 0.21,\n",
       "                            'f1- micro': 0.26,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.74},\n",
       "                           '20180301': {'accuracy': 0.52,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.52,\n",
       "                            'f1- weighted': 0.61,\n",
       "                            'f1- micro': 0.52,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.48},\n",
       "                           '20180302': {'accuracy': 0.29,\n",
       "                            'precision': 0.59,\n",
       "                            'recall': 0.29,\n",
       "                            'f1- weighted': 0.34,\n",
       "                            'f1- micro': 0.29,\n",
       "                            'f1- macro': 0.23,\n",
       "                            'Hamming Loss': 0.71},\n",
       "                           '20180404': {'accuracy': 0.57,\n",
       "                            'precision': 0.64,\n",
       "                            'recall': 0.57,\n",
       "                            'f1- weighted': 0.59,\n",
       "                            'f1- micro': 0.57,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.43},\n",
       "                           '20180412': {'accuracy': 0.19,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.19,\n",
       "                            'f1- weighted': 0.15,\n",
       "                            'f1- micro': 0.19,\n",
       "                            'f1- macro': 0.18,\n",
       "                            'Hamming Loss': 0.81},\n",
       "                           '20180420': {'accuracy': 0.11,\n",
       "                            'precision': 0.66,\n",
       "                            'recall': 0.11,\n",
       "                            'f1- weighted': 0.08,\n",
       "                            'f1- micro': 0.11,\n",
       "                            'f1- macro': 0.12,\n",
       "                            'Hamming Loss': 0.89}}),\n",
       "              '20170712': defaultdict(dict,\n",
       "                          {'20170718': {'accuracy': 0.63,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.63,\n",
       "                            'f1- weighted': 0.68,\n",
       "                            'f1- micro': 0.63,\n",
       "                            'f1- macro': 0.34,\n",
       "                            'Hamming Loss': 0.37},\n",
       "                           '20170724': {'accuracy': 0.38,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.38,\n",
       "                            'f1- weighted': 0.48,\n",
       "                            'f1- micro': 0.38,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.62},\n",
       "                           '20170801': {'accuracy': 0.37,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.37,\n",
       "                            'f1- weighted': 0.45,\n",
       "                            'f1- micro': 0.37,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.63},\n",
       "                           '20170802': {'accuracy': 0.28,\n",
       "                            'precision': 0.5,\n",
       "                            'recall': 0.28,\n",
       "                            'f1- weighted': 0.31,\n",
       "                            'f1- micro': 0.28,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.72},\n",
       "                           '20170803': {'accuracy': 0.18,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.18,\n",
       "                            'f1- weighted': 0.19,\n",
       "                            'f1- micro': 0.18,\n",
       "                            'f1- macro': 0.18,\n",
       "                            'Hamming Loss': 0.82},\n",
       "                           '20170809': {'accuracy': 0.66,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.7,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20170818': {'accuracy': 0.19,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.19,\n",
       "                            'f1- weighted': 0.27,\n",
       "                            'f1- micro': 0.19,\n",
       "                            'f1- macro': 0.15,\n",
       "                            'Hamming Loss': 0.81},\n",
       "                           '20170830': {'accuracy': 0.59,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.59,\n",
       "                            'f1- weighted': 0.67,\n",
       "                            'f1- micro': 0.59,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.41},\n",
       "                           '20170915': {'accuracy': 0.56,\n",
       "                            'precision': 0.62,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.58,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170921': {'accuracy': 0.49,\n",
       "                            'precision': 0.37,\n",
       "                            'recall': 0.49,\n",
       "                            'f1- weighted': 0.42,\n",
       "                            'f1- micro': 0.49,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.51},\n",
       "                           '20170922': {'accuracy': 0.47,\n",
       "                            'precision': 0.59,\n",
       "                            'recall': 0.47,\n",
       "                            'f1- weighted': 0.49,\n",
       "                            'f1- micro': 0.47,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.53},\n",
       "                           '20170925': {'accuracy': 0.28,\n",
       "                            'precision': 0.41,\n",
       "                            'recall': 0.28,\n",
       "                            'f1- weighted': 0.28,\n",
       "                            'f1- micro': 0.28,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.72},\n",
       "                           '20180301': {'accuracy': 0.28,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.28,\n",
       "                            'f1- weighted': 0.38,\n",
       "                            'f1- micro': 0.28,\n",
       "                            'f1- macro': 0.19,\n",
       "                            'Hamming Loss': 0.72},\n",
       "                           '20180302': {'accuracy': 0.42,\n",
       "                            'precision': 0.61,\n",
       "                            'recall': 0.42,\n",
       "                            'f1- weighted': 0.47,\n",
       "                            'f1- micro': 0.42,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.58},\n",
       "                           '20180404': {'accuracy': 0.64,\n",
       "                            'precision': 0.64,\n",
       "                            'recall': 0.64,\n",
       "                            'f1- weighted': 0.64,\n",
       "                            'f1- micro': 0.64,\n",
       "                            'f1- macro': 0.36,\n",
       "                            'Hamming Loss': 0.36}}),\n",
       "              '20170717': defaultdict(dict,\n",
       "                          {'20170718': {'accuracy': 0.25,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.32,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20170719': {'accuracy': 0.39,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.39,\n",
       "                            'f1- weighted': 0.5,\n",
       "                            'f1- micro': 0.39,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.61},\n",
       "                           '20170720': {'accuracy': 0.53,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.53,\n",
       "                            'f1- weighted': 0.61,\n",
       "                            'f1- micro': 0.53,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.47},\n",
       "                           '20170721': {'accuracy': 0.36,\n",
       "                            'precision': 0.79,\n",
       "                            'recall': 0.36,\n",
       "                            'f1- weighted': 0.46,\n",
       "                            'f1- micro': 0.36,\n",
       "                            'f1- macro': 0.23,\n",
       "                            'Hamming Loss': 0.64},\n",
       "                           '20170724': {'accuracy': 0.49,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.49,\n",
       "                            'f1- weighted': 0.58,\n",
       "                            'f1- micro': 0.49,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.51},\n",
       "                           '20170727': {'accuracy': 0.35,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.35,\n",
       "                            'f1- weighted': 0.44,\n",
       "                            'f1- micro': 0.35,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.65},\n",
       "                           '20170801': {'accuracy': 0.5,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.5,\n",
       "                            'f1- weighted': 0.57,\n",
       "                            'f1- micro': 0.5,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.5},\n",
       "                           '20170802': {'accuracy': 0.56,\n",
       "                            'precision': 0.51,\n",
       "                            'recall': 0.56,\n",
       "                            'f1- weighted': 0.52,\n",
       "                            'f1- micro': 0.56,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.44},\n",
       "                           '20170803': {'accuracy': 0.52,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.52,\n",
       "                            'f1- weighted': 0.55,\n",
       "                            'f1- micro': 0.52,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.48},\n",
       "                           '20170804': {'accuracy': 0.27,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.27,\n",
       "                            'f1- weighted': 0.37,\n",
       "                            'f1- micro': 0.27,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.73},\n",
       "                           '20170809': {'accuracy': 0.58,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.58,\n",
       "                            'f1- weighted': 0.66,\n",
       "                            'f1- micro': 0.58,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.42},\n",
       "                           '20170814': {'accuracy': 0.34,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.34,\n",
       "                            'f1- weighted': 0.46,\n",
       "                            'f1- micro': 0.34,\n",
       "                            'f1- macro': 0.2,\n",
       "                            'Hamming Loss': 0.66},\n",
       "                           '20170816': {'accuracy': 0.53,\n",
       "                            'precision': 0.75,\n",
       "                            'recall': 0.53,\n",
       "                            'f1- weighted': 0.6,\n",
       "                            'f1- micro': 0.53,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.47},\n",
       "                           '20170817': {'accuracy': 0.46,\n",
       "                            'precision': 0.71,\n",
       "                            'recall': 0.46,\n",
       "                            'f1- weighted': 0.54,\n",
       "                            'f1- micro': 0.46,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.54},\n",
       "                           '20170818': {'accuracy': 0.08,\n",
       "                            'precision': 0.86,\n",
       "                            'recall': 0.08,\n",
       "                            'f1- weighted': 0.05,\n",
       "                            'f1- micro': 0.08,\n",
       "                            'f1- macro': 0.09,\n",
       "                            'Hamming Loss': 0.92},\n",
       "                           '20170822': {'accuracy': 0.22,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.22,\n",
       "                            'f1- weighted': 0.3,\n",
       "                            'f1- micro': 0.22,\n",
       "                            'f1- macro': 0.18,\n",
       "                            'Hamming Loss': 0.78},\n",
       "                           '20170823': {'accuracy': 0.26,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.26,\n",
       "                            'f1- weighted': 0.34,\n",
       "                            'f1- micro': 0.26,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.74},\n",
       "                           '20170824': {'accuracy': 0.42,\n",
       "                            'precision': 0.72,\n",
       "                            'recall': 0.42,\n",
       "                            'f1- weighted': 0.5,\n",
       "                            'f1- micro': 0.42,\n",
       "                            'f1- macro': 0.28,\n",
       "                            'Hamming Loss': 0.58},\n",
       "                           '20170830': {'accuracy': 0.29,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.29,\n",
       "                            'f1- weighted': 0.37,\n",
       "                            'f1- micro': 0.29,\n",
       "                            'f1- macro': 0.18,\n",
       "                            'Hamming Loss': 0.71},\n",
       "                           '20170901': {'accuracy': 0.46,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.46,\n",
       "                            'f1- weighted': 0.54,\n",
       "                            'f1- micro': 0.46,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.54},\n",
       "                           '20170905': {'accuracy': 0.39,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.39,\n",
       "                            'f1- weighted': 0.49,\n",
       "                            'f1- micro': 0.39,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.61},\n",
       "                           '20170908': {'accuracy': 0.36,\n",
       "                            'precision': 0.81,\n",
       "                            'recall': 0.36,\n",
       "                            'f1- weighted': 0.47,\n",
       "                            'f1- micro': 0.36,\n",
       "                            'f1- macro': 0.25,\n",
       "                            'Hamming Loss': 0.64},\n",
       "                           '20170913': {'accuracy': 0.55,\n",
       "                            'precision': 0.74,\n",
       "                            'recall': 0.55,\n",
       "                            'f1- weighted': 0.62,\n",
       "                            'f1- micro': 0.55,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.45},\n",
       "                           '20170914': {'accuracy': 0.14,\n",
       "                            'precision': 0.73,\n",
       "                            'recall': 0.14,\n",
       "                            'f1- weighted': 0.16,\n",
       "                            'f1- micro': 0.14,\n",
       "                            'f1- macro': 0.13,\n",
       "                            'Hamming Loss': 0.86},\n",
       "                           '20170915': {'accuracy': 0.38,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.38,\n",
       "                            'f1- weighted': 0.44,\n",
       "                            'f1- micro': 0.38,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.62},\n",
       "                           '20170918': {'accuracy': 0.42,\n",
       "                            'precision': 0.67,\n",
       "                            'recall': 0.42,\n",
       "                            'f1- weighted': 0.49,\n",
       "                            'f1- micro': 0.42,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.58},\n",
       "                           '20170919': {'accuracy': 0.63,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.63,\n",
       "                            'f1- weighted': 0.7,\n",
       "                            'f1- micro': 0.63,\n",
       "                            'f1- macro': 0.29,\n",
       "                            'Hamming Loss': 0.37},\n",
       "                           '20170921': {'accuracy': 0.41,\n",
       "                            'precision': 0.43,\n",
       "                            'recall': 0.41,\n",
       "                            'f1- weighted': 0.4,\n",
       "                            'f1- micro': 0.41,\n",
       "                            'f1- macro': 0.32,\n",
       "                            'Hamming Loss': 0.59},\n",
       "                           '20170922': {'accuracy': 0.3,\n",
       "                            'precision': 0.57,\n",
       "                            'recall': 0.3,\n",
       "                            'f1- weighted': 0.33,\n",
       "                            'f1- micro': 0.3,\n",
       "                            'f1- macro': 0.21,\n",
       "                            'Hamming Loss': 0.7},\n",
       "                           '20170925': {'accuracy': 0.23,\n",
       "                            'precision': 0.56,\n",
       "                            'recall': 0.23,\n",
       "                            'f1- weighted': 0.17,\n",
       "                            'f1- micro': 0.23,\n",
       "                            'f1- macro': 0.19,\n",
       "                            'Hamming Loss': 0.77},\n",
       "                           '20170929': {'accuracy': 0.39,\n",
       "                            'precision': 0.35,\n",
       "                            'recall': 0.39,\n",
       "                            'f1- weighted': 0.36,\n",
       "                            'f1- micro': 0.39,\n",
       "                            'f1- macro': 0.31,\n",
       "                            'Hamming Loss': 0.61},\n",
       "                           '20180301': {'accuracy': 0.21,\n",
       "                            'precision': 0.76,\n",
       "                            'recall': 0.21,\n",
       "                            'f1- weighted': 0.29,\n",
       "                            'f1- micro': 0.21,\n",
       "                            'f1- macro': 0.16,\n",
       "                            'Hamming Loss': 0.79},\n",
       "                           '20180302': {'accuracy': 0.44,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.44,\n",
       "                            'f1- weighted': 0.48,\n",
       "                            'f1- micro': 0.44,\n",
       "                            'f1- macro': 0.27,\n",
       "                            'Hamming Loss': 0.56},\n",
       "                           '20180404': {'accuracy': 0.25,\n",
       "                            'precision': 0.59,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.28,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.19,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20180412': {'accuracy': 0.68,\n",
       "                            'precision': 0.54,\n",
       "                            'recall': 0.68,\n",
       "                            'f1- weighted': 0.6,\n",
       "                            'f1- micro': 0.68,\n",
       "                            'f1- macro': 0.3,\n",
       "                            'Hamming Loss': 0.32},\n",
       "                           '20180420': {'accuracy': 0.58,\n",
       "                            'precision': 0.69,\n",
       "                            'recall': 0.58,\n",
       "                            'f1- weighted': 0.63,\n",
       "                            'f1- micro': 0.58,\n",
       "                            'f1- macro': 0.33,\n",
       "                            'Hamming Loss': 0.42}}),\n",
       "              '20170718': defaultdict(dict,\n",
       "                          {'20170724': {'accuracy': 0.33,\n",
       "                            'precision': 0.77,\n",
       "                            'recall': 0.33,\n",
       "                            'f1- weighted': 0.43,\n",
       "                            'f1- micro': 0.33,\n",
       "                            'f1- macro': 0.23,\n",
       "                            'Hamming Loss': 0.67},\n",
       "                           '20170801': {'accuracy': 0.5,\n",
       "                            'precision': 0.7,\n",
       "                            'recall': 0.5,\n",
       "                            'f1- weighted': 0.57,\n",
       "                            'f1- micro': 0.5,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.5},\n",
       "                           '20170802': {'accuracy': 0.26,\n",
       "                            'precision': 0.54,\n",
       "                            'recall': 0.26,\n",
       "                            'f1- weighted': 0.28,\n",
       "                            'f1- micro': 0.26,\n",
       "                            'f1- macro': 0.26,\n",
       "                            'Hamming Loss': 0.74},\n",
       "                           '20170803': {'accuracy': 0.25,\n",
       "                            'precision': 0.6,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.29,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.23,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20170818': {'accuracy': 0.37,\n",
       "                            'precision': 0.8,\n",
       "                            'recall': 0.37,\n",
       "                            'f1- weighted': 0.5,\n",
       "                            'f1- micro': 0.37,\n",
       "                            'f1- macro': 0.22,\n",
       "                            'Hamming Loss': 0.63},\n",
       "                           '20170915': {'accuracy': 0.19,\n",
       "                            'precision': 0.63,\n",
       "                            'recall': 0.19,\n",
       "                            'f1- weighted': 0.2,\n",
       "                            'f1- micro': 0.19,\n",
       "                            'f1- macro': 0.2,\n",
       "                            'Hamming Loss': 0.81},\n",
       "                           '20170925': {'accuracy': 0.25,\n",
       "                            'precision': 0.51,\n",
       "                            'recall': 0.25,\n",
       "                            'f1- weighted': 0.2,\n",
       "                            'f1- micro': 0.25,\n",
       "                            'f1- macro': 0.24,\n",
       "                            'Hamming Loss': 0.75},\n",
       "                           '20180301': {'accuracy': 0.66,\n",
       "                            'precision': 0.78,\n",
       "                            'recall': 0.66,\n",
       "                            'f1- weighted': 0.71,\n",
       "                            'f1- micro': 0.66,\n",
       "                            'f1- macro': 0.35,\n",
       "                            'Hamming Loss': 0.34},\n",
       "                           '20180302': {'accuracy': 0.52,\n",
       "                            'precision': 0.63,\n",
       "                            'recall': 0.52,\n",
       "                            'f1- weighted': 0.56,\n",
       "                            'f1- micro': 0.52,\n",
       "                            'f1- macro': 0.34,\n",
       "                            'Hamming Loss': 0.48}})}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys =list(results_dict)\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_keys = list(results_dict['20170706'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_keys =list(results_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL.L', 'ECM.L', 'RDSa.L', 'RSA.L', 'SHP.L', 'STAN.L']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/media/ak/My Passport/Data/FinDataReal/JointLocationsAlternateDataClean/CV_Results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ef98988bf6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results_dict[results_keys[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame.from_dict(value) for key, value in results_dict.items()], axis=0, keys=results_dict.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('MKL_Results', '20170707'), ('MKL_Results', '20170712'),\n",
       "       ('MKL_Results', '20170718'), ('MKL_Results', '20170720'),\n",
       "       ('MKL_Results', '20170721'), ('MKL_Results', '20170724'),\n",
       "       ('MKL_Results', '20170801'), ('MKL_Results', '20170802'),\n",
       "       ('MKL_Results', '20170803'), ('MKL_Results', '20170804'),\n",
       "       ('MKL_Results', '20170809'), ('MKL_Results', '20170817'),\n",
       "       ('MKL_Results', '20170818'), ('MKL_Results', '20170822'),\n",
       "       ('MKL_Results', '20170823'), ('MKL_Results', '20170830'),\n",
       "       ('MKL_Results', '20170905'), ('MKL_Results', '20170908'),\n",
       "       ('MKL_Results', '20170913'), ('MKL_Results', '20170914'),\n",
       "       ('MKL_Results', '20170915'), ('MKL_Results', '20170918'),\n",
       "       ('MKL_Results', '20170919'), ('MKL_Results', '20170921'),\n",
       "       ('MKL_Results', '20170922'), ('MKL_Results', '20170925'),\n",
       "       ('MKL_Results', '20170929'), ('MKL_Results', '20180301'),\n",
       "       ('MKL_Results', '20180302'), ('MKL_Results', '20180404'),\n",
       "       ('MKL_Results', '20180412'), ('MKL_Results', '20180420'),\n",
       "       ('MKL_Results', '20170719'), ('MKL_Results', '20170727'),\n",
       "       ('MKL_Results', '20170814'), ('MKL_Results', '20170816'),\n",
       "       ('MKL_Results', '20170824'), ('MKL_Results', '20170901'),\n",
       "       ('AvgKL_Results', '20170707'), ('AvgKL_Results', '20170712'),\n",
       "       ('AvgKL_Results', '20170718'), ('AvgKL_Results', '20170720'),\n",
       "       ('AvgKL_Results', '20170721'), ('AvgKL_Results', '20170724'),\n",
       "       ('AvgKL_Results', '20170801'), ('AvgKL_Results', '20170802'),\n",
       "       ('AvgKL_Results', '20170803'), ('AvgKL_Results', '20170804'),\n",
       "       ('AvgKL_Results', '20170809'), ('AvgKL_Results', '20170817'),\n",
       "       ('AvgKL_Results', '20170818'), ('AvgKL_Results', '20170822'),\n",
       "       ('AvgKL_Results', '20170823'), ('AvgKL_Results', '20170830'),\n",
       "       ('AvgKL_Results', '20170905'), ('AvgKL_Results', '20170908'),\n",
       "       ('AvgKL_Results', '20170913'), ('AvgKL_Results', '20170914'),\n",
       "       ('AvgKL_Results', '20170915'), ('AvgKL_Results', '20170918'),\n",
       "       ('AvgKL_Results', '20170919'), ('AvgKL_Results', '20170921'),\n",
       "       ('AvgKL_Results', '20170922'), ('AvgKL_Results', '20170925'),\n",
       "       ('AvgKL_Results', '20170929'), ('AvgKL_Results', '20180301'),\n",
       "       ('AvgKL_Results', '20180302'), ('AvgKL_Results', '20180404'),\n",
       "       ('AvgKL_Results', '20180412'), ('AvgKL_Results', '20180420'),\n",
       "       ('AvgKL_Results', '20170719'), ('AvgKL_Results', '20170727'),\n",
       "       ('AvgKL_Results', '20170814'), ('AvgKL_Results', '20170816'),\n",
       "       ('AvgKL_Results', '20170824'), ('AvgKL_Results', '20170901')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'symbol_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a9055020ce84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'symbol_results' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(symbol_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
