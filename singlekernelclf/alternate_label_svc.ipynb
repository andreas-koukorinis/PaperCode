{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import fileutils as fileutils\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import pickle\n",
    "import fnmatch\n",
    "import os\n",
    "import clfutils\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "dataDrive = '/media/ak/My Passport/Data/FinDataReal/'  # also labels location folder\n",
    "jointLocationsPickleFolder = os.path.join(dataDrive, 'JointLocationsDicts')\n",
    "extPath = '/media/ak/My Passport/ExperimentData'\n",
    "featuresPath = \"/\".join((extPath, 'features'))  # path with features\n",
    "\n",
    "# Labels\n",
    "labels_location_folder = fileutils.data_path  # this is the folder where all the labels are saved\n",
    "\n",
    "labels_pickle_files = [s for s in os.listdir(labels_location_folder) if ('LabelsAlternate') in s if\n",
    "                       not ('.pkl') in s]  # these are all the dicts that we have alternate labels for.\n",
    "# labels_pickle_files: these are all the dicts that we have alternate labels for.\n",
    "\n",
    "symbols = [f for f in [s for s in os.listdir(labels_location_folder) if '.L' in s if '_Features' not in s] if\n",
    "           ('.L_A' or '_Features') not in f]  # from all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardDates = [f for f in os.listdir(dataDrive) if ('ForwardDates') in f]\n",
    "svcModels = [g for g in os.listdir(dataDrive) if ('_SingleKernelSVC') in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logmemoryusage(msg):\n",
    "    # function to log memory usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print('Memory usage at %s is %smb.' % (msg, process.memory_info().rss / 1000 / 1000))\n",
    "\n",
    "\n",
    "def unpickle_csv(pickled_csv):\n",
    "    with open(pickled_csv, 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        p = u.load()\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ticker_features_labels(file_joint_locations):\n",
    "    # input a joint location file that contains both features and labels and returns one\n",
    "    labels = pd.read_csv(file_joint_locations[1])\n",
    "    features = unpickle_csv(file_joint_locations[0])\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def hmm_features_df(features_tuple):\n",
    "    return pd.concat([features_tuple[0], features_tuple[1], \\\n",
    "                      features_tuple[2], features_tuple[3]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AlternateLabelFeaturesLoader(object):\n",
    "    \"\"\"\n",
    "    takes in a main path, a symbol, an alternate label index (from 0 to 4) and returns, the pickled dict file name\n",
    "    and path for the common locations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_main, symbol, alternate_label_idx=None,\n",
    "                 jointLocationsPickleInput=jointLocationsPickleFolder):\n",
    "        self.main_path = path_main\n",
    "        self.symbol = symbol\n",
    "        self.LabelsAlternateName = ['LabelsAlternateFive', 'LabelsAlternateFour', 'LabelsAlternateOne',\n",
    "                                    'LabelsAlternateThree', 'LabelsAlternateTwo']\n",
    "        self.alternate_label_idx = alternate_label_idx\n",
    "        self.jointLocationsPickleFolder = jointLocationsPickleInput\n",
    "        self.jointLocsSymbols = list(np.unique([f.split(\"_\")[0] for f in os.listdir(self.jointLocationsPickleFolder)]))\n",
    "\n",
    "    def return_pickled_dict(self):\n",
    "        # returns the filename of the joint features and labels file\n",
    "        # the features file is a dictionary that has keys\n",
    "#         if self.symbol in self.jointLocsSymbols:\n",
    "        if self.alternate_label_idx < 4:\n",
    "            pickle_in_filename_local = os.path.join(self.jointLocationsPickleFolder, \"_\".join(\n",
    "                (self.symbol, self.LabelsAlternateName[self.alternate_label_idx], 'FeaturesLocations.pkl')))\n",
    "        else:\n",
    "            print('Error in the alternate label index: value between 0 and 4')\n",
    "#         else:\n",
    "#             print('Symbol is not in the folder')\n",
    "        return pickle_in_filename_local\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pickled_in_filename(file):\n",
    "        # load a simple pickled file and return it. its a bit different to the method used for the dictionary as this\n",
    "        # is pure Python 3.x\n",
    "        pickle_in = open(file, 'rb')\n",
    "        return pickle.load(pickle_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def joint_loc_pickle_keys(inputFile):\n",
    "        # returns keys of joint locations from labels and features\n",
    "        return list(AlternateLabelFeaturesLoader.load_pickled_in_filename(inputFile).keys())\n",
    "\n",
    "    @staticmethod\n",
    "    def forwardDates(list_of_keys, current_date):\n",
    "        \"\"\" return all the forward looking dates for each idxKey we use for training\"\"\"\n",
    "        lookAheadKeys = sorted(i for i in list_of_keys if i > current_date)\n",
    "        return lookAheadKeys\n",
    "\n",
    "\n",
    "class CreateMarketFeatures(object):\n",
    "    # a class to be expanded that uses features for base case -market based only-indicators/features\n",
    "    \"\"\"\"Requires:\n",
    "    a dataframe that has TradedPrice And Volume columns\n",
    "    symbol - A stock symbol on which to form a strategy on.\n",
    "    short_window - Lookback period for short moving average.\n",
    "    long_window - Lookback period for long moving average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        #         self.ticker = ticker\n",
    "        self.df = df\n",
    "\n",
    "    def load_data(self):\n",
    "        pass\n",
    "\n",
    "    def ma_spread(self, short_window=3, long_window=6):\n",
    "        # function that produces the MA spread, which can be used on its own or as an input for MACD\n",
    "        short_rolling_px = self.df['TradedPrice'].rolling(window=short_window).mean()\n",
    "        long_rolling_px = self.df['TradedPrice'].rolling(window=long_window).mean()\n",
    "        px_name = \"_\".join(('px_indx', str(short_window), str(long_window)))\n",
    "        self.df[px_name] = long_rolling_px - short_rolling_px\n",
    "        return self.df\n",
    "\n",
    "    def ma_spread_duration(self, short_window=2, long_window=4):\n",
    "        # function that produces the MA spread, which can be used on its own or as an input for MACD\n",
    "        short_rolling_px = self.df['Duration'].rolling(window=short_window).mean()\n",
    "        long_rolling_px = self.df['Duration'].rolling(window=long_window).mean()\n",
    "        dur_name = \"_\".join(('dur_indx', str(short_window), str(long_window)))\n",
    "        self.df[dur_name] = long_rolling_px - short_rolling_px\n",
    "        return self.df\n",
    "\n",
    "    def obv_calc(self):\n",
    "        # on balance volume indicator\n",
    "        self.df['SignedVolume'] = self.df['Volume'] * np.sign(self.df['TradedPrice'].diff()).cumsum()\n",
    "        self.df['SignedVolume'].iat[1] = 0\n",
    "        self.df['OBV'] = self.df['SignedVolume']  # .cumsum()\n",
    "        self.df = self.df.drop(columns=['SignedVolume'])\n",
    "        return self.df\n",
    "\n",
    "    def chaikin_mf(self, period=3):\n",
    "        # Chaikin money flow indicator\n",
    "        self.df[\"MF Multiplier\"] = (self.df['TradedPrice'] - (self.df['TradedPrice'].expanding(period).min()) \\\n",
    "                                    - (self.df['TradedPrice'].expanding(period).max() \\\n",
    "                                       - self.df['TradedPrice'])) / (\n",
    "                                           self.df['TradedPrice'].expanding(period).max() - self.df[ \\\n",
    "                                       'TradedPrice'].expanding(period).min())\n",
    "        self.df[\"MF Volume\"] = self.df['MF Multiplier'] * self.df['Volume']\n",
    "        self.df['CMF_' + str(period)] = self.df['MF Volume'].sum() / self.df[\"Volume\"].rolling(period).sum()\n",
    "        self.df = self.df.drop(columns=['MF Multiplier', 'MF Volume'])\n",
    "        return self.df\n",
    "\n",
    "\n",
    "#         # forward_dates_keys = data_cls.forwardDates(joint_keys, joint_keys[joint_key_idx])  # forward dates for this date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LabelsAlternateOne'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just pick symbols I have joint locations\n",
    "jointLocsSymbols = list(np.unique([f.split(\"_\")[0] for f in os.listdir(jointLocationsPickleFolder)]))\n",
    "symbol= 'AAL.L'\n",
    "alternate_label_idx = 2\n",
    "symbol_idx = jointLocsSymbols.index(symbol)\n",
    "jointLocsSymbols[symbol_idx]\n",
    "labels_pickle_files[alternate_label_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AAL.L'\n",
    "best_svc_dict =defaultdict(dict)\n",
    "################\n",
    "symbolForwardDates = [f for f in forwardDates if str(symbol) in f]\n",
    "symbolSVCModels = [g for g in svcModels if str(symbol) in g]\n",
    "\n",
    "############################### SVC Model Location and Alternate Labels ###############################\n",
    "\n",
    "symbolSVCModelLocationIdx = 0\n",
    "symbolSVCModelLocation = os.path.join(dataDrive,symbolSVCModels[symbolSVCModelLocationIdx])\n",
    "alternate_label = symbolSVCModelLocation.split(\"_\")[1]\n",
    "\n",
    "######### MODELS #########################################################\n",
    "models =unpickle_csv(symbolSVCModelLocation)\n",
    "\n",
    "\n",
    "modelDates = list(models[list(models.keys())[0]].keys())\n",
    "modelDateIdx = 0\n",
    "svc = models[str(symbol)][modelDates[modelDateIdx]]['SVC']\n",
    "#### pick forward date ### \n",
    "forwardDate = [g for g in [f for f in symbolForwardDates if (str(modelDates[modelDateIdx])) in f] if str(alternate_label) in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL.L_LabelsAlternateFour_20170117_ForwardDates.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok to go\n",
      "AAL.L  and labels  LabelsAlternateFour\n"
     ]
    }
   ],
   "source": [
    "best_svc_dict =defaultdict(dict)\n",
    "if symbol in jointLocsSymbols:\n",
    "    print('ok to go')\n",
    "    alternate_label_idx = 0  # pick a label indexprint(jointLocsSymbols[symbol_idx], ' and labels ', labels_pickle_files[alternate_label_idx])\n",
    "    symbol_idx = jointLocsSymbols.index(symbol) # dont particularly need this!\n",
    "    print(symbol, ' and labels ', alternate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit code per symbol - see if this works! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AlternateLabelFeaturesLoader' object has no attribute 'joint_loc_pickle_kys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71705d8a797f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         jointLocationsPickleInput=jointLocationsPickleFolder)\n\u001b[1;32m      4\u001b[0m \u001b[0mjointLocationsDictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pickled_in_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_pickled_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mjoint_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_loc_pickle_kys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_pickled_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlogmemoryusage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before garbage collect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlternateLabelFeaturesLoader' object has no attribute 'joint_loc_pickle_kys'"
     ]
    }
   ],
   "source": [
    "\n",
    "    data_cls = AlternateLabelFeaturesLoader(path_main=dataDrive, symbol=jointLocsSymbols[symbol_idx],\n",
    "                                            alternate_label_idx=alternate_label_idx,\n",
    "                                            jointLocationsPickleInput=jointLocationsPickleFolder)\n",
    "    jointLocationsDictionary = (data_cls.load_pickled_in_filename(data_cls.return_pickled_dict()))\n",
    "    joint_keys = data_cls.joint_loc_pickle_kys(data_cls.return_pickled_dict())\n",
    "    logmemoryusage(\"Before garbage collect\")\n",
    "    gc.collect()  # continue\n",
    "    for joint_key_idx, joint_key_date in enumerate(joint_keys):\n",
    "        # this is a date - and we will enumerate through the keys\n",
    "        # getting features and labels\n",
    "        logmemoryusage(\"Before feature creation\")\n",
    "        features, labels = ticker_features_labels(jointLocationsDictionary[joint_keys[joint_key_idx]])\n",
    "        print(joint_key_date)\n",
    "        label_name = str(labels.columns[labels.columns.str.contains(pat='label')].values[0])\n",
    "        features_df = hmm_features_df(features)  # features data-frame - this just unbundles the features into a dataframe\n",
    "        # lets get all the features in order now#\n",
    "        market_features_df = CreateMarketFeatures(\n",
    "                CreateMarketFeatures(CreateMarketFeatures(df=CreateMarketFeatures(df=labels).ma_spread_duration())\n",
    "                                     .ma_spread()).chaikin_mf()).obv_calc()  # market features dataframe\n",
    "        df_concat = pd.DataFrame(pd.concat([features_df, market_features_df], axis=1, sort='False').dropna())\n",
    "        df = df_concat[df_concat[label_name].notna()]\n",
    "        df_final = df.drop(columns=['TradedPrice', 'Duration', 'TradedTime', 'ReturnTradedPrice', \\\n",
    "                                                           'Volume', label_name])\n",
    "        y_labels_train = df[df.columns[df.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "        if df_final.shape[0] < 10:\n",
    "            print(' the ratio of classes is too low. try another label permutation')\n",
    "            continue\n",
    "        else:\n",
    "            X_train = MinMaxScaler().fit_transform(df_final)\n",
    "            models_cls =  clfutils.FitModels(X_train, y_labels_train)\n",
    "            best_svc_dict[symbol][joint_key_date] = {'SVC': models_cls.best_svc_clf()}\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
