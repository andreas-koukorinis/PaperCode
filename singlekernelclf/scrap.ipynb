{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/ak/Documents/Research/PaperCode/singlekernelclf/')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "\n",
    "# paths\n",
    "oos_experiment_path = '/media/ak/My Passport/ExperimentData/AlternateLabelExperimentPath'\n",
    "oos_experiment_symbol_folders = [f for f in os.listdir(oos_experiment_path) if str('pkl') not in f]\n",
    "\n",
    "\n",
    "# functions\n",
    "\n",
    "def load_pickled_in_filename(file):\n",
    "    # load a simple pickled file and return it. its a bit different to the method used for the dictionary as this\n",
    "    # is pure Python 3.x\n",
    "    pickle_in = open(file, 'rb')\n",
    "    return pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "def concatenate_all_oos_per_label(dict_list):\n",
    "    # the barani solution\n",
    "    \"\"\"\n",
    "\n",
    "    :param dict_list: takes a list o dictionaries for the way the formatted OOS results are\n",
    "    :return: a clean concatenated dataframe, the values of the row index across all dataframes must be the same!\n",
    "    \"\"\"\n",
    "    list_of_dfs = [pd.DataFrame(l) for l in dict_list]\n",
    "    combined_results = pd.concat([pd.DataFrame(l) for l in dict_list], axis=1)\n",
    "    combined_results\n",
    "    return combined_results\n",
    "\n",
    "\n",
    "def create_mean_list_w_correct_label(df, label_string):\n",
    "    df = pd.DataFrame(df.mean(axis=1))\n",
    "    df = df.rename(columns={df.columns[0]: label_string}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def labels_files(folder_files):\n",
    "    LabelsAlternateFive_symbol_files = [f for f in folder_files if str('LabelsAlternateFive') in f]\n",
    "    LabelsAlternateFour_symbol_files = [f for f in folder_files if str('LabelsAlternateFour') in f]\n",
    "    LabelsAlternateThree_symbol_files = [f for f in folder_files if str('LabelsAlternateThree') in f]\n",
    "    LabelsAlternateTwo_symbol_files = [f for f in folder_files if str('LabelsAlternateTwo') in f]\n",
    "    LabelsAlternateOne_symbol_files = [f for f in folder_files if str('LabelsAlternateOne') in f]\n",
    "    labels_files_list = [LabelsAlternateOne_symbol_files, LabelsAlternateTwo_symbol_files, LabelsAlternateThree_symbol_files, LabelsAlternateFour_symbol_files, LabelsAlternateFive_symbol_files]\n",
    "    return labels_files_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL.L\n"
     ]
    }
   ],
   "source": [
    "oos_symbol_idx =0 # this corresponds to a symbol\n",
    "symbol = oos_experiment_symbol_folders[oos_symbol_idx]\n",
    "print(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_symbol_folder_files = [f for f in os.listdir(os.path.join(oos_experiment_path, symbol)) if str('_OOS_results') in f]\n",
    " # this is a structurd list of lists. each one is a specified one with output. some may be empty so need to adjust for that\n",
    "oos_symbol_list_of_files_list = labels_files(oos_symbol_folder_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# so i need a per label filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelsAlternate_symbol_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_list=[]\n",
    "if number_model_files >0: # if the list is not empty\n",
    "    for file in LabelsAlternate_symbol_files:\n",
    "        pickle_file_location = os.path.join(oos_experiment_path, symbol, file)\n",
    "        df_w_Data = load_pickled_in_filename(pickle_file_location)\n",
    "        ans = {label.split(\"_\")[1] : {metric : np.mean([value[metric] for value in values.values()]) for metric in values[list(values)[0]].keys()} for label, values in df_w_Data.items()}\n",
    "        dict_list.append(ans)\n",
    "        \n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_from_dict(dict_list, label):\n",
    "    df =concatenate_all_oos_per_label(dict_list)\n",
    "    df_w_label = pd.DataFrame(df.mean(axis=1)).rename(columns={0: label}).to_latex(index=True)\n",
    "    return df_w_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lr}\\n\\\\toprule\\n{} &  LabelsAlternateOne \\\\\\\\\\n\\\\midrule\\nHamming Loss &            0.648843 \\\\\\\\\\naccuracy     &            0.351157 \\\\\\\\\\nf1- macro    &            0.237748 \\\\\\\\\\nf1- micro    &            0.351157 \\\\\\\\\\nf1- weighted &            0.265395 \\\\\\\\\\nprecision    &            0.267711 \\\\\\\\\\nrecall       &            0.351157 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_table_from_dict(dict_list, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_label.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lr}\\n\\\\toprule\\n{} &  LabelsAlternateOne \\\\\\\\\\n\\\\midrule\\nHamming Loss &            0.648843 \\\\\\\\\\naccuracy     &            0.351157 \\\\\\\\\\nf1- macro    &            0.237748 \\\\\\\\\\nf1- micro    &            0.351157 \\\\\\\\\\nf1- weighted &            0.265395 \\\\\\\\\\nprecision    &            0.267711 \\\\\\\\\\nrecall       &            0.351157 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
