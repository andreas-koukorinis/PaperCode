{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "import fileutils as fileutils\n",
    "import gc\n",
    "import psutil\n",
    "import pickle\n",
    "import fnmatch\n",
    "import os\n",
    "import time\n",
    "import clfutils\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score\n",
    "import new_alternate_single_svm as nalsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feature_labels_fit(features, labels):\n",
    "    label_name = str(labels.columns[labels.columns.str.contains(pat='label')].values[0])\n",
    "    features_df = nalsvm.hmm_features_df(\n",
    "        features)  # features data-frame - this just unbundles the features into a dataframe\n",
    "    # lets get all the features in order now#\n",
    "    if features_df.isnull().values.all() == True:\n",
    "        print('HMM Features Problematic') #do i need a counter here?\n",
    "        market_features_df = nalsvm.CreateMarketFeatures(\n",
    "            nalsvm.CreateMarketFeatures(\n",
    "                nalsvm.CreateMarketFeatures(df=nalsvm.CreateMarketFeatures(df=labels).ma_spread_duration())\n",
    "                    .ma_spread()).chaikin_mf()).obv_calc()  # market features dataframe\n",
    "        df_concat = market_features_df.dropna()\n",
    "        df = df_concat[df_concat[label_name].notna()]\n",
    "        df_final = df.drop(columns=['TradedPrice', 'Duration', 'TradedTime', 'ReturnTradedPrice', \\\n",
    "                                    'Volume', label_name])\n",
    "    else:\n",
    "        market_features_df = nalsvm.CreateMarketFeatures(\n",
    "            nalsvm.CreateMarketFeatures(\n",
    "                nalsvm.CreateMarketFeatures(df=nalsvm.CreateMarketFeatures(df=labels).ma_spread_duration())\n",
    "                    .ma_spread()).chaikin_mf()).obv_calc()  # market features dataframe\n",
    "        df_concat = pd.DataFrame(pd.concat([features_df, market_features_df], axis=1, sort='False').dropna())\n",
    "        df = df_concat[df_concat[label_name].notna()]\n",
    "        df_final = df.drop(columns=['TradedPrice', 'Duration', 'TradedTime', 'ReturnTradedPrice', \\\n",
    "                                    'Volume', label_name])\n",
    "\n",
    "    if df_final.shape[0] < 10:\n",
    "        print(' the ratio of classes is too low. try another label permutation')\n",
    "    else:\n",
    "        X_ = MinMaxScaler().fit_transform(df_final)\n",
    "        y_labels = df[df.columns[df.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "\n",
    "        return X_, y_labels\n",
    "    \n",
    "def hmm_features_df(features):\n",
    "    features_df = nalsvm.hmm_features_df(\n",
    "        features)  # features data-frame - this just unbundles the features into a dataframe\n",
    "    return features_df\n",
    "\n",
    "def logmemoryusage(msg):\n",
    "    # function to log memory usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print('Memory usage at %s is %smb.' % (msg, process.memory_info().rss / 1000 / 1000))\n",
    "\n",
    "\n",
    "def unpickle_csv(pickled_csv):\n",
    "    with open(pickled_csv, 'rb') as f:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        p = u.load()\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ticker_features_labels(file_joint_locations):\n",
    "    # input a joint location file that contains both features and labels and returns one\n",
    "    labels = pd.read_csv(file_joint_locations[1])\n",
    "    features = unpickle_csv(file_joint_locations[0])\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def hmm_features_df(features_tuple):\n",
    "    return pd.concat([features_tuple[0], features_tuple[1], \\\n",
    "                      features_tuple[2], features_tuple[3]], axis=1, sort=False)\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels\n",
    "    on a classification.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds, average='weighted')\n",
    "    recall = recall_score(y_true, y_preds, average='weighted')\n",
    "    f1 = f1_score(y_true, y_preds, average='weighted')\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# paths\n",
    "dataDrive = '/media/ak/My Passport/Data/FinDataReal/'  # also labels location folder\n",
    "jointLocationsPickleFolder = os.path.join(dataDrive, 'JointLocationsDicts')\n",
    "extPath = '/media/ak/My Passport/ExperimentData'\n",
    "featuresPath = \"/\".join((extPath, 'features'))  # path with features\n",
    "\n",
    "# Labels\n",
    "labels_location_folder = fileutils.data_path  # this is the folder where all the labels are saved\n",
    "\n",
    "labels_pickle_files = sorted([s for s in os.listdir(labels_location_folder) if ('LabelsAlternate') in s if\n",
    "                              not ('.pkl') in s])  # these are all the dicts that we have alternate labels for.\n",
    "# labels_pickle_files: these are all the dicts that we have alternate labels for.\n",
    "\n",
    "symbols = [f for f in [s for s in os.listdir(labels_location_folder) if '.L' in s if '_Features' not in s] if\n",
    "           ('.L_A' or '_Features') not in f]  # from all\n",
    "forwardDates = [f for f in os.listdir(dataDrive) if 'ForwardDates' in f]\n",
    "svcModels = [g for g in os.listdir(dataDrive) if '_SingleKernelSVC' in g]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL.L_LabelsAlternateFour_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateFour_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateOne_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateThree_SingleKernelSVC.pkl',\n",
       " 'BATS.L_LabelsAlternateFour_SingleKernelSVC.pkl',\n",
       " 'AAL.L_LabelsAlternateOne_SingleKernelSVC.pkl']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BARC.L_LabelsAlternateFour_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateOne_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateThree_SingleKernelSVC.pkl']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = 'BARC.L'\n",
    "symbolSVCModels = [g for g in svcModels if str(symbol) in g]\n",
    "symbolSVCModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/My Passport/Data/FinDataReal/JointLocationsDicts'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jointLocationsPickleFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternate_label_idx = 2\n",
    "jointLocsSymbols = list(np.unique([f.split(\"_\")[0] for f in os.listdir(jointLocationsPickleFolder)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_idx = jointLocsSymbols.index(symbol)\n",
    "\n",
    "data_cls = nalsvm.AlternateLabelFeaturesLoader(path_main=dataDrive, symbol=symbol,\n",
    "                                               alternate_label_idx=alternate_label_idx,\n",
    "                                               jointLocationsPickleInput=jointLocationsPickleFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jointLocationsDictionary = (data_cls.load_pickled_in_filename(data_cls.return_pickled_dict()))\n",
    "joint_keys = data_cls.joint_loc_pickle_keys(data_cls.return_pickled_dict())\n",
    "\n",
    "\n",
    "  \n",
    "joint_keys == list(jointLocationsDictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which label I am using  LabelsAlternateOne\n",
      "Memory usage at Before garbage collect is 301.162496mb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2942"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# jointLocsSymbols[symbol_idx]--> this returns the symbol.\n",
    "\n",
    "print('which label I am using ',labels_pickle_files[alternate_label_idx])  # \n",
    "logmemoryusage(\"Before garbage collect\")\n",
    "gc.collect()  # continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Model Location and Alternate Labels ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARC.L_LabelsAlternateOne_SingleKernelSVC.pkl\n",
      "/media/ak/My Passport/Data/FinDataReal/BARC.L_LabelsAlternateOne_SingleKernelSVC.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "symbolSVCModelLocationIndexedLabel = \\\n",
    "    [f for f in symbolSVCModels if str(labels_pickle_files[alternate_label_idx]) in f][0]\n",
    "print(symbolSVCModelLocationIndexedLabel)\n",
    "symbolSVCModelLocation = os.path.join(dataDrive, symbolSVCModelLocationIndexedLabel)\n",
    "print(symbolSVCModelLocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BARC.L_LabelsAlternateFour_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateOne_SingleKernelSVC.pkl',\n",
       " 'BARC.L_LabelsAlternateThree_SingleKernelSVC.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolSVCModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelsAlternateOne\n"
     ]
    }
   ],
   "source": [
    "alternate_label = symbolSVCModelLocation.split(\"_\")[1]\n",
    "print(alternate_label) # do I really need this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######### MODELS #########################################################\n",
    "models = unpickle_csv(symbolSVCModelLocation)\n",
    "modelDates = list(models[list(models.keys())[0]].keys())\n",
    "\n",
    "modelDateIdx = 0  # <-- this is fit-date in sample that corresponds to the labels date too\n",
    "print(modelDates[modelDateIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = models[str(symbol)][modelDates[modelDateIdx]]['SVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok to go\n",
      "BARC.L  and labels  LabelsAlternateOne\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "if symbol in jointLocsSymbols:\n",
    "    print('ok to go')\n",
    "    print(symbol, ' and labels ', labels_pickle_files[alternate_label_idx])\n",
    "    features, labels = ticker_features_labels(jointLocationsDictionary[modelDates[modelDateIdx]])\n",
    "    X_fit, y_fit = feature_labels_fit(features, labels)\n",
    "    fitted_model = svc.fit(X_fit, y_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170118',\n",
       " '20170119',\n",
       " '20170120',\n",
       " '20170123',\n",
       " '20170124',\n",
       " '20170125',\n",
       " '20170126',\n",
       " '20170127',\n",
       " '20170130',\n",
       " '20170131',\n",
       " '20170801',\n",
       " '20170802',\n",
       " '20170803',\n",
       " '20170804',\n",
       " '20170807',\n",
       " '20170808',\n",
       " '20170809',\n",
       " '20170810',\n",
       " '20170811',\n",
       " '20170814',\n",
       " '20170815',\n",
       " '20170816',\n",
       " '20170817',\n",
       " '20170818',\n",
       " '20170821',\n",
       " '20170822',\n",
       " '20170823',\n",
       " '20170824',\n",
       " '20170825',\n",
       " '20170829',\n",
       " '20170830',\n",
       " '20170831',\n",
       " '20170901',\n",
       " '20170904',\n",
       " '20170905',\n",
       " '20170906',\n",
       " '20170907',\n",
       " '20170908',\n",
       " '20170911',\n",
       " '20170912',\n",
       " '20170913',\n",
       " '20170914',\n",
       " '20170915',\n",
       " '20170918',\n",
       " '20170919',\n",
       " '20170920',\n",
       " '20170921',\n",
       " '20170922',\n",
       " '20170925',\n",
       " '20170926',\n",
       " '20170927',\n",
       " '20170928',\n",
       " '20170929']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolForwardDates = data_cls.forwardDates(joint_keys, modelDates[modelDateIdx]) # out of sample dates\n",
    "symbolForwardDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 49.87%\n",
      "Precision: 0.77\n",
      "Recall: 0.50\n",
      "F1 score: 0.58\n",
      "{'accuracy': 0.5, 'precision': 0.77, 'recall': 0.5, 'f1': 0.58}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 44.53%\n",
      "Precision: 0.79\n",
      "Recall: 0.45\n",
      "F1 score: 0.53\n",
      "{'accuracy': 0.45, 'precision': 0.79, 'recall': 0.45, 'f1': 0.53}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.74%\n",
      "Precision: 0.80\n",
      "Recall: 0.46\n",
      "F1 score: 0.55\n",
      "{'accuracy': 0.46, 'precision': 0.8, 'recall': 0.46, 'f1': 0.55}\n",
      "Problem\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 52.26%\n",
      "Precision: 0.70\n",
      "Recall: 0.52\n",
      "F1 score: 0.57\n",
      "{'accuracy': 0.52, 'precision': 0.7, 'recall': 0.52, 'f1': 0.57}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 46.80%\n",
      "Precision: 0.77\n",
      "Recall: 0.47\n",
      "F1 score: 0.55\n",
      "{'accuracy': 0.47, 'precision': 0.77, 'recall': 0.47, 'f1': 0.55}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 44.52%\n",
      "Precision: 0.80\n",
      "Recall: 0.45\n",
      "F1 score: 0.55\n",
      "{'accuracy': 0.45, 'precision': 0.8, 'recall': 0.45, 'f1': 0.55}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 39.07%\n",
      "Precision: 0.75\n",
      "Recall: 0.39\n",
      "F1 score: 0.46\n",
      "{'accuracy': 0.39, 'precision': 0.75, 'recall': 0.39, 'f1': 0.46}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 42.04%\n",
      "Precision: 0.69\n",
      "Recall: 0.42\n",
      "F1 score: 0.48\n",
      "{'accuracy': 0.42, 'precision': 0.69, 'recall': 0.42, 'f1': 0.48}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 27.12%\n",
      "Precision: 0.68\n",
      "Recall: 0.27\n",
      "F1 score: 0.33\n",
      "{'accuracy': 0.27, 'precision': 0.68, 'recall': 0.27, 'f1': 0.33}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 43.12%\n",
      "Precision: 0.62\n",
      "Recall: 0.43\n",
      "F1 score: 0.48\n",
      "{'accuracy': 0.43, 'precision': 0.62, 'recall': 0.43, 'f1': 0.48}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 50.53%\n",
      "Precision: 0.55\n",
      "Recall: 0.51\n",
      "F1 score: 0.51\n",
      "{'accuracy': 0.51, 'precision': 0.55, 'recall': 0.51, 'f1': 0.51}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 46.82%\n",
      "Precision: 0.56\n",
      "Recall: 0.47\n",
      "F1 score: 0.49\n",
      "{'accuracy': 0.47, 'precision': 0.56, 'recall': 0.47, 'f1': 0.49}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 54.00%\n",
      "Precision: 0.54\n",
      "Recall: 0.54\n",
      "F1 score: 0.53\n",
      "{'accuracy': 0.54, 'precision': 0.54, 'recall': 0.54, 'f1': 0.53}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 18.65%\n",
      "Precision: 0.59\n",
      "Recall: 0.19\n",
      "F1 score: 0.11\n",
      "{'accuracy': 0.19, 'precision': 0.59, 'recall': 0.19, 'f1': 0.11}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 47.51%\n",
      "Precision: 0.57\n",
      "Recall: 0.48\n",
      "F1 score: 0.50\n",
      "{'accuracy': 0.48, 'precision': 0.57, 'recall': 0.48, 'f1': 0.5}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.86%\n",
      "Precision: 0.67\n",
      "Recall: 0.46\n",
      "F1 score: 0.51\n",
      "{'accuracy': 0.46, 'precision': 0.67, 'recall': 0.46, 'f1': 0.51}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.71%\n",
      "Precision: 0.59\n",
      "Recall: 0.46\n",
      "F1 score: 0.50\n",
      "{'accuracy': 0.46, 'precision': 0.59, 'recall': 0.46, 'f1': 0.5}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 43.56%\n",
      "Precision: 0.50\n",
      "Recall: 0.44\n",
      "F1 score: 0.45\n",
      "{'accuracy': 0.44, 'precision': 0.5, 'recall': 0.44, 'f1': 0.45}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 49.67%\n",
      "Precision: 0.56\n",
      "Recall: 0.50\n",
      "F1 score: 0.51\n",
      "{'accuracy': 0.5, 'precision': 0.56, 'recall': 0.5, 'f1': 0.51}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 46.61%\n",
      "Precision: 0.53\n",
      "Recall: 0.47\n",
      "F1 score: 0.47\n",
      "{'accuracy': 0.47, 'precision': 0.53, 'recall': 0.47, 'f1': 0.47}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 44.67%\n",
      "Precision: 0.58\n",
      "Recall: 0.45\n",
      "F1 score: 0.48\n",
      "{'accuracy': 0.45, 'precision': 0.58, 'recall': 0.45, 'f1': 0.48}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 52.52%\n",
      "Precision: 0.57\n",
      "Recall: 0.53\n",
      "F1 score: 0.53\n",
      "{'accuracy': 0.53, 'precision': 0.57, 'recall': 0.53, 'f1': 0.53}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 34.52%\n",
      "Precision: 0.48\n",
      "Recall: 0.35\n",
      "F1 score: 0.36\n",
      "{'accuracy': 0.35, 'precision': 0.48, 'recall': 0.35, 'f1': 0.36}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 44.75%\n",
      "Precision: 0.85\n",
      "Recall: 0.45\n",
      "F1 score: 0.58\n",
      "{'accuracy': 0.45, 'precision': 0.85, 'recall': 0.45, 'f1': 0.58}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 50.16%\n",
      "Precision: 0.63\n",
      "Recall: 0.50\n",
      "F1 score: 0.54\n",
      "{'accuracy': 0.5, 'precision': 0.63, 'recall': 0.5, 'f1': 0.54}\n",
      "Problem\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 49.24%\n",
      "Precision: 0.89\n",
      "Recall: 0.49\n",
      "F1 score: 0.62\n",
      "{'accuracy': 0.49, 'precision': 0.89, 'recall': 0.49, 'f1': 0.62}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 12.65%\n",
      "Precision: 0.94\n",
      "Recall: 0.13\n",
      "F1 score: 0.20\n",
      "{'accuracy': 0.13, 'precision': 0.94, 'recall': 0.13, 'f1': 0.2}\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 47.31%\n",
      "Precision: 0.79\n",
      "Recall: 0.47\n",
      "F1 score: 0.58\n",
      "{'accuracy': 0.47, 'precision': 0.79, 'recall': 0.47, 'f1': 0.58}\n",
      "Problem\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 40.70%\n",
      "Precision: 0.86\n",
      "Recall: 0.41\n",
      "F1 score: 0.53\n",
      "{'accuracy': 0.41, 'precision': 0.86, 'recall': 0.41, 'f1': 0.53}\n",
      "Problem\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 42.18%\n",
      "Precision: 0.82\n",
      "Recall: 0.42\n",
      "F1 score: 0.53\n",
      "{'accuracy': 0.42, 'precision': 0.82, 'recall': 0.42, 'f1': 0.53}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 45.10%\n",
      "Precision: 0.79\n",
      "Recall: 0.45\n",
      "F1 score: 0.55\n",
      "{'accuracy': 0.45, 'precision': 0.79, 'recall': 0.45, 'f1': 0.55}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 42.91%\n",
      "Precision: 0.90\n",
      "Recall: 0.43\n",
      "F1 score: 0.57\n",
      "{'accuracy': 0.43, 'precision': 0.9, 'recall': 0.43, 'f1': 0.57}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 49.87%\n",
      "Precision: 0.91\n",
      "Recall: 0.50\n",
      "F1 score: 0.63\n",
      "{'accuracy': 0.5, 'precision': 0.91, 'recall': 0.5, 'f1': 0.63}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 42.82%\n",
      "Precision: 0.80\n",
      "Recall: 0.43\n",
      "F1 score: 0.54\n",
      "{'accuracy': 0.43, 'precision': 0.8, 'recall': 0.43, 'f1': 0.54}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 28.57%\n",
      "Precision: 0.90\n",
      "Recall: 0.29\n",
      "F1 score: 0.42\n",
      "{'accuracy': 0.29, 'precision': 0.9, 'recall': 0.29, 'f1': 0.42}\n",
      "Problem\n",
      "Problem\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 30.59%\n",
      "Precision: 0.86\n",
      "Recall: 0.31\n",
      "F1 score: 0.42\n",
      "{'accuracy': 0.31, 'precision': 0.86, 'recall': 0.31, 'f1': 0.42}\n",
      "479     1\n",
      "550     1\n",
      "5164    1\n",
      "Name: label_EndPo__window_9__thres_arbitrary__0.1, dtype: int64\n",
      "Acc: 31.36%\n",
      "Precision: 0.90\n",
      "Recall: 0.31\n",
      "F1 score: 0.43\n",
      "{'accuracy': 0.31, 'precision': 0.9, 'recall': 0.31, 'f1': 0.43}\n",
      "it took 2704.6839826107025 seconds!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for forward_date_idx, _ in enumerate(symbolForwardDates):\n",
    "    features_oos, labels_oos = ticker_features_labels(\n",
    "        jointLocationsDictionary[symbolForwardDates[forward_date_idx]])\n",
    "    if hmm_features_df(features_oos).isnull().values.all()==True:\n",
    "        print('Problem')\n",
    "    else:\n",
    "        print(labels.value_counts())\n",
    "        X_true, y_true = feature_labels_fit(features_oos, labels_oos)\n",
    "        y_pred = fitted_model.predict(X_true)\n",
    "        print(evaluate_predictions(y_true, y_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(f'it took {end - start} seconds!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels= ticker_features_labels(\n",
    "        jointLocationsDictionary[symbolForwardDates[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
