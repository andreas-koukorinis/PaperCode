{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from sklearn.metrics.pairwise import rbf_kernel as RBF\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from MKLpy.metrics.pairwise.misc import homogeneous_polynomial_kernel as HPK_kernel\n",
    "from MKLpy.metrics import pairwise\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier  # support from multiclass\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from MKLpy.preprocessing import normalization, rescale_01\n",
    "from MKLpy.model_selection import cross_val_score, cross_val_predict\n",
    "import pickle as pkl\n",
    "###\n",
    "\n",
    "\n",
    "from MKLpy.metrics import pairwise\n",
    "from MKLpy.algorithms import AverageMKL, EasyMKL, KOMD#KOMD is not a MKL algorithm but a simple kernel machine like the SVM\n",
    "#evaluate the solution\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def featureCreation(idxKey, locDict):\n",
    "    \"\"\" gives out clean features and labels for a given locDict and a idxKey \"\"\"\n",
    "    featuresIdxDirFileLoc = locDict[idxKey][0]\n",
    "    labelsIdxDirFileLoc = locDict[idxKey][1]\n",
    "    ''' read the features file'''\n",
    "    featuresTupleFile = pkl.load(open(featuresIdxDirFileLoc, \"rb\"), encoding='latin1')\n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1], \\\n",
    "                            featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "    labelsDf = pd.read_csv(labelsIdxDirFileLoc)\n",
    "    ''' pop the labels out'''\n",
    "    labels = labelsDf['label_PrMov__window_5__thres_arbitrary__0.1']\n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[labelName])\n",
    "    arrX = np.array(dfX)\n",
    "    ''' feature normalisation'''\n",
    "    # feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    X = normalization(rescale_01(arrX))\n",
    "    y = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "    ''' returns features, labels'''\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-506037faeb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMKLExpPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMKLExpPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msymbolIdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "MKLExpPath = os.path.join(DataLoc, path)\n",
    "symbols = sorted(os.listdir(MKLExpPath))\n",
    "\n",
    "\n",
    "symbolIdx = 3\n",
    "print(symbols[symbolIdx])\n",
    "MKLSymbolPath = os.path.join(MKLExpPath, symbols[symbolIdx])\n",
    "MKLSymbolKernelsPath = \"/\".join((MKLSymbolPath, 'Kernels'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MKLSymbolPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanListKernelInputKeys = {}\n",
    "compKernels={}\n",
    "\n",
    "''' creating the appropriate paths and making the code far more modular'''\n",
    "SymbolCommonPaths = mkl_base.open_pickle_file(MKLSymbolPath,'LocDictsListCorrect.pkl')  # where the locations of the symbol\n",
    "# paths are\n",
    "kernelInputPaths = mkl_base.open_pickle_file(MKLSymbolPath, 'kernelInputsLocations.pkl')  # where the location of the kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelFiles =[s for s in os.listdir(\"/\".join((MKLSymbolPath,'Kernels'))) if ('RBFKernels.pkl') in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "for keyInput in kernelInputPaths.keys() :\n",
    "    Xtr, ytr = featureCreation(idxKey=keyInput,\n",
    "                                   locDict=SymbolCommonPaths)\n",
    "    if (np.isfinite( Xtr ).all()==True and  np.isnan( Xtr ).all() == False):\n",
    "        print(keyInput)\n",
    "        cleanListKernelInputKeys[keyInput] = SymbolCommonPaths[keyInput]\n",
    "    else:\n",
    "        print('Shapes dont match.')\n",
    "        continue\n",
    "\n",
    "\n",
    "pkl.dump(cleanListKernelInputKeys, open(\"/\".join((MKLSymbolKernelsPath, \"cleanKernelsList.pkl\")), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanListKernelInputKeys = pkl.load(open(\"/\".join((MKLSymbolKernelsPath, \"cleanKernelsList.pkl\",)),\"rb\"), encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keysKernels = list(cleanListKernelInputKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compKernels={}\n",
    "RBFKernels={}\n",
    "for kernelKey in cleanListKernelInputKeys:\n",
    "    featuresIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][0]\n",
    "    labelsIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][1]\n",
    "    \n",
    "    featuresTupleFile = pkl.load(open(featuresIdxDirFileLoc, \"rb\"), encoding='latin1')\n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1], \\\n",
    "                                featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "#     labelsDf = \n",
    "    ''' pop the labels out'''\n",
    "    labels = pd.read_csv(labelsIdxDirFileLoc)['label_PrMov__window_5__thres_arbitrary__0.1']\n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[labelName])\n",
    "    ''' feature normalisation'''\n",
    "    # feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    Xtr = normalization(rescale_01(np.array(dfX)))\n",
    "    #kernelHPK = [HPK_kernel(Xtr, degree=d) for d in range(1, 4)]\n",
    "    kernelRBF = [RBF(Xtr, gamma=gamma) for gamma in [1., 10, 100.]]\n",
    "    print('training EasyMKL...for polynomials and RBF', end='')\n",
    "    #compKernelsRBF[kernelKey] = [kernelHPK, kernelRBF]\n",
    "    RBFKernels[kernelKey] = [kernelRBF]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# kernelFileName = \"/\".join(\n",
    "#         (MKLSymbolKernelsPath, \"\".join((kernelKey[0], '_', kernelKey[1], \"_RBFKernels.pkl\"))))\n",
    "    \n",
    "kernelFileName = \"/\".join(\n",
    "        (MKLSymbolKernelsPath, symbols[symbolIdx], \"_RBFKernels.pkl\"))\n",
    "pkl.dump(RBFKernels[kernelKey], open(kernelFileName, \"wb\"))\n",
    "\n",
    "           \n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleanListKernelInputKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernelKey in cleanListKernelInputKeys:\n",
    "    featuresIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][0]\n",
    "    labelsIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][1]\n",
    "    \n",
    "    featuresTupleFile = pkl.load(open(featuresIdxDirFileLoc, \"rb\"), encoding='latin1')\n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1], \\\n",
    "                                featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "#     labelsDf = \n",
    "    ''' pop the labels out'''\n",
    "    labels = pd.read_csv(labelsIdxDirFileLoc)['label_PrMov__window_5__thres_arbitrary__0.1']\n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[labelName])\n",
    "    ''' feature normalisation'''\n",
    "    # feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    Xtr = normalization(rescale_01(np.array(dfX)))\n",
    "    ytr = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_list = [rbf_kernel(Xtr, gamma=g) for g in gamma_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFKeys=list(RBFKernels)\n",
    "print(RBFKeys[0]) #load this data and this kernel and fit model\n",
    "fwdKeys = [i for i in RBFKeys if i>RBFKeys[0]] #load this data and produce the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Xtr.shape[0] == ytr.shape[0]:\n",
    "            print(SymbolCommonPaths[keyInput])\n",
    "            print('doing the kernels bit')\n",
    "            kernelHPK = [HPK_kernel(Xtr, degree=d) for d in range(1, 11)]\n",
    "            kernelRBF = [RBF(Xtr, gamma=gamma) for gamma in [1., 10, 100.]]\n",
    "            print('training EasyMKL...for polynomials and RBF', end='')\n",
    "            compKernels[keyInput] = [kernelHPK, kernelRBF]\n",
    "        else:\n",
    "            print('Shapes dont match.')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelFileName = \"/\".join((MKLSymbolPath,'kernelInputsLocations.pkl'))\n",
    "pkl.load(open(kernelFileName, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"/\".join((MKLSymbolPath,'LocDictsListCorrect.pkl'))\n",
    "pkl.load(open(fileName, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(RBFKernels)\n",
    "for kernelKey in RBFKernels:\n",
    "    featuresIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][0]\n",
    "    labelsIdxDirFileLoc = cleanListKernelInputKeys[kernelKey][1]\n",
    "    \n",
    "    featuresTupleFile = pkl.load(open(featuresIdxDirFileLoc, \"rb\"), encoding='latin1')\n",
    "    dfFeatures = pd.concat([featuresTupleFile[0], featuresTupleFile[1], \\\n",
    "                                featuresTupleFile[2], featuresTupleFile[3]], axis=1, sort=False).fillna(0)\n",
    "    ''' read the labels file'''\n",
    "#     labelsDf = \n",
    "    ''' pop the labels out'''\n",
    "    labels = pd.read_csv(labelsIdxDirFileLoc)['label_PrMov__window_5__thres_arbitrary__0.1']\n",
    "    '''dataframe of Features and Labels - X and Y'''\n",
    "    dfXY = pd.concat([dfFeatures, labels], axis=1, sort='False').dropna()\n",
    "    labelName = str(dfXY.columns[dfXY.columns.str.contains(pat='label')].values[0])\n",
    "    ''' drop the labels from the features'''\n",
    "    dfX = dfXY.drop(columns=[labelName])\n",
    "    ''' feature normalisation'''\n",
    "    # feature scaling in [0,1] - X = rescale_01(arrX)\n",
    "    Xtr = normalization(rescale_01(np.array(dfX)))\n",
    "    ytr = dfXY[dfXY.columns[dfXY.columns.str.contains(pat='label')]].iloc[:, 0]\n",
    "    ker_list = RBFKernels[kernelKey]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfEasy = EasyMKL(lam=0.1).fit(KLtr,ytr)#combining kernels with the EasyMKL algorithm\n",
    "clfRBF = EasyMKL(lam=0.1).fit(ker_list,ytr)\n",
    "    print('Average Kernel Testing')\n",
    "y_pred = clf.predict(KLte)                 #predictions\n",
    "y_score = clf.decision_function(KLte)      #rank\n",
    "accuracy = accuracy_score(Yte, y_pred)\n",
    "fprAverage, tprAverage, thresholdsAverage = roc_curve(Yte.ravel(), y_score.ravel())\n",
    "roc_auc = auc(fprAverage, tprAverage)\n",
    "\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy, roc_auc))\n",
    "\n",
    "\n",
    "''' Test Linear'''\n",
    "print('MKL-Linear Testing')\n",
    "y_predMKLLinear = clfEasy.predict(KLte)                 #predictions\n",
    "y_scoreMKLLinear = clfEasy.decision_function(KLte)  #rank\n",
    "\n",
    "accuracy_MKLLinear = accuracy_score(Yte, y_predMKLLinear)\n",
    "roc_auc_MKLLinear = roc_auc_score(Yte, y_scoreMKLLinear)\n",
    "print ('Accuracy score: %.3f, roc AUC score: %.3f' % (accuracy_MKLLinear, roc_auc_MKLLinear))\n",
    "\n",
    "fprLinear, tprLinear, thresholds = roc_curve(Yte.ravel(), y_scoreMKLLinear.ravel())\n",
    "\n",
    "roc_auc_Linear = auc(fprLinear, tprLinear)\n",
    "\n",
    "# fprMKLLinear, fprMKLLinear, thresholdsRBF =roc_curve(Yte, y_scoreMKLLinear)\n",
    "\n",
    "print(roc_auc_Linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
