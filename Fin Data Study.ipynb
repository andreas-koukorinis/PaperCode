{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pickle\n",
    "import fnmatch\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "#Set PANDAS to show all columns in DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def listdirs(folder): #return only directories from a master folder\n",
    "    return [d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]\n",
    "\n",
    "def find_path(basepath, stringname):\n",
    "    for fname in os.listdir(basepath):\n",
    "        path = os.path.join(basepath, fname)\n",
    "        if os.path.isdir(path):\n",
    "            if stringname in fname:\n",
    "                return path\n",
    "def get_ticket(rx_path):\n",
    "    ticker=rx_path.split(\".\")[0].split(\"/\")[-1].split(\"-\")[0]\n",
    "    return ticker\n",
    "\n",
    "def ticker_trades_dir(ticker):\n",
    "    dest=os.path.join(os.getenv('FINANCE_DATA'), \"_\".join((ticker,'trades')))\n",
    "    if not os.path.isdir(dest):\n",
    "        os.makedirs(dest)\n",
    "def quotes_trades_dir(ticker):\n",
    "    dest=os.path.join(os.getenv('FINANCE_DATA'), \"_\".join((ticker,'quotes')))\n",
    "    if not os.path.isdir(dest):\n",
    "        os.makedirs(dest)\n",
    "def agg_on_trd_time(gr):\n",
    "    \"\"\"\n",
    "    Utility func to aggregate trades on timestamp. All trades with equal time stamp\n",
    "    will collapse to one row and the traded price will be the volume weighted traded\n",
    "    price.\n",
    "    \"\"\"\n",
    "    vTrdPrice = np.sum(gr['TradedPrice'] * gr['Volume'])/np.sum(gr['Volume'])\n",
    "    volume = np.sum(gr['Volume'])\n",
    "\n",
    "    return pd.Series({'Volume': volume,\n",
    "                      'TradedPrice': vTrdPrice})\n",
    "\n",
    "def open_pickle_file(path, pickle_file):\n",
    "    file_loc = os.path.join(path, pickle_file)\n",
    "    pickle_to_file = pickle.load(open(file_loc, \"rb\"))\n",
    "    return pickle_to_file\n",
    "def common_member(a, b): \n",
    "      \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "      \n",
    "    # check length  \n",
    "    if len(a_set.intersection(b_set)) > 0: \n",
    "        return(a_set.intersection(b_set))   \n",
    "    else: \n",
    "        return(\"no common elements\") \n",
    "\n",
    "def f(x):\n",
    "     return Series(dict(Number_of_tweets = x['content'].count(), \n",
    "                        Company=x['Company'].min(),\n",
    "                        Description=x['from_user_description'].min(),\n",
    "                        ))\n",
    "    \n",
    "def obv_calc(df):\n",
    "    df['SignedVolume']=df['Volume']*np.sign(df['TradedPrice'].diff()).cumsum()\n",
    "    df['SignedVolume'][:1]=0\n",
    "    df['OBV']=df['SignedVolume'].cumsum()\n",
    "    df =df.drop(columns=['SignedVolume'])\n",
    "    return df\n",
    "def chaikin_mf(df, period=5):\n",
    "    df[\"MF Multiplier\"] = (df['TradedPrice']-(df['TradedPrice'].expanding(period).min() ) \\\n",
    "                           - (df['TradedPrice'].expanding(period).max() - df['TradedPrice']))/(df['TradedPrice'].expanding(period).max() - df['TradedPrice'].expanding(period).min())\n",
    "    df[\"MF Volume\"] = df['MF Multiplier'] * df['Volume'] \n",
    "    df['CMF']= df['MF Volume'].sum()/df[\"Volume\"].rolling(5).sum()\n",
    "    df=df.drop(columns=['MF Multiplier','MF Volume'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data):\n",
    "    plt.figure(figsize=(16,4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(data[\"x\"], data[\"y\"])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(data[\"x\"], data[\"z\"])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    plt.show()\n",
    "def transform_to_uniform(x):\n",
    "    tmp = x.argsort()\n",
    "    cdf = np.zeros(tmp.shape)\n",
    "    cdf[tmp] = np.arange(len(x))\n",
    "    return cdf / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 2000\n",
    "\n",
    "def generate_plots(data):\n",
    "    plt.figure(figsize=(20,4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.hist2d(data[:,0], data[:,1], density=True, vmin=0, vmax=1)\n",
    "    c = plt.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "    plt.colorbar(c)\n",
    "    plt.title(\"Real\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    try:\n",
    "        copula = Clayton()\n",
    "        copula.fit(data)\n",
    "        synthetic = copula.sample(len(data))\n",
    "        plt.hist2d(synthetic[:,0], synthetic[:,1], density=True, vmin=0, vmax=1)\n",
    "        plt.colorbar();\n",
    "        plt.title(\"Clayton\")\n",
    "    except:\n",
    "        print(\"Skipping Clayton...\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    try:\n",
    "        copula = Gumbel()\n",
    "        copula.fit(data)\n",
    "        synthetic = copula.sample(len(data))\n",
    "        plt.hist2d(synthetic[:,0], synthetic[:,1], density=True, vmin=0, vmax=1)\n",
    "        plt.colorbar();\n",
    "        plt.title(\"Gumbel\")\n",
    "    except:\n",
    "        print(\"Skipping Gumbel...\")\n",
    "\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    try:\n",
    "        copula = Frank()\n",
    "        copula.fit(data)\n",
    "        synthetic = copula.sample(len(data))\n",
    "        plt.hist2d(synthetic[:,0], synthetic[:,1], density=True, vmin=0, vmax=1)\n",
    "        plt.colorbar();\n",
    "        plt.title(\"Frank\")\n",
    "    except:\n",
    "        print(\"Skipping Frank...\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##locations ##\n",
    "dataOnlyDrive = ('/media/ak/WorkDrive/Data')\n",
    "''' Exterrnal Files'''\n",
    "extPath = '/media/ak/My Passport/Experiment Data'\n",
    "barketData = '/media/ak/My Passport/Barket Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDrive = barketData\n",
    "bmrg_folders=[s for s in os.listdir(targetDrive ) if s.endswith('Comdty')]\n",
    "bmrg_trades=sorted([s for s in os.listdir(targetDrive ) if s.endswith('y_trades')])\n",
    "bmrg_quotes=sorted([s for s in os.listdir(targetDrive ) if s.endswith('y_quotes')])\n",
    "bmrg_tickers=sorted([bmrg_trades[idx].split('_t')[0] for idx,_ in enumerate(bmrg_trades)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TY1_Comdty_quotes', 'US1_Comdty_quotes'] ['TY1_Comdty_trades', 'US1_Comdty_trades']\n"
     ]
    }
   ],
   "source": [
    "# symbols = ['FB1', 'TU1', 'TY1', 'FV1']\n",
    "print(bmrg_quotes, bmrg_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TY1_Comdty', 'US1_Comdty']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmrg_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolIdx= 0\n",
    "# get dates and files\n",
    "symbol_quotes = os.path.join(targetDrive,str(bmrg_quotes[symbolIdx]))\n",
    "symbol_trades = os.path.join(targetDrive,str(bmrg_trades[symbolIdx]))\n",
    "symbolQuoteDates = [quoteFile.split(\".\")[0] for quoteFile in os.listdir(symbol_quotes)] \n",
    "symbolTradeDates = [tradeFile.split(\".\")[0] for tradeFile in os.listdir(symbol_trades)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ak/My Passport/Barket Data/TY1_Comdty_quotes'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TradeQuoteDates =[set(ymQuoteDates).intersection(set(ymTradeDates))]\n",
    "symbol_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tradeTestDate = os.path.join(symbol_trades, quoteTradeDates[0]+'.csv')\n",
    "# tradeQuoteDate = os.path.join(symbol_quotes, quoteTradeDates[0]+'.csv')\n",
    "# trades =pd.read_csv(tradeTestDate,low_memory=False)\n",
    "# quotes = pd.read_csv(tradeQuoteDate, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create dictionaries that have all the data we may need/want. on for top of the LOB and one for trades\n",
    "# quoteTradeDates=[eventDate for eventDate in symbolQuoteDates if eventDate in symbolTradeDates]\n",
    "# len(quoteTradeDates)\n",
    "# dfAllTrades ={}\n",
    "# dfAllQuotes ={}\n",
    "# for idx,date in enumerate(quoteTradeDates):\n",
    "#     tradeTestDate = pd.read_csv(os.path.join(symbol_trades, quoteTradeDates[idx]+'.csv'))\n",
    "#     tradeQuoteDate = pd.read_csv(os.path.join(symbol_quotes, quoteTradeDates[idx]+'.csv'))\n",
    "#     dfAllTrades[date] = tradeTestDate\n",
    "#     dfAllQuotes[date] = tradeQuoteDate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAllQuotesName = \"\".join(('AllQuotes',bmrg_quotes[symbolIdx],'Comdty.pkl'))\n",
    "dfAllTradesName = \"\".join(('AllTrades',bmrg_trades[symbolIdx],'Comdty.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(\"/\".join((symbol_quotes, dfAllQuotesName)))\n",
    "allQuotesDict =open_pickle_file(symbol_quotes, dfAllQuotesName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTradesDict = open_pickle_file(symbol_trades, dfAllTradesName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl.dump(dfAllQuotes, open(\"/\".join((symbol_quotes, dfAllQuotesName)), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl.dump(dfAllTrades, open(\"/\".join((symbol_trades, dfAllTradesName)), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQuoteKeys = list(allQuotesDict.keys()) #one common set of keys at the moment\n",
    "dTradeKeys = list(allTradesDict.keys())\n",
    "commonDates =list(set(dQuoteKeys).intersection(set(dTradeKeys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>size</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1319</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "      <td>BID</td>\n",
       "      <td>120.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>427</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "      <td>ASK</td>\n",
       "      <td>120.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>425</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "      <td>ASK</td>\n",
       "      <td>120.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "      <td>ASK</td>\n",
       "      <td>120.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1320</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "      <td>BID</td>\n",
       "      <td>120.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852509</th>\n",
       "      <td>886104</td>\n",
       "      <td>728</td>\n",
       "      <td>2018-04-17 00:00:00</td>\n",
       "      <td>ASK</td>\n",
       "      <td>120.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852510</th>\n",
       "      <td>886105</td>\n",
       "      <td>1191</td>\n",
       "      <td>2018-04-17 00:00:00</td>\n",
       "      <td>BID</td>\n",
       "      <td>120.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852511</th>\n",
       "      <td>886106</td>\n",
       "      <td>1190</td>\n",
       "      <td>2018-04-17 00:00:00</td>\n",
       "      <td>BID</td>\n",
       "      <td>120.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852512</th>\n",
       "      <td>886107</td>\n",
       "      <td>1192</td>\n",
       "      <td>2018-04-17 00:00:00</td>\n",
       "      <td>BID</td>\n",
       "      <td>120.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852513</th>\n",
       "      <td>886108</td>\n",
       "      <td>727</td>\n",
       "      <td>2018-04-17 00:00:00</td>\n",
       "      <td>ASK</td>\n",
       "      <td>120.453125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852514 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  size                 time type       value\n",
       "0                0  1319  2018-04-16 00:00:00  BID  120.375000\n",
       "1                1   427  2018-04-16 00:00:00  ASK  120.390625\n",
       "2                2   425  2018-04-16 00:00:00  ASK  120.390625\n",
       "3                3   350  2018-04-16 00:00:00  ASK  120.390625\n",
       "4                4  1320  2018-04-16 00:00:00  BID  120.375000\n",
       "...            ...   ...                  ...  ...         ...\n",
       "852509      886104   728  2018-04-17 00:00:00  ASK  120.453125\n",
       "852510      886105  1191  2018-04-17 00:00:00  BID  120.437500\n",
       "852511      886106  1190  2018-04-17 00:00:00  BID  120.437500\n",
       "852512      886107  1192  2018-04-17 00:00:00  BID  120.437500\n",
       "852513      886108   727  2018-04-17 00:00:00  ASK  120.453125\n",
       "\n",
       "[852514 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allQuotesDict[dQuoteKeys[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# dfLOBRaw={}\n",
    "# QuoteColumns =['Unnamed: 0','TimeStamp']\n",
    "# TradeColumns= ['Unnamed: 0', 'size', 'time', 'type', 'value']\n",
    "dKeys= commonDates\n",
    "for idx, dateKey in enumerate(commonDates):\n",
    "    #dfAllQuotes[dKeys[idx]].reset_index(level=0, inplace=True)\n",
    "    allQuotesDict[dKeys[idx]]['TimeStamp']= pd.to_datetime(allQuotesDict[dKeys[idx]]['time'])\n",
    "    allTradesDict[dKeys[idx]]['TradeTimeStamp']= pd.to_datetime(allTradesDict[dKeys[idx]]['time'])\n",
    "    allTradesDict[dKeys[idx]]['TradedPrice']= allTradesDict[dKeys[idx]]['value']\n",
    "    allTradesDict[dKeys[idx]]['TradedSize']= allTradesDict[dKeys[idx]]['size']\n",
    "    allTradesDict[dKeys[idx]].rename(columns = {'type':'QuotedSide','value':'bestPrice','size':'QuoteSize','time':'QuoteTimeStamp'}, inplace = True) \n",
    "    allTradesDict[dKeys[idx]]['Duration']=allTradesDict[dKeys[idx]].TradeTimeStamp.diff()/np.timedelta64(1, 'ms')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonKeys =list(set(allTradesDict).intersection(set(allQuotesDict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxKey=1\n",
    "dfBID=allQuotesDict[commonKeys[idxKey]][allQuotesDict[commonKeys[idxKey]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'TimeStampS'})\n",
    "dfASK=allQuotesDict[commonKeys[idxKey]][allQuotesDict[commonKeys[idxKey]]['type']=='ASK'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'TimeStampS'})\n",
    "#  =dfAllQuotes[commonDates[idx]][dfAllQuotes[commonDates[idx]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'TimeStampS'})#.drop(QuoteColumns, inplace=True, axis=1)\n",
    "# dfASK =dfAllQuotes[commonDates[idx]][dfAllQuotes[commonDates[idx]]['type']=='ASK'].rename(columns={'type':'AskSide','value':'bestAskPrice','size':'bestAskSize','time':'TimeStampS'})#.drop(QuoteColumns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=1\n",
    "# dfBID =dfAllQuotes[commonDates[idx]][dfAllQuotes[commonDates[idx]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'TimeStampS'})#.drop(QuoteColumns, inplace=True, axis=1)\n",
    "# dfASK =dfAllQuotes[commonDates[idx]][dfAllQuotes[commonDates[idx]]['type']=='ASK'].rename(columns={'type':'AskSide','value':'bestAskPrice','size':'bestAskSize','time':'TimeStampS'})#.drop(QuoteColumns, inplace=True, axis=1)\n",
    "dfLOB =dfBID.merge(dfASK,left_on='TimeStampS', right_on='TimeStampS')\n",
    "# dfLOB= dfLOB.drop(['Unnamed: 0_x', 'Unnamed: 0_y','AskSide','BidSide'], axis=1)\n",
    "#dfAllTrades[dKeys[0]].TradeTimeStamp.diff().dropna()/np.timedelta64(1, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0_x', 'bestBidSize_x', 'TimeStampS', 'BidSide_x',\n",
       "       'bestBidPrice_x', 'TimeStamp_x', 'Unnamed: 0_y', 'bestBidSize_y',\n",
       "       'BidSide_y', 'bestBidPrice_y', 'TimeStamp_y'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfLOB.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTradesDict[commonDates[idx]] = allTradesDict[commonDates[idxKey]].rename(index=str, columns={\"QuoteSize\": \"TradedVolume\",\"TradeTimeStamp\":\"TimeStampS\"}).drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean = allTradesDict[commonDates[idx]].rename(index=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMergedLOB = dfBID.merge(dfASK,left_on='TimeStampS', right_on='TimeStampS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/Envs/resrPyth3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfClean['TradedPriceChange'] =dfClean.TradedPrice.pct_change()\n",
    "dfClean=dfClean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= dfClean.TradedPriceChange.values\n",
    "y= dfClean.Duration\n",
    "z= dfClean.TradedVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-6191157985d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransform_to_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_to_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-48c953f296bb>\u001b[0m in \u001b[0;36mgenerate_plots\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdBu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_min' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.stack([transform_to_uniform(z), transform_to_uniform(y)], axis=1)\n",
    "generate_plots(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfLOBraw ={}\n",
    "# for idx, dateKey in enumerate(commonDates):\n",
    "#     dfBID =dfAllQuotes[dKeys[idx]][dfAllQuotes[dKeys[0]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'BidTimeStamp'})\n",
    "#     dfASK =dfAllQuotes[dKeys[idx]][dfAllQuotes[dKeys[0]]['type']=='ASK'].rename(columns={'type':'AskSide','value':'bestAskPrice','size':'bestAskSize','time':'AskTimeStamp'})\n",
    "#     dfLOBraw[dKeys[idx]] =pd.concat([dfBID, dfASK],axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfAllQuotes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ad98d7dd4009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfBID\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdfAllQuotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfAllQuotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'BID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'BidSide'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bestBidPrice'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bestBidSize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'BidTimeStamp'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.drop(QuoteColumns, inplace=True, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfASK\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdfAllQuotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfAllQuotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ASK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'AskSide'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bestAskPrice'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bestAskSize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'AskTimeStamp'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.drop(QuoteColumns, inplace=True, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdfAllTrades\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTradeTimeStamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dfAllQuotes[dateKeys[idx]]['Time']= dfAllQuotes[dateKeys[idx]]['time'].dt.time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfAllQuotes' is not defined"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "dfBID =dfAllQuotes[dKeys[idx]][dfAllQuotes[dKeys[idx]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','time':'BidTimeStamp'})#.drop(QuoteColumns, inplace=True, axis=1)\n",
    "dfASK =dfAllQuotes[dKeys[idx]][dfAllQuotes[dKeys[idx]]['type']=='ASK'].rename(columns={'type':'AskSide','value':'bestAskPrice','size':'bestAskSize','time':'AskTimeStamp'})#.drop(QuoteColumns, inplace=True, axis=1)\n",
    "dfAllTrades[dKeys[0]].TradeTimeStamp.diff().dropna()/np.timedelta64(1, 'ms')\n",
    "#dfAllQuotes[dateKeys[idx]]['Time']= dfAllQuotes[dateKeys[idx]]['time'].dt.time\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfAllTrades' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-24cbf66a0cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfAllTrades\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTradeTimeStamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfAllTrades' is not defined"
     ]
    }
   ],
   "source": [
    "dfAllTrades[dKeys[0]].TradeTimeStamp.diff().dropna()/np.timedelta64(1, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index', 'Unnamed: 0','time','AskSide']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBID =dfAllQuotes[dKeys[0]][dfAllQuotes[dKeys[0]]['type']=='BID'].rename(columns={'type':'BidSide','value':'bestBidPrice','size':'bestBidSize','TimeStamp':'BidTimeStamp'})\n",
    "# dfASK =dfAllQuotes[dKeys[0]][dfAllQuotes[dKeys[0]]['type']=='ASK'].rename(columns={'type':'AskSide','value':'bestAskPrice','size':'bestAskSize','TimeStamp':'AskTimeStamp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfASK.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'Unnamed: 0','TimeStamp','AskSide']\n",
    "dfASK.drop(columns, inplace=True, axis=1)\n",
    "dfASK.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfBID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-63f94dede603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TimeStamp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BidSide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfBID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfBID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfBID' is not defined"
     ]
    }
   ],
   "source": [
    "columns = [ 'Unnamed: 0','TimeStamp','BidSide']\n",
    "dfBID.drop(columns, inplace=True, axis=1)\n",
    "dfBID.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfBID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5a9af141a7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfLOBraw\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfBID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfASK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfLOBraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfBID' is not defined"
     ]
    }
   ],
   "source": [
    "dfLOBraw =pd.concat([dfBID, dfASK],axis=1, join='outer').ffill().dropna()\n",
    "dfLOBraw.tail(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_rolling=test_file['TradedPrice'].rolling(5).mean()\n",
    "v= test_file['Volume'].rolling(5).mean()\n",
    "df=test_file\n",
    "# df.groupby(df.index).rolling(7).apply(lambda x: np.average(x.TradedPrice, weights=x.Volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Groupby column with rolling mean.\n",
    "# df_grouped_rolling = df.groupby(df.index)[['TradedPrice', 'Volume']].rolling(window=3, min_periods=2).min()\n",
    "# df_grouped_rolling.groupby(df_grouped_rolling.index).rolling(7).apply(lambda x: np.average(x.TradedPrice, weights=x.Volume))\n",
    "# # # df_grouped_rolling.head(10)\n",
    "# df_grouped_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx=0\n",
    "# trades_files_loc = os.path.join(data_dir,bmrg_trades[idx])\n",
    "# trades_files= os.listdir(os.path.join(data_dir,bmrg_trades[idx]))\n",
    "# # file_idx=1\n",
    "# for file_idx,_ in enumerate(trades_files):\n",
    "#     symbol='G_1_Comdty'\n",
    "#     print('working on symbol:', symbol)\n",
    "#     trades_df = pd.read_csv(os.path.join(trades_files_loc, trades_files[file_idx]), index_col=0)\n",
    "#     print('reading this:', trades_files[file_idx])\n",
    "#     trades_df=trades_df.rename(index=str, columns={\"size\": \"Volume\",\"value\":\"TradedPrice\"}).drop(columns=['type'])\n",
    "#     trades_df['TradedTime'] = pd.to_datetime(trades_df['time'])\n",
    "#     trades_df= trades_df.drop(columns=['time'])\n",
    "#     res = trades_df.groupby('TradedTime').apply(agg_on_trd_time)\n",
    "#     res.reset_index(inplace=True)\n",
    "#     res.loc[:, 'Duration'] = res['TradedTime']- res['TradedTime'].shift(1)\n",
    "#     res['Duration'].fillna(value=0, inplace=True)\n",
    "#     res.loc[:, 'Duration'] = res['Duration'].apply(lambda tt: tt.total_seconds())\n",
    "#     res.loc[1:, 'ReturnTradedPrice'] = \\\n",
    "#         res['TradedPrice'].rolling(window=2).apply(lambda xx: np.log(xx[-1]/xx[0]))\n",
    "#     res.loc[0, 'ReturnTradedPrice'] = 0.\n",
    "#     target_file_name\n",
    "#     target_file_name = os.path.join(os.path.join(data_dir,symbol),trades_files[file_idx])\n",
    "#     print('saving here:', target_file_name)karima\n",
    "#     res[['TradedTime', 'TradedPrice', 'ReturnTradedPrice', 'Volume', \\\n",
    "#          'Duration']].to_csv(target_file_name, index=False)\n",
    "# print(res.columns.values)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, symbol_trades in enumerate(bmrg_trades):\n",
    "#     trades_files_loc = os.path.join(data_dir,bmrg_trades[idx])\n",
    "#     trades_files= os.listdir(os.path.join(data_dir,bmrg_trades[idx]))\n",
    "#     symbol=\"_\".join((bmrg_trades[idx].split('_')[0],\"Comdty\"))\n",
    "#     print('working on symbol:', symbol)\n",
    "#     for file_idx,_ in enumerate(trades_files):\n",
    "#         print('reading this:', trades_files[file_idx])\n",
    "#         trades_df = pd.read_csv(os.path.join(trades_files_loc, trades_files[file_idx]), index_col=0)\n",
    "#         trades_df=trades_df.rename(index=str, columns={\"size\": \"Volume\",\"value\":\"TradedPrice\"}).drop(columns=['type'])\n",
    "#         trades_df['TradedTime'] = pd.to_datetime(trades_df['time'])\n",
    "#         trades_df= trades_df.drop(columns=['time'])\n",
    "#         res = trades_df.groupby('TradedTime').apply(agg_on_trd_time)\n",
    "#         res.reset_index(inplace=True)\n",
    "#         res.loc[:, 'Duration'] = res['TradedTime']- res['TradedTime'].shift(1)\n",
    "#         res['Duration'].fillna(value=0, inplace=True)\n",
    "#         res.loc[:, 'Duration'] = res['Duration'].apply(lambda tt: tt.total_seconds())\n",
    "#         res.loc[1:, 'ReturnTradedPrice'] = \\\n",
    "#             res['TradedPrice'].rolling(window=2).apply(lambda xx: np.log(xx[-1]/xx[0]))\n",
    "#         res.loc[0, 'ReturnTradedPrice'] = 0\n",
    "#         target_file_name = os.path.join(os.path.join(data_dir,symbol),trades_files[file_idx])\n",
    "#         print('saving here:', target_file_name)\n",
    "#         res[['TradedTime', 'TradedPrice', 'ReturnTradedPrice', 'Volume', \\\n",
    "#              'Duration']].to_csv(target_file_name, index=False)\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol_path = find_path(data_dir, str(bmrg_symbols[0]))\n",
    "# symbol_files=os.listdir(symbol_path)\n",
    "\n",
    "# symbol=symbol_files[1].split('-')[0]\n",
    "# date=symbol_files[1].split('-')[1].split('.')[0]\n",
    "idx=3\n",
    "trades_loc= os.path.join(data_dir,bmrg_trades[1])\n",
    "list_files =os.listdir(os.path.join(data_dir,bmrg_trades[1]))\n",
    "trades_file = os.path.join(trades_loc, list_files[idx])\n",
    "df= pd.read_csv(trades_file,index_col=0 )\n",
    "df.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import datetime as dt\n",
    "# sample = parse(df['time'].iloc[:,1])\n",
    "# print(sample)\n",
    "sample=parse(df['time'].iloc[12])\n",
    "# # datetime.datetime(2010, 2, 15, 0, 0)\n",
    "# print(dt.strftime('%d/%m/%Y'))\n",
    "# # 15/02/2010\n",
    "sample_time=sample.time()\n",
    "sample_time.strftime('%H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto Data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "crypto=os.path.join(data_only_drive,'crypto/BTCUSD.PERP.BMEX')\n",
    "os.listdir(data_only_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_path=os.path.join(data_only_drive,'crypto')\n",
    "trades_crypto_path = os.path.join(crypto_path,'trades')\n",
    "perp_trades_loc= os.path.join(trades_crypto_path,'BTCUSD.PERP.BMEX')\n",
    "perp_trades_list=os.listdir(perp_trades_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOB = os.path.join(crypto_path,'LOB')\n",
    "lob_files= os.listdir(os.path.join(LOB,os.listdir(LOB)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = pd.read_csv(os.path.join(perp_trades_loc, perp_trades_list[0]), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(perp_trades_loc, perp_trades_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file=sample_file.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df= pd.to_datetime(sample_file['received_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df['TradedPrice']= sample_file['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file =sample_file.rename(index=str, columns={\"received_at\":\"TradedTime\",\"side\":\"Side\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file['TradedTime']=pd.to_datetime(sample_file['TradedTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file =sample_file.rename(index=str, columns={\"price\":\"TradedPrice\",\"size\":\"Volume\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(date_time):\n",
    "    timestamp= date_time.strftime('%H:%M:%S.%f')\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file['TradedTime']=sample_file['TradedTime'].apply(get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = sample_file.groupby('TradedTime').apply(agg_on_trd_time)\n",
    "res.reset_index(inplace=True)\n",
    "res.loc[:, 'Duration'] = res['TradedTime']- res['TradedTime'].shift(1)\n",
    "res['Duration'].fillna(value=0, inplace=True)\n",
    "res.loc[:, 'Duration'] = res['Duration'].apply(lambda tt: tt.total_seconds())\n",
    "res.loc[1:, 'ReturnTradedPrice'] = \\\n",
    "res['TradedPrice'].rolling(window=2).apply(lambda xx: np.log(xx[-1]/xx[0]))\n",
    "res.loc[0, 'ReturnTradedPrice'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('FINANCE_DATA') #main directory\n",
    "data_only_drive= '/mnt/usb-Seagate_Expansion_Desk_NA8XEHR6-0:0-part2'\n",
    "bmrg_symbols=[s for s in os.listdir(data_dir) if s.endswith('20181028') or s.endswith('20181027')]\n",
    "\n",
    "\n",
    "bmrg_symbols_destinations=[s for s in os.listdir(data_dir) if s.endswith('trades') or s.endswith('quotes')]\n",
    "bmrg_tickers=[bmrg_symbols_destinations[idx].split('_t')[0] or \\\n",
    "              bmrg_symbols_destinations[idx].split('_q')[0] for idx,_ in enumerate(bmrg_symbols_destinations)]\n",
    "ftse_symbols= [s for s in os.listdir(data_dir) if s.endswith('.L')]\n",
    "features_models_dd= os.path.join(data_dir, 'features_models')\n",
    "labels = os.path.join(features_models_dd, 'labels')\n",
    "model_features= os.path.join(features_models_dd, 'features')\n",
    "features_models_dOd= os.path.join(data_only_drive, 'features_models')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#     symbol_features_path = os.path.join(model_features, symbol,'MODEL_BASED') # set model-based features path for the symbol\n",
    "#     symbol_labels_list= os.listdir(symbol_labels_path) # make a list of all the labels\n",
    "#     market_features_path = os.path.join(data_only_drive,'Data','features_models',symbol,'MARKET_BASED')\n",
    "#     features_dates_dir= os.listdir(symbol_features_path)\n",
    "#     market_features_dates= [os.listdir(market_features_path)[idx].split(\".\")[0] for idx, _ in enumerate(market_features_path)]\n",
    "#     labels_dates= [symbol_labels_list[idx].split(\".\")[0] for idx, _ in enumerate(symbol_labels_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir\n",
    "ftse_symbols= [s for s in os.listdir(data_dir) if s.endswith('.L')]\n",
    "test=os.listdir(os.path.join(data_dir, ftse_symbols[1]))\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx,_ in enumerate(ftse_symbols):\n",
    "    symbol=ftse_symbols[idx] # set symbol\n",
    "    features_models_path = '/media/ak/WorkDrive/Data/features_models/models/'\n",
    "    features_only_path = '/media/ak/WorkDrive/Data/features_models/features/'\n",
    "    symbol_raw_data_path = os.listdir(os.path.join(data_dir, symbol))\n",
    "    symbol_hmm_model_path = os.listdir(os.path.join(features_models_path, symbol,'HMM'))\n",
    "    symbol_labels_path= os.listdir(os.path.join(labels, symbol,'NON_DIRECTIONAL')) # set labels path for the symbol\n",
    "    market_features_path = os.listdir(os.path.join(data_only_drive,'Data','features_models',symbol,'MARKET_BASED'))\n",
    "    symbol_model_features = os.listdir(os.path.join(features_only_path, symbol, 'MODEL_BASED'))\n",
    "#     print('symbol: ', symbol)\n",
    "# #     print('number of days: ', len(symbol_raw_data_path))\n",
    "# #     print('number of hmm models: ', len(symbol_hmm_model_path))\n",
    "# #     print(\"number of date files in labels:\",len(symbol_labels_path))\n",
    "#     print(\"mearket features:\", len(market_features_path))\n",
    "#     print(\"common elements between market features and labels:\",len(list(common_member(market_features_path, \\\n",
    "#                                                                                        symbol_labels_path))))\n",
    "# #     if len(symbol_raw_data_path)!= len(symbol_labels_path):\n",
    "# #         print('check symbol:',symbol)\n",
    "# #         problem_list.append(symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test case##\n",
    "symbol='AAL.L' # set symbol\n",
    "features_models_path = '/media/ak/WorkDrive/Data/features_models/models/'\n",
    "symbol_raw_data_path = os.path.join(data_dir, symbol)\n",
    "symbol_hmm_model_path = os.path.join(features_models_path, symbol,'HMM')\n",
    "symbol_labels_path= os.path.join(labels, symbol,'NON_DIRECTIONAL') # set labels path for the symbol\n",
    "market_features_path = os.path.join(data_only_drive,'Data','features_models',symbol,'MARKET_BASED')\n",
    "print('symbol: ', symbol)\n",
    "print(symbol_raw_data_path)\n",
    "print(symbol_hmm_model_path)\n",
    "print(symbol_labels_path)\n",
    "print(market_features_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_features = os.listdir(os.path.join(features_only_path, symbol, 'MODEL_BASED')) #this is a list of folders, indexed by date\n",
    "labels_dates= [symbol_labels_path[idx].split(\".\")[0] for idx, _ in enumerate(symbol_labels_path)]\n",
    "date=labels_dates[1]\n",
    "# for _, date in enumerate(labels_dates):\n",
    "date_symbol_features = os.path.join(features_only_path, symbol, 'MODEL_BASED', date)\n",
    "date_feature_list= os.listdir(date_symbol_features)\n",
    "for idx, _ in enumerate(date_feature_list):\n",
    "    open_pickle_file(path=date_symbol_features, pickle_file=date_feature_list[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date\n",
    "date_symbol_features = os.path.join(features_only_path, symbol, 'MODEL_BASED', date)\n",
    "date_symbol_features\n",
    "date_feature_list= os.listdir(date_symbol_features)\n",
    "print date_feature_list\n",
    "for idx, _ in enumerate(date_feature_list):\n",
    "     open_pickle_file(path=date_symbol_features, pickle_file=date_feature_list[idx])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, date  in enumerate(symbol_model_features):\n",
    "#     print os.listdir(os.path.join(features_only_path, symbol, 'MODEL_BASED', date))\n",
    "date_feature_list= os.listdir(date_symbol_features)\n",
    "for idx, _ in enumerate(date_feature_list):\n",
    "    print date_feature_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[symbol_labels_list[idx].split(\".\")[0] for idx, _ in enumerate(symbol_labels_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=pd.read_csv(file_location,index_col=0)['Duration']\n",
    "non_directional_labels = pd.read_csv(file_location,index_col=0)['label_PrMov__window_25__thres_arbitrary__10.0'] #this is a problem\n",
    "df = pd.read_csv(file_location,index_col=0)\n",
    "features_dates_dir= os.listdir(symbol_features_path)#\n",
    "# path for a specific hmm model date --- out of sample pickle files\n",
    "pickle_features_path= os.path.join(symbol_features_path, features_dates_dir[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(pickle_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'III.L_3_states_features_date:_20171024_now:_20181226_\n",
    "compute_date= '20181226'\n",
    "date= features_dates_dir[5]\n",
    "features_pickle_file = \"_\".join((symbol,'3_states_features_date:',features_dates_dir[5],'now:',compute_date,'.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features =open_pickle_file(pickle_features_path,features_pickle_file) #tuple for all the HMM- model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features_path = os.path.join(data_only_drive,'Data','features_models',symbol,'MARKET_BASED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features= os.path.join(market_features_path, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(market_features):\n",
    "    pd.read_csv(market_features)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features_dates= [os.listdir(market_features_path)[idx].split(\".\")[0] for idx, _ in enumerate(market_features_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b): \n",
    "      \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "      \n",
    "    # check length  \n",
    "    if len(a_set.intersection(b_set)) > 0: \n",
    "        return(a_set.intersection(b_set))   \n",
    "    else: \n",
    "        return(\"no common elements\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_elements=list(common_member(features_dates_dir, market_features_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_dates_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(market_features_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
